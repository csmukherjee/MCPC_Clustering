{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "#sys.path.append('/Users/chandrasekharmukherjee/Home/Centrality framework/Modules')\n",
    "sys.path.append('I:/내 드라이브/backup/document/USC/Research/MCPC/Code/Codes')\n",
    "\n",
    "#Import packages\n",
    "#imports\n",
    "import time\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import sknetwork\n",
    "\n",
    "\n",
    "from sknetwork.ranking import PageRank\n",
    "from sknetwork.ranking import Betweenness\n",
    "from sknetwork.ranking import Closeness\n",
    "\n",
    "#import umap as umap\n",
    "\n",
    "from numba.typed import List\n",
    "import warnings\n",
    "from numba import njit\n",
    "import pynndescent\n",
    "import numpy as np\n",
    "from sklearn.cluster import SpectralClustering\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import operator\n",
    "from sklearn.utils.extmath import randomized_svd\n",
    "from random import randint\n",
    "from sklearn.utils.extmath import randomized_svd\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import scipy\n",
    "#from umap.umap_ import *\n",
    "import math\n",
    "from random import randint\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.datasets import cifar10\n",
    "from keras.datasets import cifar100\n",
    "from keras.datasets import fashion_mnist\n",
    "import scanpy\n",
    "from sklearn.metrics.cluster import normalized_mutual_info_score\n",
    "from sklearn.metrics import adjusted_mutual_info_score, roc_auc_score\n",
    "from sklearn.metrics.cluster import adjusted_rand_score\n",
    "from sklearn.metrics.cluster import adjusted_mutual_info_score\n",
    "\n",
    "#import community as community_louvain\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import fowlkes_mallows_score\n",
    "\n",
    "import scipy\n",
    "\n",
    "import igraph \n",
    "import networkx as nx\n",
    "\n",
    "\n",
    "import metric as met \n",
    "import embedding as embed   \n",
    "import data_utils_ch as data_util\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import importlib\n",
    "\n",
    "import metric as met \n",
    "import embedding as embed   \n",
    "import data_utils_ch as data_util\n",
    "from subgraph import *\n",
    "\n",
    "\n",
    "met=importlib.reload(met)\n",
    "embed=importlib.reload(embed)\n",
    "data_util=importlib.reload(data_util)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Louvain Baseline (idx: 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Cust_Top as Cust\n",
    "import networkx.algorithms.community.louvain as Louv\n",
    "from sklearn.metrics.cluster import normalized_mutual_info_score as NMI\n",
    "from collections import deque\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import os\n",
    "from subgraph import * \n",
    "import debug\n",
    "from collections import defaultdict\n",
    "import leidenalg as la \n",
    "\n",
    "#data_names = ['Zhengmix8eq','mRNA','miRNA','FashionMNIST','MNIST','seeds','breast-cancer','Omniglot','bbc_news','20NewsGroups_tfdif','biorxiv','big_patent','Cora','Cora full','Citeseer','Eu core']\n",
    "#data_names = ['ALM', 'AMB', 'Baron_Human', 'Baron_Mouse', 'Muraro', 'Segerstolpe', 'Tcell-medicine', 'TM', 'VISP', 'Xin', 'Zheng']\n",
    "#data_names = ['Zhengmix8eq']\n",
    "data_names = ['Zhengmix8eq','mRNA','miRNA','FashionMNIST','MNIST','seeds','breast-cancer','Omniglot','bbc_news','20NewsGroups_tfdif','biorxiv','big_patent','Cora','Cora full','Citeseer','Eu core','ALM', 'AMB', 'Baron_Human', 'Baron_Mouse', 'Muraro', 'Segerstolpe', 'Tcell-medicine', 'TM', 'VISP', 'Xin', 'Zheng']\n",
    "\n",
    "'''\n",
    "datasets with nodes that have no outgoing edges : \n",
    "['Cora full', 'Citeseer', 'Eu core']\n",
    "'''\n",
    "\n",
    "FR_tp = ['FL','FL_ng','FL_ng_pr','PageRank']\n",
    "FR_tp_short = ['FL','FL_ng','FL_ng_p','PR']\n",
    "Num_hops = {0:'5',1:'log(n)'}\n",
    "\n",
    "#top k% nodes for induced subgraph\n",
    "k=0.2\n",
    "resolution_list = [0.05, 0.5, 1, 1.5, 5, 50]\n",
    "\n",
    "for data_idx, data in enumerate(data_names): \n",
    "\n",
    "    data_directory = f'./Plots/{data}'\n",
    "    file_path = f'{data_directory}/{data}.txt'\n",
    "    os.makedirs(data_directory, exist_ok=True)\n",
    "    pdf_name = './Plots/'+data+'/Testing'+data+'.pdf'\n",
    "\n",
    "    '''\n",
    "    Get the Graph from Edge_List and get the labels\n",
    "    '''\n",
    "    G, label= data_to_graph(data)\n",
    "\n",
    "    True_num_of_clusters = len(set(label))\n",
    "    \n",
    "\n",
    "    cluster_sizes = defaultdict(int)\n",
    "    for node in G.nodes():\n",
    "        cluster_sizes[label[node]]+=1\n",
    "\n",
    "    '''\n",
    "    Add self loops to the nodes with no outgoing edges\n",
    "    '''\n",
    "    G_ = G.copy()\n",
    "    for node in G_.nodes():\n",
    "        if not list(G_.successors(node)):\n",
    "            G_.add_edge(node, node, weight=1)\n",
    "\n",
    "    '''\n",
    "    dictionary for exporting to excel\n",
    "    '''\n",
    "    data_for_excel = defaultdict(lambda: defaultdict(int)) #nested dictionary to store data for plots\n",
    "    data_for_excel['data_idx'] = data_idx\n",
    "    data_for_excel['data_name'] = data\n",
    "    #data_for_excel['fr_tp'] = FR_tp\n",
    "    data_for_excel['fr_tp']=['FL']\n",
    "    data_for_excel['res_list'] = resolution_list\n",
    "    data_for_excel['method_idx'] = 0\n",
    "    data_for_excel['method_name'] = 'Louv_baseline'\n",
    "    data_for_excel['num_comm'] = True_num_of_clusters\n",
    "\n",
    "    for Num_hop in [1]:\n",
    "        #List of FR_values\n",
    "        FR_precalculated = []\n",
    "        for fr_type in range(4): \n",
    "            '''\n",
    "            Calculate FlowRank for the whole graph\n",
    "            '''\n",
    "            if Num_hop==0:\n",
    "                node2FR = calc_FlowRank(G_, fr_type, 5)\n",
    "            else:\n",
    "                node2FR = calc_FlowRank(G_, fr_type, np.log2(G.number_of_nodes()))\n",
    "            FR_precalculated.append(node2FR)\n",
    "\n",
    "        for idx, res in enumerate(resolution_list):\n",
    "            for Mod_type in [0]:\n",
    "                ''' \n",
    "                Louvain on G (baseline)\n",
    "                '''\n",
    "                label_, NMI_, Purity_ = do_Louvain(G, G, res, 0, label)\n",
    "                Num_Cluster_Louv_on_G = len(set(label_))\n",
    "                \n",
    "                data_for_excel[res]['FL'] = [round(NMI_,2), round(Purity_,2), '100%', Num_Cluster_Louv_on_G]\n",
    "    write_to_excel(data_for_excel, 'results.xlsx', 'results')\n",
    "    \n",
    "        \n",
    "            \n",
    "\n",
    "                                \n",
    "                    \n",
    "\n",
    "                    \n",
    "                    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leiden baseline (idx: 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Cust_Top as Cust\n",
    "import networkx.algorithms.community.louvain as Louv\n",
    "from sklearn.metrics.cluster import normalized_mutual_info_score as NMI\n",
    "from collections import deque\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import os\n",
    "from subgraph import * \n",
    "import debug\n",
    "from collections import defaultdict\n",
    "import leidenalg as la \n",
    "\n",
    "#data_names = ['Zhengmix8eq','mRNA','miRNA','FashionMNIST','MNIST','seeds','breast-cancer','Omniglot','bbc_news','20NewsGroups_tfdif','biorxiv','big_patent','Cora','Cora full','Citeseer','Eu core']\n",
    "#data_names = ['ALM', 'AMB', 'Baron_Human', 'Baron_Mouse', 'Muraro', 'Segerstolpe', 'Tcell-medicine', 'TM', 'VISP', 'Xin', 'Zheng']\n",
    "#data_names = ['Zhengmix8eq']\n",
    "data_names = ['Zhengmix8eq','mRNA','miRNA','FashionMNIST','MNIST','seeds','breast-cancer','Omniglot','bbc_news','20NewsGroups_tfdif','biorxiv','big_patent','Cora','Cora full','Citeseer','Eu core','ALM', 'AMB', 'Baron_Human', 'Baron_Mouse', 'Muraro', 'Segerstolpe', 'Tcell-medicine', 'TM', 'VISP', 'Xin', 'Zheng']\n",
    "\n",
    "'''\n",
    "datasets with nodes that have no outgoing edges : \n",
    "['Cora full', 'Citeseer', 'Eu core']\n",
    "'''\n",
    "\n",
    "FR_tp = ['FL','FL_ng','FL_ng_pr','PageRank']\n",
    "FR_tp_short = ['FL','FL_ng','FL_ng_p','PR']\n",
    "Num_hops = {0:'5',1:'log(n)'}\n",
    "\n",
    "#top k% nodes for induced subgraph\n",
    "k=0.2\n",
    "resolution_list = [0.05, 0.5, 1, 1.5, 5, 50]\n",
    "\n",
    "for data_idx, data in enumerate(data_names): \n",
    "\n",
    "    data_directory = f'./Plots/{data}'\n",
    "    file_path = f'{data_directory}/{data}.txt'\n",
    "    os.makedirs(data_directory, exist_ok=True)\n",
    "    pdf_name = './Plots/'+data+'/Testing'+data+'.pdf'\n",
    "\n",
    "    '''\n",
    "    Get the Graph from Edge_List and get the labels\n",
    "    '''\n",
    "    G, label= data_to_graph(data)\n",
    "\n",
    "    True_num_of_clusters = len(set(label))\n",
    "    \n",
    "\n",
    "    cluster_sizes = defaultdict(int)\n",
    "    for node in G.nodes():\n",
    "        cluster_sizes[label[node]]+=1\n",
    "\n",
    "    '''\n",
    "    Add self loops to the nodes with no outgoing edges\n",
    "    '''\n",
    "    G_ = G.copy()\n",
    "    for node in G_.nodes():\n",
    "        if not list(G_.successors(node)):\n",
    "            G_.add_edge(node, node, weight=1)\n",
    "\n",
    "    '''\n",
    "    dictionary for exporting to excel\n",
    "    '''\n",
    "    data_for_excel = defaultdict(lambda: defaultdict(int)) #nested dictionary to store data for plots\n",
    "    data_for_excel['data_idx'] = data_idx\n",
    "    data_for_excel['data_name'] = data\n",
    "    #data_for_excel['fr_tp'] = FR_tp\n",
    "    data_for_excel['fr_tp']=['FL']\n",
    "    data_for_excel['res_list'] = resolution_list\n",
    "    data_for_excel['method_idx'] = 1\n",
    "    data_for_excel['method_name'] = 'Leiden_baseline'\n",
    "    data_for_excel['num_comm'] = True_num_of_clusters\n",
    "\n",
    "    for Num_hop in [1]:\n",
    "        #List of FR_values\n",
    "        FR_precalculated = []\n",
    "        for fr_type in range(4): \n",
    "            '''\n",
    "            Calculate FlowRank for the whole graph\n",
    "            '''\n",
    "            if Num_hop==0:\n",
    "                node2FR = calc_FlowRank(G_, fr_type, 5)\n",
    "            else:\n",
    "                node2FR = calc_FlowRank(G_, fr_type, np.log2(G.number_of_nodes()))\n",
    "            FR_precalculated.append(node2FR)\n",
    "\n",
    "        for idx, res in enumerate(resolution_list):\n",
    "            for Mod_type in [0]:\n",
    "                '''\n",
    "                Leiden on G (Baseline)\n",
    "                '''\n",
    "                label_, NMI_, Purity_ = do_Leiden(G, G, res, 0, label)\n",
    "                Num_Cluster_Leiden_on_G = len(set(label_))\n",
    "                \n",
    "                data_for_excel[res]['FL'] = [round(NMI_,2), round(Purity_,2), '100%', Num_Cluster_Leiden_on_G]\n",
    "    write_to_excel(data_for_excel, 'results.xlsx', 'results')\n",
    "    \n",
    "        \n",
    "            \n",
    "\n",
    "                                \n",
    "                    \n",
    "\n",
    "                    \n",
    "                    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leiden + Majority vote (2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zhengmix8eq 3994\n",
      "Log transform done\n",
      "(3994, 50)\n",
      "Accuracy of  15 -NN graph is 0.791\n",
      "59910\n",
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "(11235, 19939)\n",
      "selected vertices  11235\n",
      "(11235,) Counter({'TCGA-BRCA': 1226, 'TCGA-KIRC': 610, 'TCGA-LUAD': 589, 'TCGA-UCEC': 585, 'TCGA-THCA': 572, 'TCGA-HNSC': 566, 'TCGA-PRAD': 554, 'TCGA-LUSC': 552, 'TCGA-LGG': 534, 'TCGA-COAD': 514, 'TCGA-SKCM': 473, 'TCGA-STAD': 448, 'TCGA-OV': 429, 'TCGA-BLCA': 428, 'TCGA-LIHC': 424, 'TCGA-KIRP': 323, 'TCGA-CESC': 309, 'TCGA-SARC': 265, 'TCGA-ESCA': 198, 'TCGA-PCPG': 187, 'TCGA-PAAD': 183, 'TCGA-READ': 177, 'TCGA-GBM': 174, 'TCGA-TGCT': 156, 'TCGA-LAML': 151, 'TCGA-THYM': 122, 'TCGA-KICH': 91, 'TCGA-MESO': 87, 'TCGA-UVM': 80, 'TCGA-ACC': 79, 'TCGA-UCS': 57, 'TCGA-DLBC': 48, 'TCGA-CHOL': 44})\n",
      "33 32\n",
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "(11020, 1882)\n",
      "selected vertices  11020\n",
      "(11020,) Counter({'TCGA-BRCA': 1202, 'TCGA-KIRC': 592, 'TCGA-UCEC': 575, 'TCGA-THCA': 573, 'TCGA-HNSC': 569, 'TCGA-LUAD': 564, 'TCGA-PRAD': 551, 'TCGA-LGG': 530, 'TCGA-LUSC': 523, 'TCGA-OV': 498, 'TCGA-STAD': 477, 'TCGA-COAD': 461, 'TCGA-SKCM': 452, 'TCGA-BLCA': 432, 'TCGA-LIHC': 425, 'TCGA-KIRP': 326, 'TCGA-CESC': 312, 'TCGA-SARC': 263, 'TCGA-ESCA': 198, 'TCGA-LAML': 188, 'TCGA-PCPG': 187, 'TCGA-PAAD': 183, 'TCGA-READ': 165, 'TCGA-TGCT': 156, 'TCGA-THYM': 126, 'TCGA-KICH': 91, 'TCGA-MESO': 87, 'TCGA-UVM': 80, 'TCGA-ACC': 80, 'TCGA-UCS': 57, 'TCGA-DLBC': 47, 'TCGA-CHOL': 45, 'TCGA-GBM': 5})\n",
      "33 32\n",
      "FashionMNIST (30000, 50)\n",
      "10 9\n",
      "MNIST (30000, 50)\n",
      "10 9\n",
      "seeds (209, 7)\n",
      "3 2\n",
      "2 1\n",
      "Files already downloaded and verified\n",
      "964 963\n",
      "bbc_news (1490, 50)\n",
      "5 4\n",
      "20NewsGroups_tfdif (10909, 50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MSI\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\scipy\\sparse\\_index.py:145: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 19\n",
      "biorxiv (68131, 50)\n",
      "26 25\n",
      "big_patent (17064, 50)\n",
      "9 8\n",
      "7 6\n",
      "70 69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "i:\\내 드라이브\\backup\\document\\USC\\Research\\MCPC\\Code\\Codes\\New_Cleaned\\FlowRank_General.py:424: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  rank[v]=v_cover[v]/sc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation for `citeseer_labels` and `citeseer_features` passes.\n",
      "7 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "i:\\내 드라이브\\backup\\document\\USC\\Research\\MCPC\\Code\\Codes\\New_Cleaned\\FlowRank_General.py:424: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  rank[v]=v_cover[v]/sc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42 41\n",
      "ALM 10068\n",
      "Log transform done\n",
      "(10068, 50)\n",
      "Accuracy of  15 -NN graph is 0.701\n",
      "151020\n",
      "AMB 12832\n",
      "Log transform done\n",
      "(12832, 50)\n",
      "Accuracy of  15 -NN graph is 0.764\n",
      "192480\n",
      "Baron_Human 8569\n",
      "Log transform done\n",
      "(8569, 50)\n",
      "Accuracy of  15 -NN graph is 0.972\n",
      "128535\n",
      "Baron_Mouse 1886\n",
      "Log transform done\n",
      "(1886, 50)\n",
      "Accuracy of  15 -NN graph is 0.954\n",
      "28290\n",
      "Muraro 2122\n",
      "Log transform done\n",
      "(2122, 50)\n",
      "Accuracy of  15 -NN graph is 0.951\n",
      "31830\n",
      "Segerstolpe 2133\n",
      "Log transform done\n",
      "(2133, 50)\n",
      "Accuracy of  15 -NN graph is 0.932\n",
      "31995\n",
      "Tcell-medicine 5759\n",
      "Log transform done\n",
      "(5759, 50)\n",
      "Accuracy of  15 -NN graph is 0.735\n",
      "86385\n",
      "TM 54865\n",
      "Log transform done\n",
      "(54865, 50)\n",
      "Accuracy of  15 -NN graph is 0.949\n",
      "822975\n",
      "VISP 15413\n",
      "Log transform done\n",
      "(15413, 50)\n",
      "Accuracy of  15 -NN graph is 0.709\n",
      "231195\n",
      "Xin 1449\n",
      "Log transform done\n",
      "(1449, 50)\n",
      "Accuracy of  15 -NN graph is 0.975\n",
      "21735\n",
      "Zheng 65943\n",
      "Log transform done\n",
      "(65943, 50)\n",
      "Accuracy of  15 -NN graph is 0.561\n",
      "989145\n"
     ]
    }
   ],
   "source": [
    "import Cust_Top as Cust\n",
    "import networkx.algorithms.community.louvain as Louv\n",
    "from sklearn.metrics.cluster import normalized_mutual_info_score as NMI\n",
    "from collections import deque\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import os\n",
    "from subgraph import * \n",
    "import debug\n",
    "from collections import defaultdict\n",
    "import leidenalg as la \n",
    "\n",
    "#data_names = ['Zhengmix8eq','mRNA','miRNA','FashionMNIST','MNIST','seeds','breast-cancer','Omniglot','bbc_news','20NewsGroups_tfdif','biorxiv','big_patent','Cora','Cora full','Citeseer','Eu core']\n",
    "#data_names = ['ALM', 'AMB', 'Baron_Human', 'Baron_Mouse', 'Muraro', 'Segerstolpe', 'Tcell-medicine', 'TM', 'VISP', 'Xin', 'Zheng']\n",
    "#data_names = ['Zhengmix8eq']\n",
    "data_names = ['Zhengmix8eq','mRNA','miRNA','FashionMNIST','MNIST','seeds','breast-cancer','Omniglot','bbc_news','20NewsGroups_tfdif','biorxiv','big_patent','Cora','Cora full','Citeseer','Eu core','ALM', 'AMB', 'Baron_Human', 'Baron_Mouse', 'Muraro', 'Segerstolpe', 'Tcell-medicine', 'TM', 'VISP', 'Xin', 'Zheng']\n",
    "\n",
    "'''\n",
    "datasets with nodes that have no outgoing edges : \n",
    "['Cora full', 'Citeseer', 'Eu core']\n",
    "'''\n",
    "\n",
    "FR_tp = ['FL','FL_ng','FL_ng_pr','PageRank']\n",
    "FR_tp_short = ['FL','FL_ng','FL_ng_p','PR']\n",
    "Num_hops = {0:'5',1:'log(n)'}\n",
    "\n",
    "#top k% nodes for induced subgraph\n",
    "k=0.2\n",
    "resolution_list = [0.05, 0.5, 1, 1.5, 5, 50]\n",
    "\n",
    "for data_idx, data in enumerate(data_names): \n",
    "\n",
    "    data_directory = f'./Plots/{data}'\n",
    "    file_path = f'{data_directory}/{data}.txt'\n",
    "    os.makedirs(data_directory, exist_ok=True)\n",
    "    pdf_name = './Plots/'+data+'/Testing'+data+'.pdf'\n",
    "\n",
    "    '''\n",
    "    Get the Graph from Edge_List and get the labels\n",
    "    '''\n",
    "    G, label= data_to_graph(data)\n",
    "\n",
    "    True_num_of_clusters = len(set(label))\n",
    "    \n",
    "\n",
    "    cluster_sizes = defaultdict(int)\n",
    "    for node in G.nodes():\n",
    "        cluster_sizes[label[node]]+=1\n",
    "\n",
    "    '''\n",
    "    Add self loops to the nodes with no outgoing edges\n",
    "    '''\n",
    "    G_ = G.copy()\n",
    "    for node in G_.nodes():\n",
    "        if not list(G_.successors(node)):\n",
    "            G_.add_edge(node, node, weight=1)\n",
    "\n",
    "    '''\n",
    "    dictionary for exporting to excel\n",
    "    '''\n",
    "    data_for_excel = defaultdict(lambda: defaultdict(int)) #nested dictionary to store data for plots\n",
    "    data_for_excel['data_idx'] = data_idx\n",
    "    data_for_excel['data_name'] = data\n",
    "    data_for_excel['fr_tp'] = FR_tp\n",
    "    #data_for_excel['fr_tp']=['FL']\n",
    "    data_for_excel['res_list'] = resolution_list\n",
    "    data_for_excel['method_idx'] = 2\n",
    "    data_for_excel['method_name'] = 'Leiden + Vote'\n",
    "    data_for_excel['num_comm'] = True_num_of_clusters\n",
    "\n",
    "    for Num_hop in [1]:\n",
    "        #List of FR_values\n",
    "        FR_precalculated = []\n",
    "        for fr_type in range(4): \n",
    "            '''\n",
    "            Calculate FlowRank for the whole graph\n",
    "            '''\n",
    "            if Num_hop==0:\n",
    "                node2FR = calc_FlowRank(G_, fr_type, 5)\n",
    "            else:\n",
    "                node2FR = calc_FlowRank(G_, fr_type, np.log2(G.number_of_nodes()))\n",
    "            FR_precalculated.append(node2FR)\n",
    "\n",
    "        for idx, res in enumerate(resolution_list):\n",
    "            for Mod_type in [0]:\n",
    "\n",
    "                for FR_type in range(4):\n",
    "                    \n",
    "                    '''\n",
    "                    Get induced subgraph of top k% nodes in FR value\n",
    "                    '''\n",
    "                    node2FR = FR_precalculated[FR_type]\n",
    "                    node_list = sorted(G.nodes, key=lambda x: node2FR[x], reverse=True)\n",
    "                    \n",
    "                    k_ = int(k*len(node_list))\n",
    "                    top_nodes = node_list[:k_]\n",
    "                    nodes_rest = node_list[k_:]\n",
    "                    H = getInducedSubgraph(G, top_nodes) # H = induced subgraph\n",
    "                    \n",
    "                    '''\n",
    "                    label counts for balancedness calculation\n",
    "                    '''\n",
    "                    selected_labels_dict = defaultdict(int)\n",
    "                    for node in H.nodes():\n",
    "                        selected_labels_dict[label[node]]+=1\n",
    "                    \n",
    "                    '''\n",
    "                    Leiden on the subgraph H \n",
    "                    '''\n",
    "                    H_label, _, _ = do_Leiden(H, G, res, 0, label)\n",
    "                    \n",
    "                    Num_Cluster_Leid_on_H = len({x for x in set(H_label) if x != -1})\n",
    "                    \n",
    "                    '''\n",
    "                    Add nodes to the subgraph by strong majority vote\n",
    "                    '''\n",
    "                    NMI_List, Purity_List, Balance_List, Preserv_List, InEdge_List = merge_by_vote(top_nodes, nodes_rest, H_label, G, label, selected_labels_dict, cluster_sizes)\n",
    "                    selected_node_num = len([x for x in H_label if x != -1])\n",
    "                    selected_node_percent = str(round(selected_node_num*100/(G.number_of_nodes()),2))+'%' \n",
    "                    data_for_excel[res][FR_tp[FR_type]] = [round(NMI_List[-1],2), round(Purity_List[-1],2), selected_node_percent, Num_Cluster_Leid_on_H]\n",
    "                    \n",
    "                    \n",
    "    write_to_excel(data_for_excel, 'results.xlsx', 'results')\n",
    "    \n",
    "        \n",
    "            \n",
    "\n",
    "                                \n",
    "                    \n",
    "\n",
    "                    \n",
    "                    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leiden + Majority vote + Leiden (3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zhengmix8eq 3994\n",
      "Log transform done\n",
      "(3994, 50)\n",
      "Accuracy of  15 -NN graph is 0.792\n",
      "59910\n",
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "(11235, 19939)\n",
      "selected vertices  11235\n",
      "(11235,) Counter({'TCGA-BRCA': 1226, 'TCGA-KIRC': 610, 'TCGA-LUAD': 589, 'TCGA-UCEC': 585, 'TCGA-THCA': 572, 'TCGA-HNSC': 566, 'TCGA-PRAD': 554, 'TCGA-LUSC': 552, 'TCGA-LGG': 534, 'TCGA-COAD': 514, 'TCGA-SKCM': 473, 'TCGA-STAD': 448, 'TCGA-OV': 429, 'TCGA-BLCA': 428, 'TCGA-LIHC': 424, 'TCGA-KIRP': 323, 'TCGA-CESC': 309, 'TCGA-SARC': 265, 'TCGA-ESCA': 198, 'TCGA-PCPG': 187, 'TCGA-PAAD': 183, 'TCGA-READ': 177, 'TCGA-GBM': 174, 'TCGA-TGCT': 156, 'TCGA-LAML': 151, 'TCGA-THYM': 122, 'TCGA-KICH': 91, 'TCGA-MESO': 87, 'TCGA-UVM': 80, 'TCGA-ACC': 79, 'TCGA-UCS': 57, 'TCGA-DLBC': 48, 'TCGA-CHOL': 44})\n",
      "33 32\n",
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "(11020, 1882)\n",
      "selected vertices  11020\n",
      "(11020,) Counter({'TCGA-BRCA': 1202, 'TCGA-KIRC': 592, 'TCGA-UCEC': 575, 'TCGA-THCA': 573, 'TCGA-HNSC': 569, 'TCGA-LUAD': 564, 'TCGA-PRAD': 551, 'TCGA-LGG': 530, 'TCGA-LUSC': 523, 'TCGA-OV': 498, 'TCGA-STAD': 477, 'TCGA-COAD': 461, 'TCGA-SKCM': 452, 'TCGA-BLCA': 432, 'TCGA-LIHC': 425, 'TCGA-KIRP': 326, 'TCGA-CESC': 312, 'TCGA-SARC': 263, 'TCGA-ESCA': 198, 'TCGA-LAML': 188, 'TCGA-PCPG': 187, 'TCGA-PAAD': 183, 'TCGA-READ': 165, 'TCGA-TGCT': 156, 'TCGA-THYM': 126, 'TCGA-KICH': 91, 'TCGA-MESO': 87, 'TCGA-UVM': 80, 'TCGA-ACC': 80, 'TCGA-UCS': 57, 'TCGA-DLBC': 47, 'TCGA-CHOL': 45, 'TCGA-GBM': 5})\n",
      "33 32\n",
      "FashionMNIST (30000, 50)\n",
      "10 9\n",
      "MNIST (30000, 50)\n",
      "10 9\n",
      "seeds (209, 7)\n",
      "3 2\n",
      "2 1\n",
      "Files already downloaded and verified\n",
      "964 963\n",
      "bbc_news (1490, 50)\n",
      "5 4\n",
      "20NewsGroups_tfdif (10909, 50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MSI\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\scipy\\sparse\\_index.py:145: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 19\n",
      "biorxiv (68131, 50)\n",
      "26 25\n",
      "big_patent (17064, 50)\n",
      "9 8\n",
      "7 6\n",
      "70 69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "i:\\내 드라이브\\backup\\document\\USC\\Research\\MCPC\\Code\\Codes\\New_Cleaned\\FlowRank_General.py:424: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  rank[v]=v_cover[v]/sc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation for `citeseer_labels` and `citeseer_features` passes.\n",
      "7 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "i:\\내 드라이브\\backup\\document\\USC\\Research\\MCPC\\Code\\Codes\\New_Cleaned\\FlowRank_General.py:424: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  rank[v]=v_cover[v]/sc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42 41\n",
      "ALM 10068\n",
      "Log transform done\n",
      "(10068, 50)\n",
      "Accuracy of  15 -NN graph is 0.702\n",
      "151020\n",
      "AMB 12832\n",
      "Log transform done\n",
      "(12832, 50)\n",
      "Accuracy of  15 -NN graph is 0.762\n",
      "192480\n",
      "Baron_Human 8569\n",
      "Log transform done\n",
      "(8569, 50)\n",
      "Accuracy of  15 -NN graph is 0.972\n",
      "128535\n",
      "Baron_Mouse 1886\n",
      "Log transform done\n",
      "(1886, 50)\n",
      "Accuracy of  15 -NN graph is 0.954\n",
      "28290\n",
      "Muraro 2122\n",
      "Log transform done\n",
      "(2122, 50)\n",
      "Accuracy of  15 -NN graph is 0.951\n",
      "31830\n",
      "Segerstolpe 2133\n",
      "Log transform done\n",
      "(2133, 50)\n",
      "Accuracy of  15 -NN graph is 0.932\n",
      "31995\n",
      "Tcell-medicine 5759\n",
      "Log transform done\n",
      "(5759, 50)\n",
      "Accuracy of  15 -NN graph is 0.737\n",
      "86385\n",
      "TM 54865\n",
      "Log transform done\n",
      "(54865, 50)\n",
      "Accuracy of  15 -NN graph is 0.949\n",
      "822975\n",
      "VISP 15413\n",
      "Log transform done\n",
      "(15413, 50)\n",
      "Accuracy of  15 -NN graph is 0.711\n",
      "231195\n",
      "Xin 1449\n",
      "Log transform done\n",
      "(1449, 50)\n",
      "Accuracy of  15 -NN graph is 0.974\n",
      "21735\n",
      "Zheng 65943\n",
      "Log transform done\n",
      "(65943, 50)\n",
      "Accuracy of  15 -NN graph is 0.562\n",
      "989145\n"
     ]
    }
   ],
   "source": [
    "import Cust_Top as Cust\n",
    "import networkx.algorithms.community.louvain as Louv\n",
    "from sklearn.metrics.cluster import normalized_mutual_info_score as NMI\n",
    "from collections import deque\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import os\n",
    "from subgraph import * \n",
    "import debug\n",
    "from collections import defaultdict\n",
    "import leidenalg as la \n",
    "\n",
    "#data_names = ['Zhengmix8eq','mRNA','miRNA','FashionMNIST','MNIST','seeds','breast-cancer','Omniglot','bbc_news','20NewsGroups_tfdif','biorxiv','big_patent','Cora','Cora full','Citeseer','Eu core']\n",
    "#data_names = ['ALM', 'AMB', 'Baron_Human', 'Baron_Mouse', 'Muraro', 'Segerstolpe', 'Tcell-medicine', 'TM', 'VISP', 'Xin', 'Zheng']\n",
    "#data_names = ['Zhengmix8eq']\n",
    "data_names = ['Zhengmix8eq','mRNA','miRNA','FashionMNIST','MNIST','seeds','breast-cancer','Omniglot','bbc_news','20NewsGroups_tfdif','biorxiv','big_patent','Cora','Cora full','Citeseer','Eu core','ALM', 'AMB', 'Baron_Human', 'Baron_Mouse', 'Muraro', 'Segerstolpe', 'Tcell-medicine', 'TM', 'VISP', 'Xin', 'Zheng']\n",
    "\n",
    "'''\n",
    "datasets with nodes that have no outgoing edges : \n",
    "['Cora full', 'Citeseer', 'Eu core']\n",
    "'''\n",
    "\n",
    "FR_tp = ['FL','FL_ng','FL_ng_pr','PageRank']\n",
    "FR_tp_short = ['FL','FL_ng','FL_ng_p','PR']\n",
    "Num_hops = {0:'5',1:'log(n)'}\n",
    "\n",
    "#top k% nodes for induced subgraph\n",
    "k=0.2\n",
    "resolution_list = [0.05, 0.5, 1, 1.5, 5, 50]\n",
    "\n",
    "for data_idx, data in enumerate(data_names): \n",
    "\n",
    "    data_directory = f'./Plots/{data}'\n",
    "    file_path = f'{data_directory}/{data}.txt'\n",
    "    os.makedirs(data_directory, exist_ok=True)\n",
    "    pdf_name = './Plots/'+data+'/Testing'+data+'.pdf'\n",
    "\n",
    "    '''\n",
    "    Get the Graph from Edge_List and get the labels\n",
    "    '''\n",
    "    G, label= data_to_graph(data)\n",
    "\n",
    "    True_num_of_clusters = len(set(label))\n",
    "    \n",
    "\n",
    "    cluster_sizes = defaultdict(int)\n",
    "    for node in G.nodes():\n",
    "        cluster_sizes[label[node]]+=1\n",
    "\n",
    "    '''\n",
    "    Add self loops to the nodes with no outgoing edges\n",
    "    '''\n",
    "    G_ = G.copy()\n",
    "    for node in G_.nodes():\n",
    "        if not list(G_.successors(node)):\n",
    "            G_.add_edge(node, node, weight=1)\n",
    "\n",
    "    '''\n",
    "    dictionary for exporting to excel\n",
    "    '''\n",
    "    data_for_excel = defaultdict(lambda: defaultdict(int)) #nested dictionary to store data for plots\n",
    "    data_for_excel['data_idx'] = data_idx\n",
    "    data_for_excel['data_name'] = data\n",
    "    data_for_excel['fr_tp'] = FR_tp\n",
    "    #data_for_excel['fr_tp']=['FL']\n",
    "    data_for_excel['res_list'] = resolution_list\n",
    "    data_for_excel['method_idx'] = 3\n",
    "    data_for_excel['method_name'] = 'Leiden + Vote + Leiden'\n",
    "    data_for_excel['num_comm'] = True_num_of_clusters\n",
    "\n",
    "    for Num_hop in [1]:\n",
    "        #List of FR_values\n",
    "        FR_precalculated = []\n",
    "        for fr_type in range(4): \n",
    "            '''\n",
    "            Calculate FlowRank for the whole graph\n",
    "            '''\n",
    "            if Num_hop==0:\n",
    "                node2FR = calc_FlowRank(G_, fr_type, 5)\n",
    "            else:\n",
    "                node2FR = calc_FlowRank(G_, fr_type, np.log2(G.number_of_nodes()))\n",
    "            FR_precalculated.append(node2FR)\n",
    "\n",
    "        for idx, res in enumerate(resolution_list):\n",
    "            for Mod_type in [0]:\n",
    "\n",
    "                for FR_type in range(4):\n",
    "                    \n",
    "                    '''\n",
    "                    Get induced subgraph of top k% nodes in FR value\n",
    "                    '''\n",
    "                    node2FR = FR_precalculated[FR_type]\n",
    "                    node_list = sorted(G.nodes, key=lambda x: node2FR[x], reverse=True)\n",
    "                    \n",
    "                    k_ = int(k*len(node_list))\n",
    "                    top_nodes = node_list[:k_]\n",
    "                    nodes_rest = node_list[k_:]\n",
    "                    H = getInducedSubgraph(G, top_nodes) # H = induced subgraph\n",
    "                    \n",
    "                    '''\n",
    "                    label counts for balancedness calculation\n",
    "                    '''\n",
    "                    selected_labels_dict = defaultdict(int)\n",
    "                    for node in H.nodes():\n",
    "                        selected_labels_dict[label[node]]+=1\n",
    "                    \n",
    "                    '''\n",
    "                    Leiden on the subgraph H \n",
    "                    '''\n",
    "                    H_label, _, _ = do_Leiden(H, G, res, 0, label)\n",
    "                    \n",
    "                    Num_Cluster_Leid_on_H = len({x for x in set(H_label) if x != -1})\n",
    "                    \n",
    "                    '''\n",
    "                    Add nodes to the subgraph by strong majority vote\n",
    "                    '''\n",
    "                    NMI_List, Purity_List, Balance_List, Preserv_List, InEdge_List = merge_by_vote(top_nodes, nodes_rest, H_label, G, label, selected_labels_dict, cluster_sizes)\n",
    "                    selected_node_num = len([x for x in H_label if x != -1])\n",
    "                    selected_node_percent = str(round(selected_node_num*100/(G.number_of_nodes()),2))+'%' \n",
    "                    \n",
    "                    '''\n",
    "                    Leiden again on the vote subgraph\n",
    "                    '''\n",
    "                    selected_node_list = [node_num_ for node_num_, node_label_ in enumerate(H_label) if node_label_ != -1]\n",
    "                    H2 = getInducedSubgraph(G, selected_node_list)\n",
    "                    H2_ig, ig_to_nx, nx_to_ig = networkx_to_igraph(H2) # Mapping = igraph index to networkx index\n",
    "                    initial_membership = [H_label[ig_to_nx[i]] for i in list(H2_ig.vs.indices)]\n",
    "                    partition2_ = la.find_partition(H2_ig, la.RBConfigurationVertexPartition, initial_membership = initial_membership, n_iterations=-1, resolution_parameter=res, seed=0)\n",
    "                    H_label2 = part_to_full_label(partition2_, G.number_of_nodes(), ig_to_nx)\n",
    "                    \n",
    "                    label_compressed2, H_label_compressed2 = get_compressed_labels(label,H_label2, selected_node_list)\n",
    "                    NMI_louv_vote_louv = NMI(H_label_compressed2, label_compressed2)\n",
    "                    Purity_louv_vote_louv = met.purity_score(label_compressed2, H_label_compressed2)\n",
    "                    Num_Cluster_Leid_on_H2 = len({x for x in set(H_label2) if x != -1})\n",
    "                    \n",
    "                    \n",
    "                    data_for_excel[res][FR_tp[FR_type]] = [round(NMI_louv_vote_louv,2), round(Purity_louv_vote_louv,2), selected_node_percent, Num_Cluster_Leid_on_H2]\n",
    "                    \n",
    "                    \n",
    "    write_to_excel(data_for_excel, 'results.xlsx', 'results')\n",
    "    \n",
    "        \n",
    "            \n",
    "\n",
    "                                \n",
    "                    \n",
    "\n",
    "                    \n",
    "                    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leiden + Vote + Leiden + Vote (4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Cust_Top as Cust\n",
    "import networkx.algorithms.community.louvain as Louv\n",
    "from sklearn.metrics.cluster import normalized_mutual_info_score as NMI\n",
    "from collections import deque\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import os\n",
    "from subgraph import * \n",
    "import debug\n",
    "from collections import defaultdict\n",
    "import leidenalg as la \n",
    "\n",
    "#data_names = ['Zhengmix8eq','mRNA','miRNA','FashionMNIST','MNIST','seeds','breast-cancer','Omniglot','bbc_news','20NewsGroups_tfdif','biorxiv','big_patent','Cora','Cora full','Citeseer','Eu core']\n",
    "#data_names = ['ALM', 'AMB', 'Baron_Human', 'Baron_Mouse', 'Muraro', 'Segerstolpe', 'Tcell-medicine', 'TM', 'VISP', 'Xin', 'Zheng']\n",
    "#data_names = ['Zhengmix8eq']\n",
    "data_names = ['Zhengmix8eq','mRNA','miRNA','FashionMNIST','MNIST','seeds','breast-cancer','Omniglot','bbc_news','20NewsGroups_tfdif','biorxiv','big_patent','Cora','Cora full','Citeseer','Eu core','ALM', 'AMB', 'Baron_Human', 'Baron_Mouse', 'Muraro', 'Segerstolpe', 'Tcell-medicine', 'TM', 'VISP', 'Xin', 'Zheng']\n",
    "\n",
    "'''\n",
    "datasets with nodes that have no outgoing edges : \n",
    "['Cora full', 'Citeseer', 'Eu core']\n",
    "'''\n",
    "\n",
    "FR_tp = ['FL','FL_ng','FL_ng_pr','PageRank']\n",
    "FR_tp_short = ['FL','FL_ng','FL_ng_p','PR']\n",
    "Num_hops = {0:'5',1:'log(n)'}\n",
    "\n",
    "#top k% nodes for induced subgraph\n",
    "k=0.2\n",
    "resolution_list = [0.05, 0.5, 1, 1.5, 5, 50]\n",
    "\n",
    "for data_idx, data in enumerate(data_names): \n",
    "\n",
    "    data_directory = f'./Plots/{data}'\n",
    "    file_path = f'{data_directory}/{data}.txt'\n",
    "    os.makedirs(data_directory, exist_ok=True)\n",
    "    pdf_name = './Plots/'+data+'/Testing'+data+'.pdf'\n",
    "\n",
    "    '''\n",
    "    Get the Graph from Edge_List and get the labels\n",
    "    '''\n",
    "    G, label= data_to_graph(data)\n",
    "\n",
    "    True_num_of_clusters = len(set(label))\n",
    "    \n",
    "\n",
    "    cluster_sizes = defaultdict(int)\n",
    "    for node in G.nodes():\n",
    "        cluster_sizes[label[node]]+=1\n",
    "\n",
    "    '''\n",
    "    Add self loops to the nodes with no outgoing edges\n",
    "    '''\n",
    "    G_ = G.copy()\n",
    "    for node in G_.nodes():\n",
    "        if not list(G_.successors(node)):\n",
    "            G_.add_edge(node, node, weight=1)\n",
    "\n",
    "    '''\n",
    "    dictionary for exporting to excel\n",
    "    '''\n",
    "    data_for_excel = defaultdict(lambda: defaultdict(int)) #nested dictionary to store data for plots\n",
    "    data_for_excel['data_idx'] = data_idx\n",
    "    data_for_excel['data_name'] = data\n",
    "    data_for_excel['fr_tp'] = FR_tp\n",
    "    #data_for_excel['fr_tp']=['FL']\n",
    "    data_for_excel['res_list'] = resolution_list\n",
    "    data_for_excel['method_idx'] = 4\n",
    "    data_for_excel['method_name'] = '(Leiden + Vote)x2'\n",
    "    data_for_excel['num_comm'] = True_num_of_clusters\n",
    "\n",
    "    for Num_hop in [1]:\n",
    "        #List of FR_values\n",
    "        FR_precalculated = []\n",
    "        for fr_type in range(4): \n",
    "            '''\n",
    "            Calculate FlowRank for the whole graph\n",
    "            '''\n",
    "            if Num_hop==0:\n",
    "                node2FR = calc_FlowRank(G_, fr_type, 5)\n",
    "            else:\n",
    "                node2FR = calc_FlowRank(G_, fr_type, np.log2(G.number_of_nodes()))\n",
    "            FR_precalculated.append(node2FR)\n",
    "\n",
    "        for idx, res in enumerate(resolution_list):\n",
    "            for Mod_type in [0]:\n",
    "\n",
    "                for FR_type in range(4):\n",
    "                    \n",
    "                    '''\n",
    "                    Get induced subgraph of top k% nodes in FR value\n",
    "                    '''\n",
    "                    node2FR = FR_precalculated[FR_type]\n",
    "                    node_list = sorted(G.nodes, key=lambda x: node2FR[x], reverse=True)\n",
    "                    \n",
    "                    k_ = int(k*len(node_list))\n",
    "                    top_nodes = node_list[:k_]\n",
    "                    nodes_rest = node_list[k_:]\n",
    "                    H = getInducedSubgraph(G, top_nodes) # H = induced subgraph\n",
    "                    \n",
    "                    '''\n",
    "                    label counts for balancedness calculation\n",
    "                    '''\n",
    "                    selected_labels_dict = defaultdict(int)\n",
    "                    for node in H.nodes():\n",
    "                        selected_labels_dict[label[node]]+=1\n",
    "                    \n",
    "                    '''\n",
    "                    Leiden on the subgraph H \n",
    "                    '''\n",
    "                    H_label, _, _ = do_Leiden(H, G, res, 0, label)\n",
    "                    \n",
    "                    Num_Cluster_Leid_on_H = len({x for x in set(H_label) if x != -1})\n",
    "                    \n",
    "                    '''\n",
    "                    Add nodes to the subgraph by strong majority vote\n",
    "                    '''\n",
    "                    NMI_List, Purity_List, Balance_List, Preserv_List, InEdge_List = merge_by_vote(top_nodes, nodes_rest, H_label, G, label, selected_labels_dict, cluster_sizes)\n",
    "                    selected_node_num = len([x for x in H_label if x != -1])\n",
    "                    \n",
    "                    \n",
    "                    '''\n",
    "                    Leiden again on the vote subgraph\n",
    "                    '''\n",
    "                    selected_node_list = [node_num_ for node_num_, node_label_ in enumerate(H_label) if node_label_ != -1]\n",
    "                    H2 = getInducedSubgraph(G, selected_node_list)\n",
    "                    H2_ig, ig_to_nx, nx_to_ig = networkx_to_igraph(H2) # Mapping = igraph index to networkx index\n",
    "                    initial_membership = [H_label[ig_to_nx[i]] for i in list(H2_ig.vs.indices)]\n",
    "                    partition2_ = la.find_partition(H2_ig, la.RBConfigurationVertexPartition, initial_membership = initial_membership, n_iterations=-1, resolution_parameter=res, seed=0)\n",
    "                    H_label2 = part_to_full_label(partition2_, G.number_of_nodes(), ig_to_nx)\n",
    "                    \n",
    "                    label_compressed2, H_label_compressed2 = get_compressed_labels(label,H_label2, selected_node_list)\n",
    "                    NMI_louv_vote_louv = NMI(H_label_compressed2, label_compressed2)\n",
    "                    Purity_louv_vote_louv = met.purity_score(label_compressed2, H_label_compressed2)\n",
    "                    Num_Cluster_Leid_on_H2 = len({x for x in set(H_label2) if x != -1})\n",
    "                    \n",
    "                    '''\n",
    "                    Leiden + vote + Leiden + vote\n",
    "                    '''\n",
    "                    nodes_rest2 = [node_num_ for node_num_, node_label_ in enumerate(H_label2) if node_label_ == -1]\n",
    "                    NMI_List2, Purity_List2, Balance_List2, Preserv_List2, InEdge_List2 = merge_by_vote(selected_node_list, nodes_rest2, H_label2, G, label, selected_labels_dict, cluster_sizes)\n",
    "                    selected_node_num2 = len([node_num_ for node_num_, node_label_ in enumerate(H_label2) if node_label_ != -1])\n",
    "                    selected_node_percent = str(round(selected_node_num2*100/(G.number_of_nodes()),2))+'%' \n",
    "\n",
    "                    data_for_excel[res][FR_tp[FR_type]] = [round(NMI_List2[-1],2), round(Purity_List2[-1],2), selected_node_percent, Num_Cluster_Leid_on_H2]\n",
    "                    \n",
    "                    \n",
    "    write_to_excel(data_for_excel, 'results.xlsx', 'results')\n",
    "    \n",
    "        \n",
    "            \n",
    "\n",
    "                                \n",
    "                    \n",
    "\n",
    "                    \n",
    "                    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leiden + Strong Majority Vote + Random Walk (Weak Majority Vote) (idx: 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Freeze pane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from subgraph import *\n",
    "freeze_panes('results.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leiden + Strong Majority Vote + Random Walk on unselected nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Cust_Top as Cust\n",
    "import networkx.algorithms.community.louvain as Louv\n",
    "from sklearn.metrics.cluster import normalized_mutual_info_score as NMI\n",
    "from collections import deque\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import os\n",
    "from subgraph import * \n",
    "import debug\n",
    "from collections import defaultdict\n",
    "import leidenalg as la \n",
    "\n",
    "#data_names = ['Zhengmix8eq','mRNA','miRNA','FashionMNIST','MNIST','seeds','breast-cancer','Omniglot','bbc_news','20NewsGroups_tfdif','biorxiv','big_patent','Cora','Cora full','Citeseer','Eu core']\n",
    "#data_names = ['ALM', 'AMB', 'Baron_Human', 'Baron_Mouse', 'Muraro', 'Segerstolpe', 'Tcell-medicine', 'TM', 'VISP', 'Xin', 'Zheng']\n",
    "#data_names = ['Zhengmix8eq']\n",
    "data_names = ['Zhengmix8eq','mRNA','miRNA','FashionMNIST','MNIST','seeds','breast-cancer','Omniglot','bbc_news','20NewsGroups_tfdif','biorxiv','big_patent','Cora','Cora full','Citeseer','Eu core','ALM', 'AMB', 'Baron_Human', 'Baron_Mouse', 'Muraro', 'Segerstolpe', 'Tcell-medicine', 'TM', 'VISP', 'Xin', 'Zheng']\n",
    "\n",
    "'''\n",
    "datasets with nodes that have no outgoing edges : \n",
    "['Cora full', 'Citeseer', 'Eu core']\n",
    "'''\n",
    "\n",
    "FR_tp = ['FL','FL_ng','FL_ng_pr','PageRank']\n",
    "FR_tp_short = ['FL','FL_ng','FL_ng_p','PR']\n",
    "Num_hops = {0:'5',1:'log(n)'}\n",
    "\n",
    "#top k% nodes for induced subgraph\n",
    "k=0.2\n",
    "resolution_list = [0.05,0.25, 0.5, 1, 1.5, 5]\n",
    "\n",
    "for data in data_names: \n",
    "    data_directory = f'./Plots/{data}'\n",
    "    file_path = f'{data_directory}/{data}.txt'\n",
    "    os.makedirs(data_directory, exist_ok=True)\n",
    "    pdf_name = './Plots/'+data+'/(Vote+RandWalk)'+data+'.pdf'\n",
    "    data_for_plot = defaultdict(lambda: defaultdict(dict)) #nested dictionary to store data for plots\n",
    "\n",
    "    '''\n",
    "    Get the Graph from Edge_List and get the labels\n",
    "    '''\n",
    "    G, label= data_to_graph(data)\n",
    "\n",
    "    True_num_of_clusters = len(set(label))\n",
    "    cluster_sizes = defaultdict(int)\n",
    "    for node in G.nodes():\n",
    "        cluster_sizes[label[node]]+=1\n",
    "\n",
    "    '''\n",
    "    Add self loops to the nodes with no outgoing edges\n",
    "    '''\n",
    "    G_ = G.copy()\n",
    "    for node in G_.nodes():\n",
    "        if not list(G_.successors(node)):\n",
    "            G_.add_edge(node, node, weight=1)\n",
    "    print('Number of nodes:',G.number_of_nodes())\n",
    "\n",
    "    for Num_hop in [1]:\n",
    "        #List of FR_values\n",
    "        FR_precalculated = []\n",
    "        for fr_type in range(4): \n",
    "            '''\n",
    "            Calculate FlowRank for the whole graph\n",
    "            '''\n",
    "            if Num_hop==0:\n",
    "                node2FR = calc_FlowRank(G_, fr_type, 5)\n",
    "            else:\n",
    "                node2FR = calc_FlowRank(G_, fr_type, np.log2(G.number_of_nodes()))\n",
    "            FR_precalculated.append(node2FR)\n",
    "\n",
    "        for idx, res in enumerate(resolution_list):\n",
    "            for Mod_type in [0]:\n",
    "                ''' \n",
    "                Louvain on G (baseline)\n",
    "                '''\n",
    "                label_, NMI_, Purity_ = do_Louvain(G, G, res, 0, label)\n",
    "                Num_Cluster_Louv_on_G = len(set(label_))\n",
    "\n",
    "                '''\n",
    "                Leiden on G (Baseline)\n",
    "                '''\n",
    "                label_, NMI_baseline_leiden, Purity_baseline_leiden = do_Leiden(G, G, res, 0, label)\n",
    "                Num_Cluster_Leiden_on_G = len(set(label_))\n",
    "\n",
    "                for FR_type in range(4):\n",
    "                    \n",
    "                    '''\n",
    "                    Get induced subgraph of top k% nodes in FR value\n",
    "                    '''\n",
    "                    node2FR = FR_precalculated[FR_type]\n",
    "                    node_list = sorted(G.nodes, key=lambda x: node2FR[x], reverse=True)\n",
    "                    \n",
    "                    k_ = int(k*len(node_list))\n",
    "                    top_nodes = node_list[:k_]\n",
    "                    nodes_rest = node_list[k_:]\n",
    "                    H = getInducedSubgraph(G, top_nodes) # H = induced subgraph\n",
    "                    \n",
    "                    '''\n",
    "                    label counts for balancedness calculation\n",
    "                    '''\n",
    "                    selected_labels_dict = defaultdict(int)\n",
    "                    for node in H.nodes():\n",
    "                        selected_labels_dict[label[node]]+=1\n",
    "                    \n",
    "                    '''\n",
    "                    Leiden on the subgraph H \n",
    "                    '''\n",
    "                    H_label, _, _ = do_Leiden(H, G, res, 0, label)\n",
    "                    \n",
    "                    Num_Cluster_Louv_on_H = len({x for x in set(H_label) if x != -1})\n",
    "                    '''\n",
    "                    Add nodes to the subgraph by strong majority vote\n",
    "                    '''\n",
    "                    NMI_List, Purity_List, Balance_List, Preserv_List, InEdge_List = merge_by_vote(top_nodes, nodes_rest, H_label, G, label, selected_labels_dict, cluster_sizes)\n",
    "                    # list of unselected_nodes\n",
    "                    unselected_nodes = [node_idx for node_idx, node_label in enumerate(H_label) if node_label == -1]\n",
    "                    selected_node_num = G.number_of_nodes() - len(unselected_nodes)\n",
    "                    '''\n",
    "                    Random walks from unselected nodes\n",
    "                    '''\n",
    "                    H_label, NMI_rand_walk, Purity_rand_walk = do_random_walks(G, unselected_nodes, label, H_label, node2FR) \n",
    "                    selected_node_num2 = len([x for x in H_label if x != -1])\n",
    "                    #print('selected_before_randwalk:',selected_node_num, 'selected_after_randwalk:',selected_node_num2)\n",
    "                    '''\n",
    "                    Plots\n",
    "                    '''\n",
    "                    #at index [res][FR_type] store the data for the plot\n",
    "                    data_for_plot[idx][FR_type] = {'NMI_after_vote':NMI_List[-1], 'Purity_after_vote':Purity_List[-1], 'Louvain_NMI':NMI_, \n",
    "                                                    'Louvain_Purity':Purity_, 'Leiden_NMI':NMI_baseline_leiden, 'Leiden_Purity':Purity_baseline_leiden, \n",
    "                                                    'Num_Cluster_Louv_on_G':Num_Cluster_Louv_on_G, 'Num_Cluster_Leiden_on_G':Num_Cluster_Leiden_on_G, \n",
    "                                                    'Num_Cluster_Louv_on_H':Num_Cluster_Louv_on_H, 'percent_nodes':(selected_node_num*100 / G.number_of_nodes()),\n",
    "                                                    'extra_nmi':NMI_rand_walk, 'extra_purity':Purity_rand_walk,\n",
    "                                                    'extra_name':'+RandWalk', 'extra_percent_nodes':(selected_node_num2*100 / G.number_of_nodes())\n",
    "                                                    }\n",
    "                    \n",
    "    plot_to_pdf(resolution_list, data_for_plot, k, True_num_of_clusters, pdf_name, data)\n",
    "    \n",
    "        \n",
    "            \n",
    "\n",
    "                                \n",
    "                    \n",
    "\n",
    "                    \n",
    "                    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
