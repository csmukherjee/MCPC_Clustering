{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Louvain Baseline (idx: 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Cust_Top as Cust\n",
    "import networkx.algorithms.community.louvain as Louv\n",
    "from sklearn.metrics.cluster import normalized_mutual_info_score as NMI\n",
    "from collections import deque\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import os\n",
    "from subgraph import * \n",
    "import debug\n",
    "from collections import defaultdict\n",
    "import leidenalg as la \n",
    "import time\n",
    "\n",
    "#data_names = ['Zhengmix8eq','mRNA','miRNA','FashionMNIST','MNIST','seeds','breast-cancer','Omniglot','bbc_news','20NewsGroups_tfdif','biorxiv','big_patent','Cora','Cora full','Citeseer','Eu core']\n",
    "#data_names = ['ALM', 'AMB', 'Baron_Human', 'Baron_Mouse', 'Muraro', 'Segerstolpe', 'Tcell-medicine', 'TM', 'VISP', 'Xin', 'Zheng']\n",
    "data_names = ['Zheng']\n",
    "#data_names = ['Zhengmix8eq','mRNA','miRNA','FashionMNIST','MNIST','seeds','breast-cancer','Omniglot','bbc_news','20NewsGroups_tfdif','biorxiv','big_patent','Cora','Cora full','Citeseer','Eu core','ALM', 'AMB', 'Baron_Human', 'Baron_Mouse', 'Muraro', 'Segerstolpe', 'Tcell-medicine', 'TM', 'VISP', 'Xin', 'Zheng']\n",
    "\n",
    "'''\n",
    "datasets with nodes that have no outgoing edges : \n",
    "['Cora full', 'Citeseer', 'Eu core']\n",
    "'''\n",
    "\n",
    "FR_tp = ['FL','FL_ng','FL_ng_pr','PageRank']\n",
    "FR_tp_short = ['FL','FL_ng','FL_ng_p','PR']\n",
    "Num_hops = {0:'5',1:'log(n)'}\n",
    "\n",
    "#top k% nodes for induced subgraph\n",
    "k=0.2\n",
    "resolution_list = [0.05, 0.5, 1, 1.5, 5, 50]\n",
    "\n",
    "for data_idx, data in enumerate(data_names): \n",
    "\n",
    "    data_directory = f'./Plots/{data}'\n",
    "    file_path = f'{data_directory}/{data}.txt'\n",
    "    os.makedirs(data_directory, exist_ok=True)\n",
    "    pdf_name = './Plots/'+data+'/Testing'+data+'.pdf'\n",
    "\n",
    "    '''\n",
    "    Get the Graph from Edge_List and get the labels\n",
    "    '''\n",
    "    G, label= data_to_graph(data)\n",
    "    \n",
    "    True_num_of_clusters = len(set(label))\n",
    "    \n",
    "\n",
    "    cluster_sizes = defaultdict(int)\n",
    "    for node in G.nodes():\n",
    "        cluster_sizes[label[node]]+=1\n",
    "\n",
    "    '''\n",
    "    Add self loops to the nodes with no outgoing edges\n",
    "    '''\n",
    "    G_ = G.copy()\n",
    "    for node in G_.nodes():\n",
    "        if not list(G_.successors(node)):\n",
    "            G_.add_edge(node, node, weight=1)\n",
    "\n",
    "    '''\n",
    "    dictionary for exporting to excel\n",
    "    '''\n",
    "    data_for_excel = defaultdict(lambda: defaultdict(int)) #nested dictionary to store data for plots\n",
    "    data_for_excel['data_idx'] = data_idx\n",
    "    data_for_excel['data_name'] = data\n",
    "    #data_for_excel['fr_tp'] = FR_tp\n",
    "    data_for_excel['fr_tp']=['FL']\n",
    "    data_for_excel['res_list'] = resolution_list\n",
    "    data_for_excel['method_idx'] = 0\n",
    "    data_for_excel['method_name'] = 'Louv_baseline'\n",
    "    data_for_excel['num_comm'] = True_num_of_clusters\n",
    "\n",
    "    for Num_hop in [1]:\n",
    "        #List of FR_values\n",
    "        FR_precalculated = []\n",
    "        for fr_type in range(4): \n",
    "            '''\n",
    "            Calculate FlowRank for the whole graph\n",
    "            '''\n",
    "            if Num_hop==0:\n",
    "                node2FR = calc_FlowRank(G_, fr_type, 5)\n",
    "            else:\n",
    "                node2FR = calc_FlowRank(G_, fr_type, np.log2(G.number_of_nodes()))\n",
    "            FR_precalculated.append(node2FR)\n",
    "\n",
    "        for idx, res in enumerate(resolution_list):\n",
    "            for Mod_type in [0]:\n",
    "                ''' \n",
    "                Louvain on G (baseline)\n",
    "                '''\n",
    "                label_, NMI_, Purity_ = do_Louvain(G, G, res, 0, label)\n",
    "                Num_Cluster_Louv_on_G = len(set(label_))\n",
    "                \n",
    "                data_for_excel[res]['FL'] = [round(NMI_,2), round(Purity_,2), '100%', Num_Cluster_Louv_on_G]\n",
    "    write_to_excel(data_for_excel, 'results.xlsx', 'results')\n",
    "    \n",
    "        \n",
    "            \n",
    "\n",
    "                                \n",
    "                    \n",
    "\n",
    "                    \n",
    "                    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leiden baseline (idx: 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Cust_Top as Cust\n",
    "import networkx.algorithms.community.louvain as Louv\n",
    "from sklearn.metrics.cluster import normalized_mutual_info_score as NMI\n",
    "from collections import deque\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import os\n",
    "from subgraph import * \n",
    "import debug\n",
    "from collections import defaultdict\n",
    "import leidenalg as la \n",
    "\n",
    "#data_names = ['Zhengmix8eq','mRNA','miRNA','FashionMNIST','MNIST','seeds','breast-cancer','Omniglot','bbc_news','20NewsGroups_tfdif','biorxiv','big_patent','Cora','Cora full','Citeseer','Eu core']\n",
    "#data_names = ['ALM', 'AMB', 'Baron_Human', 'Baron_Mouse', 'Muraro', 'Segerstolpe', 'Tcell-medicine', 'TM', 'VISP', 'Xin', 'Zheng']\n",
    "#data_names = ['Zhengmix8eq']\n",
    "data_names = ['Zhengmix8eq','mRNA','miRNA','FashionMNIST','MNIST','seeds','breast-cancer','Omniglot','bbc_news','20NewsGroups_tfdif','biorxiv','big_patent','Cora','Cora full','Citeseer','Eu core','ALM', 'AMB', 'Baron_Human', 'Baron_Mouse', 'Muraro', 'Segerstolpe', 'Tcell-medicine', 'TM', 'VISP', 'Xin', 'Zheng']\n",
    "\n",
    "'''\n",
    "datasets with nodes that have no outgoing edges : \n",
    "['Cora full', 'Citeseer', 'Eu core']\n",
    "'''\n",
    "\n",
    "FR_tp = ['FL','FL_ng','FL_ng_pr','PageRank']\n",
    "FR_tp_short = ['FL','FL_ng','FL_ng_p','PR']\n",
    "Num_hops = {0:'5',1:'log(n)'}\n",
    "\n",
    "#top k% nodes for induced subgraph\n",
    "k=0.2\n",
    "resolution_list = [0.05, 0.5, 1, 1.5, 5, 50]\n",
    "\n",
    "for data_idx, data in enumerate(data_names): \n",
    "\n",
    "    data_directory = f'./Plots/{data}'\n",
    "    file_path = f'{data_directory}/{data}.txt'\n",
    "    os.makedirs(data_directory, exist_ok=True)\n",
    "    pdf_name = './Plots/'+data+'/Testing'+data+'.pdf'\n",
    "\n",
    "    '''\n",
    "    Get the Graph from Edge_List and get the labels\n",
    "    '''\n",
    "    G, label= data_to_graph(data)\n",
    "\n",
    "    True_num_of_clusters = len(set(label))\n",
    "    \n",
    "\n",
    "    cluster_sizes = defaultdict(int)\n",
    "    for node in G.nodes():\n",
    "        cluster_sizes[label[node]]+=1\n",
    "\n",
    "    '''\n",
    "    Add self loops to the nodes with no outgoing edges\n",
    "    '''\n",
    "    G_ = G.copy()\n",
    "    for node in G_.nodes():\n",
    "        if not list(G_.successors(node)):\n",
    "            G_.add_edge(node, node, weight=1)\n",
    "\n",
    "    '''\n",
    "    dictionary for exporting to excel\n",
    "    '''\n",
    "    data_for_excel = defaultdict(lambda: defaultdict(int)) #nested dictionary to store data for plots\n",
    "    data_for_excel['data_idx'] = data_idx\n",
    "    data_for_excel['data_name'] = data\n",
    "    #data_for_excel['fr_tp'] = FR_tp\n",
    "    data_for_excel['fr_tp']=['FL']\n",
    "    data_for_excel['res_list'] = resolution_list\n",
    "    data_for_excel['method_idx'] = 1\n",
    "    data_for_excel['method_name'] = 'Leiden_baseline'\n",
    "    data_for_excel['num_comm'] = True_num_of_clusters\n",
    "\n",
    "    for Num_hop in [1]:\n",
    "        #List of FR_values\n",
    "        FR_precalculated = []\n",
    "        for fr_type in range(4): \n",
    "            '''\n",
    "            Calculate FlowRank for the whole graph\n",
    "            '''\n",
    "            if Num_hop==0:\n",
    "                node2FR = calc_FlowRank(G_, fr_type, 5)\n",
    "            else:\n",
    "                node2FR = calc_FlowRank(G_, fr_type, np.log2(G.number_of_nodes()))\n",
    "            FR_precalculated.append(node2FR)\n",
    "\n",
    "        for idx, res in enumerate(resolution_list):\n",
    "            for Mod_type in [0]:\n",
    "                '''\n",
    "                Leiden on G (Baseline)\n",
    "                '''\n",
    "                label_, NMI_, Purity_ = do_Leiden(G, G, res, 0, label)\n",
    "                Num_Cluster_Leiden_on_G = len(set(label_))\n",
    "                \n",
    "                data_for_excel[res]['FL'] = [round(NMI_,2), round(Purity_,2), '100%', Num_Cluster_Leiden_on_G]\n",
    "    write_to_excel(data_for_excel, 'results.xlsx', 'results')\n",
    "    \n",
    "        \n",
    "            \n",
    "\n",
    "                                \n",
    "                    \n",
    "\n",
    "                    \n",
    "                    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leiden + Majority vote (One round) (2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Cust_Top as Cust\n",
    "import networkx.algorithms.community.louvain as Louv\n",
    "from sklearn.metrics.cluster import normalized_mutual_info_score as NMI\n",
    "from collections import deque\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import os\n",
    "from subgraph import * \n",
    "import debug\n",
    "from collections import defaultdict\n",
    "import leidenalg as la \n",
    "\n",
    "#data_names = ['Zhengmix8eq','mRNA','miRNA','FashionMNIST','MNIST','seeds','breast-cancer','Omniglot','bbc_news','20NewsGroups_tfdif','biorxiv','big_patent','Cora','Cora full','Citeseer','Eu core']\n",
    "#data_names = ['ALM', 'AMB', 'Baron_Human', 'Baron_Mouse', 'Muraro', 'Segerstolpe', 'Tcell-medicine', 'TM', 'VISP', 'Xin', 'Zheng']\n",
    "#data_names = ['Zhengmix8eq']\n",
    "data_names = ['Zhengmix8eq','mRNA','miRNA','FashionMNIST','MNIST','seeds','breast-cancer','Omniglot','bbc_news','20NewsGroups_tfdif','biorxiv','big_patent','Cora','Cora full','Citeseer','Eu core','ALM', 'AMB', 'Baron_Human', 'Baron_Mouse', 'Muraro', 'Segerstolpe', 'Tcell-medicine', 'TM', 'VISP', 'Xin', 'Zheng']\n",
    "\n",
    "'''\n",
    "datasets with nodes that have no outgoing edges : \n",
    "['Cora full', 'Citeseer', 'Eu core']\n",
    "'''\n",
    "\n",
    "FR_tp = ['FL','FL_ng','FL_ng_pr','PageRank']\n",
    "FR_tp_short = ['FL','FL_ng','FL_ng_p','PR']\n",
    "Num_hops = {0:'5',1:'log(n)'}\n",
    "\n",
    "#top k% nodes for induced subgraph\n",
    "k=0.2\n",
    "resolution_list = [0.05, 0.5, 1, 1.5, 5, 50]\n",
    "\n",
    "for data_idx, data in enumerate(data_names): \n",
    "\n",
    "    data_directory = f'./Plots/{data}'\n",
    "    file_path = f'{data_directory}/{data}.txt'\n",
    "    os.makedirs(data_directory, exist_ok=True)\n",
    "    pdf_name = './Plots/'+data+'/Testing'+data+'.pdf'\n",
    "\n",
    "    '''\n",
    "    Get the Graph from Edge_List and get the labels\n",
    "    '''\n",
    "    G, label= data_to_graph(data)\n",
    "\n",
    "    True_num_of_clusters = len(set(label))\n",
    "    \n",
    "\n",
    "    cluster_sizes = defaultdict(int)\n",
    "    for node in G.nodes():\n",
    "        cluster_sizes[label[node]]+=1\n",
    "\n",
    "    '''\n",
    "    Add self loops to the nodes with no outgoing edges\n",
    "    '''\n",
    "    G_ = G.copy()\n",
    "    for node in G_.nodes():\n",
    "        if not list(G_.successors(node)):\n",
    "            G_.add_edge(node, node, weight=1)\n",
    "\n",
    "    '''\n",
    "    dictionary for exporting to excel\n",
    "    '''\n",
    "    data_for_excel = defaultdict(lambda: defaultdict(int)) #nested dictionary to store data for plots\n",
    "    data_for_excel['data_idx'] = data_idx\n",
    "    data_for_excel['data_name'] = data\n",
    "    data_for_excel['fr_tp'] = FR_tp\n",
    "    #data_for_excel['fr_tp']=['FL']\n",
    "    data_for_excel['res_list'] = resolution_list\n",
    "    data_for_excel['method_idx'] = 2\n",
    "    data_for_excel['method_name'] = 'Leiden + Vote(1_Round)'\n",
    "    data_for_excel['num_comm'] = True_num_of_clusters\n",
    "\n",
    "    for Num_hop in [1]:\n",
    "        #List of FR_values\n",
    "        FR_precalculated = []\n",
    "        for fr_type in range(4): \n",
    "            '''\n",
    "            Calculate FlowRank for the whole graph\n",
    "            '''\n",
    "            if Num_hop==0:\n",
    "                node2FR = calc_FlowRank(G_, fr_type, 5)\n",
    "            else:\n",
    "                node2FR = calc_FlowRank(G_, fr_type, np.log2(G.number_of_nodes()))\n",
    "            FR_precalculated.append(node2FR)\n",
    "\n",
    "        for idx, res in enumerate(resolution_list):\n",
    "            for Mod_type in [0]:\n",
    "\n",
    "                for FR_type in range(4):\n",
    "                    \n",
    "                    '''\n",
    "                    Get induced subgraph of top k% nodes in FR value\n",
    "                    '''\n",
    "                    node2FR = FR_precalculated[FR_type]\n",
    "                    node_list = sorted(G.nodes, key=lambda x: node2FR[x], reverse=True)\n",
    "                    \n",
    "                    k_ = int(k*len(node_list))\n",
    "                    top_nodes = node_list[:k_]\n",
    "                    nodes_rest = node_list[k_:]\n",
    "                    H = getInducedSubgraph(G, top_nodes) # H = induced subgraph\n",
    "                    \n",
    "                    '''\n",
    "                    label counts for balancedness calculation\n",
    "                    '''\n",
    "                    selected_labels_dict = defaultdict(int)\n",
    "                    for node in H.nodes():\n",
    "                        selected_labels_dict[label[node]]+=1\n",
    "                    \n",
    "                    '''\n",
    "                    Leiden on the subgraph H \n",
    "                    '''\n",
    "                    H_label, _, _ = do_Leiden(H, G, res, 0, label)\n",
    "                    \n",
    "                    Num_Cluster_Leid_on_H = len({x for x in set(H_label) if x != -1})\n",
    "                    \n",
    "                    '''\n",
    "                    Add nodes to the subgraph by strong majority vote\n",
    "                    '''\n",
    "                    NMI_List, Purity_List, Balance_List, Preserv_List, InEdge_List = merge_by_vote(top_nodes, nodes_rest, H_label, G, label, selected_labels_dict, cluster_sizes, one_round=True)\n",
    "                    selected_node_num = len([x for x in H_label if x != -1])\n",
    "                    selected_node_percent = str(round(selected_node_num*100/(G.number_of_nodes()),2))+'%' \n",
    "                    data_for_excel[res][FR_tp[FR_type]] = [round(NMI_List[-1],2), round(Purity_List[-1],2), selected_node_percent, Num_Cluster_Leid_on_H]\n",
    "                    \n",
    "                    \n",
    "    write_to_excel(data_for_excel, 'results.xlsx', 'results')\n",
    "    \n",
    "        \n",
    "            \n",
    "\n",
    "                                \n",
    "                    \n",
    "\n",
    "                    \n",
    "                    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leiden + Majority vote (3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Cust_Top as Cust\n",
    "import networkx.algorithms.community.louvain as Louv\n",
    "from sklearn.metrics.cluster import normalized_mutual_info_score as NMI\n",
    "from collections import deque\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import os\n",
    "from subgraph import * \n",
    "import debug\n",
    "from collections import defaultdict\n",
    "import leidenalg as la \n",
    "\n",
    "#data_names = ['Zhengmix8eq','mRNA','miRNA','FashionMNIST','MNIST','seeds','breast-cancer','Omniglot','bbc_news','20NewsGroups_tfdif','biorxiv','big_patent','Cora','Cora full','Citeseer','Eu core']\n",
    "#data_names = ['ALM', 'AMB', 'Baron_Human', 'Baron_Mouse', 'Muraro', 'Segerstolpe', 'Tcell-medicine', 'TM', 'VISP', 'Xin', 'Zheng']\n",
    "#data_names = ['Zhengmix8eq']\n",
    "data_names = ['Zhengmix8eq','mRNA','miRNA','FashionMNIST','MNIST','seeds','breast-cancer','Omniglot','bbc_news','20NewsGroups_tfdif','biorxiv','big_patent','Cora','Cora full','Citeseer','Eu core','ALM', 'AMB', 'Baron_Human', 'Baron_Mouse', 'Muraro', 'Segerstolpe', 'Tcell-medicine', 'TM', 'VISP', 'Xin', 'Zheng']\n",
    "\n",
    "'''\n",
    "datasets with nodes that have no outgoing edges : \n",
    "['Cora full', 'Citeseer', 'Eu core']\n",
    "'''\n",
    "\n",
    "FR_tp = ['FL','FL_ng','FL_ng_pr','PageRank']\n",
    "FR_tp_short = ['FL','FL_ng','FL_ng_p','PR']\n",
    "Num_hops = {0:'5',1:'log(n)'}\n",
    "\n",
    "#top k% nodes for induced subgraph\n",
    "k=0.2\n",
    "resolution_list = [0.05, 0.5, 1, 1.5, 5, 50]\n",
    "\n",
    "for data_idx, data in enumerate(data_names): \n",
    "\n",
    "    data_directory = f'./Plots/{data}'\n",
    "    file_path = f'{data_directory}/{data}.txt'\n",
    "    os.makedirs(data_directory, exist_ok=True)\n",
    "    pdf_name = './Plots/'+data+'/Testing'+data+'.pdf'\n",
    "\n",
    "    '''\n",
    "    Get the Graph from Edge_List and get the labels\n",
    "    '''\n",
    "    G, label= data_to_graph(data)\n",
    "\n",
    "    True_num_of_clusters = len(set(label))\n",
    "    \n",
    "\n",
    "    cluster_sizes = defaultdict(int)\n",
    "    for node in G.nodes():\n",
    "        cluster_sizes[label[node]]+=1\n",
    "\n",
    "    '''\n",
    "    Add self loops to the nodes with no outgoing edges\n",
    "    '''\n",
    "    G_ = G.copy()\n",
    "    for node in G_.nodes():\n",
    "        if not list(G_.successors(node)):\n",
    "            G_.add_edge(node, node, weight=1)\n",
    "\n",
    "    '''\n",
    "    dictionary for exporting to excel\n",
    "    '''\n",
    "    data_for_excel = defaultdict(lambda: defaultdict(int)) #nested dictionary to store data for plots\n",
    "    data_for_excel['data_idx'] = data_idx\n",
    "    data_for_excel['data_name'] = data\n",
    "    data_for_excel['fr_tp'] = FR_tp\n",
    "    #data_for_excel['fr_tp']=['FL']\n",
    "    data_for_excel['res_list'] = resolution_list\n",
    "    data_for_excel['method_idx'] = 3\n",
    "    data_for_excel['method_name'] = 'Leiden + Vote'\n",
    "    data_for_excel['num_comm'] = True_num_of_clusters\n",
    "\n",
    "    for Num_hop in [1]:\n",
    "        #List of FR_values\n",
    "        FR_precalculated = []\n",
    "        for fr_type in range(4): \n",
    "            '''\n",
    "            Calculate FlowRank for the whole graph\n",
    "            '''\n",
    "            if Num_hop==0:\n",
    "                node2FR = calc_FlowRank(G_, fr_type, 5)\n",
    "            else:\n",
    "                node2FR = calc_FlowRank(G_, fr_type, np.log2(G.number_of_nodes()))\n",
    "            FR_precalculated.append(node2FR)\n",
    "\n",
    "        for idx, res in enumerate(resolution_list):\n",
    "            for Mod_type in [0]:\n",
    "\n",
    "                for FR_type in range(4):\n",
    "                    \n",
    "                    '''\n",
    "                    Get induced subgraph of top k% nodes in FR value\n",
    "                    '''\n",
    "                    node2FR = FR_precalculated[FR_type]\n",
    "                    node_list = sorted(G.nodes, key=lambda x: node2FR[x], reverse=True)\n",
    "                    \n",
    "                    k_ = int(k*len(node_list))\n",
    "                    top_nodes = node_list[:k_]\n",
    "                    nodes_rest = node_list[k_:]\n",
    "                    H = getInducedSubgraph(G, top_nodes) # H = induced subgraph\n",
    "                    \n",
    "                    '''\n",
    "                    label counts for balancedness calculation\n",
    "                    '''\n",
    "                    selected_labels_dict = defaultdict(int)\n",
    "                    for node in H.nodes():\n",
    "                        selected_labels_dict[label[node]]+=1\n",
    "                    \n",
    "                    '''\n",
    "                    Leiden on the subgraph H \n",
    "                    '''\n",
    "                    H_label, _, _ = do_Leiden(H, G, res, 0, label)\n",
    "                    \n",
    "                    Num_Cluster_Leid_on_H = len({x for x in set(H_label) if x != -1})\n",
    "                    \n",
    "                    '''\n",
    "                    Add nodes to the subgraph by strong majority vote\n",
    "                    '''\n",
    "                    NMI_List, Purity_List, Balance_List, Preserv_List, InEdge_List = merge_by_vote(top_nodes, nodes_rest, H_label, G, label, selected_labels_dict, cluster_sizes)\n",
    "                    selected_node_num = len([x for x in H_label if x != -1])\n",
    "                    selected_node_percent = str(round(selected_node_num*100/(G.number_of_nodes()),2))+'%' \n",
    "                    data_for_excel[res][FR_tp[FR_type]] = [round(NMI_List[-1],2), round(Purity_List[-1],2), selected_node_percent, Num_Cluster_Leid_on_H]\n",
    "                    \n",
    "                    \n",
    "    write_to_excel(data_for_excel, 'results.xlsx', 'results')\n",
    "    \n",
    "        \n",
    "            \n",
    "\n",
    "                                \n",
    "                    \n",
    "\n",
    "                    \n",
    "                    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leiden + Majority vote + Leiden (4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Cust_Top as Cust\n",
    "import networkx.algorithms.community.louvain as Louv\n",
    "from sklearn.metrics.cluster import normalized_mutual_info_score as NMI\n",
    "from collections import deque\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import os\n",
    "from subgraph import * \n",
    "import debug\n",
    "from collections import defaultdict\n",
    "import leidenalg as la \n",
    "\n",
    "#data_names = ['Zhengmix8eq','mRNA','miRNA','FashionMNIST','MNIST','seeds','breast-cancer','Omniglot','bbc_news','20NewsGroups_tfdif','biorxiv','big_patent','Cora','Cora full','Citeseer','Eu core']\n",
    "#data_names = ['ALM', 'AMB', 'Baron_Human', 'Baron_Mouse', 'Muraro', 'Segerstolpe', 'Tcell-medicine', 'TM', 'VISP', 'Xin', 'Zheng']\n",
    "#data_names = ['Zhengmix8eq']\n",
    "data_names = ['Zhengmix8eq','mRNA','miRNA','FashionMNIST','MNIST','seeds','breast-cancer','Omniglot','bbc_news','20NewsGroups_tfdif','biorxiv','big_patent','Cora','Cora full','Citeseer','Eu core','ALM', 'AMB', 'Baron_Human', 'Baron_Mouse', 'Muraro', 'Segerstolpe', 'Tcell-medicine', 'TM', 'VISP', 'Xin', 'Zheng']\n",
    "\n",
    "'''\n",
    "datasets with nodes that have no outgoing edges : \n",
    "['Cora full', 'Citeseer', 'Eu core']\n",
    "'''\n",
    "\n",
    "FR_tp = ['FL','FL_ng','FL_ng_pr','PageRank']\n",
    "FR_tp_short = ['FL','FL_ng','FL_ng_p','PR']\n",
    "Num_hops = {0:'5',1:'log(n)'}\n",
    "\n",
    "#top k% nodes for induced subgraph\n",
    "k=0.2\n",
    "resolution_list = [0.05, 0.5, 1, 1.5, 5, 50]\n",
    "\n",
    "for data_idx, data in enumerate(data_names): \n",
    "\n",
    "    data_directory = f'./Plots/{data}'\n",
    "    file_path = f'{data_directory}/{data}.txt'\n",
    "    os.makedirs(data_directory, exist_ok=True)\n",
    "    pdf_name = './Plots/'+data+'/Testing'+data+'.pdf'\n",
    "\n",
    "    '''\n",
    "    Get the Graph from Edge_List and get the labels\n",
    "    '''\n",
    "    G, label= data_to_graph(data)\n",
    "\n",
    "    True_num_of_clusters = len(set(label))\n",
    "    \n",
    "\n",
    "    cluster_sizes = defaultdict(int)\n",
    "    for node in G.nodes():\n",
    "        cluster_sizes[label[node]]+=1\n",
    "\n",
    "    '''\n",
    "    Add self loops to the nodes with no outgoing edges\n",
    "    '''\n",
    "    G_ = G.copy()\n",
    "    for node in G_.nodes():\n",
    "        if not list(G_.successors(node)):\n",
    "            G_.add_edge(node, node, weight=1)\n",
    "\n",
    "    '''\n",
    "    dictionary for exporting to excel\n",
    "    '''\n",
    "    data_for_excel = defaultdict(lambda: defaultdict(int)) #nested dictionary to store data for plots\n",
    "    data_for_excel['data_idx'] = data_idx\n",
    "    data_for_excel['data_name'] = data\n",
    "    data_for_excel['fr_tp'] = FR_tp\n",
    "    #data_for_excel['fr_tp']=['FL']\n",
    "    data_for_excel['res_list'] = resolution_list\n",
    "    data_for_excel['method_idx'] = 4\n",
    "    data_for_excel['method_name'] = 'Leiden + Vote + Leiden'\n",
    "    data_for_excel['num_comm'] = True_num_of_clusters\n",
    "\n",
    "    for Num_hop in [1]:\n",
    "        #List of FR_values\n",
    "        FR_precalculated = []\n",
    "        for fr_type in range(4): \n",
    "            '''\n",
    "            Calculate FlowRank for the whole graph\n",
    "            '''\n",
    "            if Num_hop==0:\n",
    "                node2FR = calc_FlowRank(G_, fr_type, 5)\n",
    "            else:\n",
    "                node2FR = calc_FlowRank(G_, fr_type, np.log2(G.number_of_nodes()))\n",
    "            FR_precalculated.append(node2FR)\n",
    "\n",
    "        for idx, res in enumerate(resolution_list):\n",
    "            for Mod_type in [0]:\n",
    "\n",
    "                for FR_type in range(4):\n",
    "                    \n",
    "                    '''\n",
    "                    Get induced subgraph of top k% nodes in FR value\n",
    "                    '''\n",
    "                    node2FR = FR_precalculated[FR_type]\n",
    "                    node_list = sorted(G.nodes, key=lambda x: node2FR[x], reverse=True)\n",
    "                    \n",
    "                    k_ = int(k*len(node_list))\n",
    "                    top_nodes = node_list[:k_]\n",
    "                    nodes_rest = node_list[k_:]\n",
    "                    H = getInducedSubgraph(G, top_nodes) # H = induced subgraph\n",
    "                    \n",
    "                    '''\n",
    "                    label counts for balancedness calculation\n",
    "                    '''\n",
    "                    selected_labels_dict = defaultdict(int)\n",
    "                    for node in H.nodes():\n",
    "                        selected_labels_dict[label[node]]+=1\n",
    "                    \n",
    "                    '''\n",
    "                    Leiden on the subgraph H \n",
    "                    '''\n",
    "                    H_label, _, _ = do_Leiden(H, G, res, 0, label)\n",
    "                    \n",
    "                    Num_Cluster_Leid_on_H = len({x for x in set(H_label) if x != -1})\n",
    "                    \n",
    "                    '''\n",
    "                    Add nodes to the subgraph by strong majority vote\n",
    "                    '''\n",
    "                    NMI_List, Purity_List, Balance_List, Preserv_List, InEdge_List = merge_by_vote(top_nodes, nodes_rest, H_label, G, label, selected_labels_dict, cluster_sizes)\n",
    "                    selected_node_num = len([x for x in H_label if x != -1])\n",
    "                    selected_node_percent = str(round(selected_node_num*100/(G.number_of_nodes()),2))+'%' \n",
    "                    \n",
    "                    '''\n",
    "                    Leiden again on the vote subgraph\n",
    "                    '''\n",
    "                    selected_node_list = [node_num_ for node_num_, node_label_ in enumerate(H_label) if node_label_ != -1]\n",
    "                    H2 = getInducedSubgraph(G, selected_node_list)\n",
    "                    H2_ig, ig_to_nx, nx_to_ig = networkx_to_igraph(H2) # Mapping = igraph index to networkx index\n",
    "                    initial_membership = [H_label[ig_to_nx[i]] for i in list(H2_ig.vs.indices)]\n",
    "                    partition2_ = la.find_partition(H2_ig, la.RBConfigurationVertexPartition, initial_membership = initial_membership, n_iterations=-1, resolution_parameter=res, seed=0)\n",
    "                    H_label2 = part_to_full_label(partition2_, G.number_of_nodes(), ig_to_nx)\n",
    "                    \n",
    "                    label_compressed2, H_label_compressed2 = get_compressed_labels(label,H_label2, selected_node_list)\n",
    "                    NMI_louv_vote_louv = NMI(H_label_compressed2, label_compressed2)\n",
    "                    Purity_louv_vote_louv = met.purity_score(label_compressed2, H_label_compressed2)\n",
    "                    Num_Cluster_Leid_on_H2 = len({x for x in set(H_label2) if x != -1})\n",
    "                    \n",
    "                    \n",
    "                    data_for_excel[res][FR_tp[FR_type]] = [round(NMI_louv_vote_louv,2), round(Purity_louv_vote_louv,2), selected_node_percent, Num_Cluster_Leid_on_H2]\n",
    "                    \n",
    "                    \n",
    "    write_to_excel(data_for_excel, 'results.xlsx', 'results')\n",
    "    \n",
    "        \n",
    "            \n",
    "\n",
    "                                \n",
    "                    \n",
    "\n",
    "                    \n",
    "                    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leiden + Vote + Leiden + Vote (5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Cust_Top as Cust\n",
    "import networkx.algorithms.community.louvain as Louv\n",
    "from sklearn.metrics.cluster import normalized_mutual_info_score as NMI\n",
    "from collections import deque\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import os\n",
    "from subgraph import * \n",
    "import debug\n",
    "from collections import defaultdict\n",
    "import leidenalg as la \n",
    "\n",
    "#data_names = ['Zhengmix8eq','mRNA','miRNA','FashionMNIST','MNIST','seeds','breast-cancer','Omniglot','bbc_news','20NewsGroups_tfdif','biorxiv','big_patent','Cora','Cora full','Citeseer','Eu core']\n",
    "#data_names = ['ALM', 'AMB', 'Baron_Human', 'Baron_Mouse', 'Muraro', 'Segerstolpe', 'Tcell-medicine', 'TM', 'VISP', 'Xin', 'Zheng']\n",
    "#data_names = ['Zhengmix8eq']\n",
    "data_names = ['Zhengmix8eq','mRNA','miRNA','FashionMNIST','MNIST','seeds','breast-cancer','Omniglot','bbc_news','20NewsGroups_tfdif','biorxiv','big_patent','Cora','Cora full','Citeseer','Eu core','ALM', 'AMB', 'Baron_Human', 'Baron_Mouse', 'Muraro', 'Segerstolpe', 'Tcell-medicine', 'TM', 'VISP', 'Xin', 'Zheng']\n",
    "\n",
    "'''\n",
    "datasets with nodes that have no outgoing edges : \n",
    "['Cora full', 'Citeseer', 'Eu core']\n",
    "'''\n",
    "\n",
    "FR_tp = ['FL','FL_ng','FL_ng_pr','PageRank']\n",
    "FR_tp_short = ['FL','FL_ng','FL_ng_p','PR']\n",
    "Num_hops = {0:'5',1:'log(n)'}\n",
    "\n",
    "#top k% nodes for induced subgraph\n",
    "k=0.2\n",
    "resolution_list = [0.05, 0.5, 1, 1.5, 5, 50]\n",
    "\n",
    "for data_idx, data in enumerate(data_names): \n",
    "\n",
    "    data_directory = f'./Plots/{data}'\n",
    "    file_path = f'{data_directory}/{data}.txt'\n",
    "    os.makedirs(data_directory, exist_ok=True)\n",
    "    pdf_name = './Plots/'+data+'/Testing'+data+'.pdf'\n",
    "\n",
    "    '''\n",
    "    Get the Graph from Edge_List and get the labels\n",
    "    '''\n",
    "    G, label= data_to_graph(data)\n",
    "\n",
    "    True_num_of_clusters = len(set(label))\n",
    "    \n",
    "\n",
    "    cluster_sizes = defaultdict(int)\n",
    "    for node in G.nodes():\n",
    "        cluster_sizes[label[node]]+=1\n",
    "\n",
    "    '''\n",
    "    Add self loops to the nodes with no outgoing edges\n",
    "    '''\n",
    "    G_ = G.copy()\n",
    "    for node in G_.nodes():\n",
    "        if not list(G_.successors(node)):\n",
    "            G_.add_edge(node, node, weight=1)\n",
    "\n",
    "    '''\n",
    "    dictionary for exporting to excel\n",
    "    '''\n",
    "    data_for_excel = defaultdict(lambda: defaultdict(int)) #nested dictionary to store data for plots\n",
    "    data_for_excel['data_idx'] = data_idx\n",
    "    data_for_excel['data_name'] = data\n",
    "    data_for_excel['fr_tp'] = FR_tp\n",
    "    #data_for_excel['fr_tp']=['FL']\n",
    "    data_for_excel['res_list'] = resolution_list\n",
    "    data_for_excel['method_idx'] = 5\n",
    "    data_for_excel['method_name'] = '(Leiden + Vote)x2'\n",
    "    data_for_excel['num_comm'] = True_num_of_clusters\n",
    "\n",
    "    for Num_hop in [1]:\n",
    "        #List of FR_values\n",
    "        FR_precalculated = []\n",
    "        for fr_type in range(4): \n",
    "            '''\n",
    "            Calculate FlowRank for the whole graph\n",
    "            '''\n",
    "            if Num_hop==0:\n",
    "                node2FR = calc_FlowRank(G_, fr_type, 5)\n",
    "            else:\n",
    "                node2FR = calc_FlowRank(G_, fr_type, np.log2(G.number_of_nodes()))\n",
    "            FR_precalculated.append(node2FR)\n",
    "\n",
    "        for idx, res in enumerate(resolution_list):\n",
    "            for Mod_type in [0]:\n",
    "\n",
    "                for FR_type in range(4):\n",
    "                    \n",
    "                    '''\n",
    "                    Get induced subgraph of top k% nodes in FR value\n",
    "                    '''\n",
    "                    node2FR = FR_precalculated[FR_type]\n",
    "                    node_list = sorted(G.nodes, key=lambda x: node2FR[x], reverse=True)\n",
    "                    \n",
    "                    k_ = int(k*len(node_list))\n",
    "                    top_nodes = node_list[:k_]\n",
    "                    nodes_rest = node_list[k_:]\n",
    "                    H = getInducedSubgraph(G, top_nodes) # H = induced subgraph\n",
    "                    \n",
    "                    '''\n",
    "                    label counts for balancedness calculation\n",
    "                    '''\n",
    "                    selected_labels_dict = defaultdict(int)\n",
    "                    for node in H.nodes():\n",
    "                        selected_labels_dict[label[node]]+=1\n",
    "                    \n",
    "                    '''\n",
    "                    Leiden on the subgraph H \n",
    "                    '''\n",
    "                    H_label, _, _ = do_Leiden(H, G, res, 0, label)\n",
    "                    \n",
    "                    Num_Cluster_Leid_on_H = len({x for x in set(H_label) if x != -1})\n",
    "                    \n",
    "                    '''\n",
    "                    Add nodes to the subgraph by strong majority vote\n",
    "                    '''\n",
    "                    NMI_List, Purity_List, Balance_List, Preserv_List, InEdge_List = merge_by_vote(top_nodes, nodes_rest, H_label, G, label, selected_labels_dict, cluster_sizes)\n",
    "                    selected_node_num = len([x for x in H_label if x != -1])\n",
    "                    \n",
    "                    \n",
    "                    '''\n",
    "                    Leiden again on the vote subgraph\n",
    "                    '''\n",
    "                    selected_node_list = [node_num_ for node_num_, node_label_ in enumerate(H_label) if node_label_ != -1]\n",
    "                    H2 = getInducedSubgraph(G, selected_node_list)\n",
    "                    H2_ig, ig_to_nx, nx_to_ig = networkx_to_igraph(H2) # Mapping = igraph index to networkx index\n",
    "                    initial_membership = [H_label[ig_to_nx[i]] for i in list(H2_ig.vs.indices)]\n",
    "                    partition2_ = la.find_partition(H2_ig, la.RBConfigurationVertexPartition, initial_membership = initial_membership, n_iterations=-1, resolution_parameter=res, seed=0)\n",
    "                    H_label2 = part_to_full_label(partition2_, G.number_of_nodes(), ig_to_nx)\n",
    "                    \n",
    "                    label_compressed2, H_label_compressed2 = get_compressed_labels(label,H_label2, selected_node_list)\n",
    "                    NMI_louv_vote_louv = NMI(H_label_compressed2, label_compressed2)\n",
    "                    Purity_louv_vote_louv = met.purity_score(label_compressed2, H_label_compressed2)\n",
    "                    Num_Cluster_Leid_on_H2 = len({x for x in set(H_label2) if x != -1})\n",
    "                    \n",
    "                    '''\n",
    "                    Leiden + vote + Leiden + vote\n",
    "                    '''\n",
    "                    nodes_rest2 = [node_num_ for node_num_, node_label_ in enumerate(H_label2) if node_label_ == -1]\n",
    "                    NMI_List2, Purity_List2, Balance_List2, Preserv_List2, InEdge_List2 = merge_by_vote(selected_node_list, nodes_rest2, H_label2, G, label, selected_labels_dict, cluster_sizes)\n",
    "                    selected_node_num2 = len([node_num_ for node_num_, node_label_ in enumerate(H_label2) if node_label_ != -1])\n",
    "                    selected_node_percent = str(round(selected_node_num2*100/(G.number_of_nodes()),2))+'%' \n",
    "\n",
    "                    data_for_excel[res][FR_tp[FR_type]] = [round(NMI_List2[-1],2), round(Purity_List2[-1],2), selected_node_percent, Num_Cluster_Leid_on_H2]\n",
    "                    \n",
    "                    \n",
    "    write_to_excel(data_for_excel, 'results.xlsx', 'results')\n",
    "    \n",
    "        \n",
    "            \n",
    "\n",
    "                                \n",
    "                    \n",
    "\n",
    "                    \n",
    "                    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leiden + Strong Majority Vote + Random Walk (Weak Majority Vote) (idx: 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Cust_Top as Cust\n",
    "import networkx.algorithms.community.louvain as Louv\n",
    "from sklearn.metrics.cluster import normalized_mutual_info_score as NMI\n",
    "from collections import deque\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import os\n",
    "from subgraph import * \n",
    "import debug\n",
    "from collections import defaultdict\n",
    "import leidenalg as la \n",
    "import copy\n",
    "\n",
    "#data_names = ['Zhengmix8eq','mRNA','miRNA','FashionMNIST','MNIST','seeds','breast-cancer','Omniglot','bbc_news','20NewsGroups_tfdif','biorxiv','big_patent','Cora','Cora full','Citeseer','Eu core']\n",
    "#data_names = ['ALM', 'AMB', 'Baron_Human', 'Baron_Mouse', 'Muraro', 'Segerstolpe', 'Tcell-medicine', 'TM', 'VISP', 'Xin', 'Zheng']\n",
    "#data_names = ['Zhengmix8eq']\n",
    "data_names = ['Zhengmix8eq','mRNA','miRNA','FashionMNIST','MNIST','seeds','breast-cancer','Omniglot','bbc_news','20NewsGroups_tfdif','biorxiv','big_patent','Cora','Cora full','Citeseer','Eu core','ALM', 'AMB', 'Baron_Human', 'Baron_Mouse', 'Muraro', 'Segerstolpe', 'Tcell-medicine', 'TM', 'VISP', 'Xin', 'Zheng']\n",
    "\n",
    "'''\n",
    "datasets with nodes that have no outgoing edges : \n",
    "['Cora full', 'Citeseer', 'Eu core']\n",
    "'''\n",
    "\n",
    "FR_tp = ['FL','FL_ng','FL_ng_pr','PageRank']\n",
    "FR_tp_short = ['FL','FL_ng','FL_ng_p','PR']\n",
    "Num_hops = {0:'5',1:'log(n)'}\n",
    "\n",
    "#top k% nodes for induced subgraph\n",
    "k=0.2\n",
    "resolution_list = [0.05,0.25, 0.5, 1, 1.5, 5]\n",
    "\n",
    "for data_idx, data in enumerate(data_names): \n",
    "    data_directory = f'./Plots/{data}'\n",
    "    file_path = f'{data_directory}/{data}.txt'\n",
    "    os.makedirs(data_directory, exist_ok=True)\n",
    "    pdf_name = './Plots/'+data+'/(Vote+RandWalk)'+data+'.pdf'\n",
    "    data_for_plot = defaultdict(lambda: defaultdict(dict)) #nested dictionary to store data for plots\n",
    "\n",
    "    '''\n",
    "    Get the Graph from Edge_List and get the labels\n",
    "    '''\n",
    "    G, label= data_to_graph(data)\n",
    "\n",
    "    True_num_of_clusters = len(set(label))\n",
    "    cluster_sizes = defaultdict(int)\n",
    "    for node in G.nodes():\n",
    "        cluster_sizes[label[node]]+=1\n",
    "\n",
    "    '''\n",
    "    dictionary for exporting to excel\n",
    "    '''\n",
    "    data_for_excel = defaultdict(lambda: defaultdict(int)) #nested dictionary to store data for plots\n",
    "    data_for_excel['data_idx'] = data_idx\n",
    "    data_for_excel['data_name'] = data\n",
    "    data_for_excel['fr_tp'] = FR_tp\n",
    "    #data_for_excel['fr_tp']=['FL']\n",
    "    data_for_excel['res_list'] = resolution_list\n",
    "    data_for_excel['method_idx'] = 6\n",
    "    data_for_excel['method_name'] = 'Leiden_Vote_RW(weak_vote)'\n",
    "    data_for_excel['num_comm'] = True_num_of_clusters\n",
    "\n",
    "    '''\n",
    "    Add self loops to the nodes with no outgoing edges\n",
    "    '''\n",
    "    G_ = copy.deepcopy(G)\n",
    "    for node in G_.nodes():\n",
    "        if not list(G_.successors(node)):\n",
    "            G_.add_edge(node, node, weight=1)\n",
    "    print('Number of nodes:',G.number_of_nodes())\n",
    "\n",
    "    for Num_hop in [1]:\n",
    "        #List of FR_values\n",
    "        FR_precalculated = []\n",
    "        for fr_type in range(4): \n",
    "            '''\n",
    "            Calculate FlowRank for the whole graph\n",
    "            '''\n",
    "            if Num_hop==0:\n",
    "                node2FR = calc_FlowRank(G_, fr_type, 5)\n",
    "            else:\n",
    "                node2FR = calc_FlowRank(G_, fr_type, np.log2(G.number_of_nodes()))\n",
    "            FR_precalculated.append(node2FR)\n",
    "\n",
    "        for idx, res in enumerate(resolution_list):\n",
    "            for Mod_type in [0]:\n",
    "                ''' \n",
    "                Louvain on G (baseline)\n",
    "                '''\n",
    "                label_, NMI_, Purity_ = do_Louvain(G, G, res, 0, label)\n",
    "                Num_Cluster_Louv_on_G = len(set(label_))\n",
    "\n",
    "                '''\n",
    "                Leiden on G (Baseline)\n",
    "                '''\n",
    "                label_, NMI_baseline_leiden, Purity_baseline_leiden = do_Leiden(G, G, res, 0, label)\n",
    "                Num_Cluster_Leiden_on_G = len(set(label_))\n",
    "\n",
    "                for FR_type in range(4):\n",
    "                    \n",
    "                    '''\n",
    "                    Get induced subgraph of top k% nodes in FR value\n",
    "                    '''\n",
    "                    node2FR = FR_precalculated[FR_type]\n",
    "                    node_list = sorted(G.nodes, key=lambda x: node2FR[x], reverse=True)\n",
    "                    \n",
    "                    k_ = int(k*len(node_list))\n",
    "                    top_nodes = node_list[:k_]\n",
    "                    nodes_rest = node_list[k_:]\n",
    "                    H = getInducedSubgraph(G, top_nodes) # H = induced subgraph\n",
    "                    \n",
    "                    '''\n",
    "                    label counts for balancedness calculation\n",
    "                    '''\n",
    "                    selected_labels_dict = defaultdict(int)\n",
    "                    for node in H.nodes():\n",
    "                        selected_labels_dict[label[node]]+=1\n",
    "                    \n",
    "                    '''\n",
    "                    Leiden on the subgraph H \n",
    "                    '''\n",
    "                    H_label, _, _ = do_Leiden(H, G, res, 0, label)\n",
    "                    \n",
    "                    Num_Cluster_Louv_on_H = len({x for x in set(H_label) if x != -1})\n",
    "                    '''\n",
    "                    Add nodes to the subgraph by strong majority vote\n",
    "                    '''\n",
    "                    NMI_List, Purity_List, Balance_List, Preserv_List, InEdge_List = merge_by_vote(top_nodes, nodes_rest, H_label, G, label, selected_labels_dict, cluster_sizes)\n",
    "                    # list of unselected_nodes\n",
    "                    unselected_nodes = [node_idx for node_idx, node_label in enumerate(H_label) if node_label == -1]\n",
    "                    selected_node_num = G.number_of_nodes() - len(unselected_nodes)\n",
    "                    '''\n",
    "                    Random walks from unselected nodes\n",
    "                    '''\n",
    "                    H_label, NMI_rand_walk, Purity_rand_walk = do_random_walks(G, unselected_nodes, label, H_label, node2FR, walk_len=10, walk_rep = 100) \n",
    "                    selected_node_num2 = len([x for x in H_label if x != -1])\n",
    "                    selected_node_percent = str(round(selected_node_num*100/(G.number_of_nodes()),2))+'%'\n",
    "                    #print('selected_before_randwalk:',selected_node_num, 'selected_after_randwalk:',selected_node_num2)\n",
    "                    '''\n",
    "                    Excel Export\n",
    "                    '''\n",
    "                    data_for_excel[res][FR_tp[FR_type]] = [round(NMI_rand_walk,2), round(Purity_rand_walk,2), selected_node_percent, Num_Cluster_Louv_on_H]\n",
    "                    \n",
    "                    '''\n",
    "                    Plots\n",
    "                    '''\n",
    "                    #at index [res][FR_type] store the data for the plot\n",
    "                    data_for_plot[idx][FR_type] = {'NMI_after_vote':NMI_List[-1], 'Purity_after_vote':Purity_List[-1], 'Louvain_NMI':NMI_, \n",
    "                                                    'Louvain_Purity':Purity_, 'Leiden_NMI':NMI_baseline_leiden, 'Leiden_Purity':Purity_baseline_leiden, \n",
    "                                                    'Num_Cluster_Louv_on_G':Num_Cluster_Louv_on_G, 'Num_Cluster_Leiden_on_G':Num_Cluster_Leiden_on_G, \n",
    "                                                    'Num_Cluster_Louv_on_H':Num_Cluster_Louv_on_H, 'percent_nodes':(selected_node_num*100 / G.number_of_nodes()),\n",
    "                                                    'extra_nmi':NMI_rand_walk, 'extra_purity':Purity_rand_walk,\n",
    "                                                    'extra_name':'+RandWalk', 'extra_percent_nodes':(selected_node_num2*100 / G.number_of_nodes())\n",
    "                                                    }\n",
    "                    \n",
    "    plot_to_pdf(resolution_list, data_for_plot, k, True_num_of_clusters, pdf_name, data)\n",
    "    write_to_excel(data_for_excel, 'results.xlsx', 'results')\n",
    "        \n",
    "            \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Cust_Top as Cust\n",
    "import networkx.algorithms.community.louvain as Louv\n",
    "from sklearn.metrics.cluster import normalized_mutual_info_score as NMI\n",
    "from collections import deque\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import os\n",
    "from subgraph import * \n",
    "import debug\n",
    "from collections import defaultdict\n",
    "import leidenalg as la \n",
    "import copy\n",
    "\n",
    "#data_names = ['Zhengmix8eq','mRNA','miRNA','FashionMNIST','MNIST','seeds','breast-cancer','Omniglot','bbc_news','20NewsGroups_tfdif','biorxiv','big_patent','Cora','Cora full','Citeseer','Eu core']\n",
    "#data_names = ['ALM', 'AMB', 'Baron_Human', 'Baron_Mouse', 'Muraro', 'Segerstolpe', 'Tcell-medicine', 'TM', 'VISP', 'Xin', 'Zheng']\n",
    "#data_names = ['Zhengmix8eq','miRNA']\n",
    "data_names = ['Zhengmix8eq','mRNA','miRNA','FashionMNIST','MNIST','seeds','breast-cancer','Omniglot','bbc_news','20NewsGroups_tfdif','biorxiv','big_patent','Cora','Cora full','Citeseer','Eu core','ALM', 'AMB', 'Baron_Human', 'Baron_Mouse', 'Muraro', 'Segerstolpe', 'Tcell-medicine', 'TM', 'VISP', 'Xin', 'Zheng']\n",
    "\n",
    "'''\n",
    "datasets with nodes that have no outgoing edges : \n",
    "['Cora full', 'Citeseer', 'Eu core']\n",
    "'''\n",
    "\n",
    "FR_tp = ['FL','FL_ng','FL_ng_pr','PageRank']\n",
    "FR_tp_short = ['FL','FL_ng','FL_ng_p','PR']\n",
    "Num_hops = {0:'5',1:'log(n)'}\n",
    "\n",
    "#top k% nodes for induced subgraph\n",
    "k=0.2\n",
    "resolution_list = [0.05, 0.5, 1, 1.5, 5, 50]\n",
    "\n",
    "for data_idx, data in enumerate(data_names): \n",
    "\n",
    "    data_directory = f'./Plots/{data}'\n",
    "    file_path = f'{data_directory}/{data}.txt'\n",
    "    os.makedirs(data_directory, exist_ok=True)\n",
    "    pdf_name = './Plots/'+data+'/Testing'+data+'.pdf'\n",
    "\n",
    "    '''\n",
    "    Get the Graph from Edge_List and get the labels\n",
    "    '''\n",
    "    G, label= data_to_graph(data)\n",
    "\n",
    "    True_num_of_clusters = len(set(label))\n",
    "    \n",
    "\n",
    "    cluster_sizes = defaultdict(int)\n",
    "    for node in G.nodes():\n",
    "        cluster_sizes[label[node]]+=1\n",
    "\n",
    "    '''\n",
    "    Add self loops to the nodes with no outgoing edges\n",
    "    '''\n",
    "    G_ = copy.deepcopy(G)\n",
    "    for node in G_.nodes():\n",
    "        if not list(G_.successors(node)):\n",
    "            G_.add_edge(node, node, weight=1)\n",
    "\n",
    "    '''\n",
    "    dictionary for exporting to excel\n",
    "    '''\n",
    "    \n",
    "\n",
    "    data_for_excel = defaultdict(lambda: defaultdict(int)) #nested dictionary to store data for plots\n",
    "    data_for_excel['data_idx'] = data_idx\n",
    "    data_for_excel['data_name'] = data\n",
    "    #data_for_excel['fr_tp'] = FR_tp\n",
    "    data_for_excel['fr_tp']=['FL']\n",
    "    data_for_excel['res_list'] = resolution_list\n",
    "    data_for_excel['method_idx'] = 0\n",
    "    data_for_excel['method_name'] = 'Louv_baseline'\n",
    "    data_for_excel['num_comm'] = True_num_of_clusters\n",
    "\n",
    "    data_for_excel2 = copy.deepcopy(data_for_excel)\n",
    "    data_for_excel3 = copy.deepcopy(data_for_excel)\n",
    "    data_for_excel3['fr_tp'] = FR_tp\n",
    "    data_for_excel4 = copy.deepcopy(data_for_excel3)\n",
    "    data_for_excel5 = copy.deepcopy(data_for_excel3)\n",
    "    data_for_excel6 = copy.deepcopy(data_for_excel3)\n",
    "    data_for_excel_ = copy.deepcopy(data_for_excel3)\n",
    "    data_for_excel7 = copy.deepcopy(data_for_excel3)  \n",
    "\n",
    "    list_of_excel_data = [data_for_excel, data_for_excel2, data_for_excel3, data_for_excel4, data_for_excel5, data_for_excel_, data_for_excel6, data_for_excel7]\n",
    "    for Num_hop in [1]:\n",
    "        #List of FR_values\n",
    "        FR_precalculated = []\n",
    "        for fr_type in range(4): \n",
    "            '''\n",
    "            Calculate FlowRank for the whole graph\n",
    "            '''\n",
    "            if Num_hop==0:\n",
    "                node2FR = calc_FlowRank(G_, fr_type, 5)\n",
    "            else:\n",
    "                node2FR = calc_FlowRank(G_, fr_type, np.log2(G.number_of_nodes()))\n",
    "            FR_precalculated.append(node2FR)\n",
    "\n",
    "        for idx, res in enumerate(resolution_list):\n",
    "            ''' \n",
    "            Louvain on G (baseline)\n",
    "            '''\n",
    "            label_, NMI_, Purity_ = do_Louvain(G, G, res, 0, label)\n",
    "            Num_Cluster_Louv_on_G = len(set(label_))\n",
    "            \n",
    "            data_for_excel[res]['FL'] = [round(NMI_,2), round(Purity_,2), '1', '100%', Num_Cluster_Louv_on_G]\n",
    "            \n",
    "            '''\n",
    "            Leiden on G (Baseline)\n",
    "            '''\n",
    "            label_, NMI_, Purity_ = do_Leiden(G, G, res, 0, label)\n",
    "            Num_Cluster_Leiden_on_G = len(set(label_))\n",
    "            \n",
    "            \n",
    "            data_for_excel2['method_idx'] = 1\n",
    "            data_for_excel2['method_name'] = 'Leiden_baseline'\n",
    "            data_for_excel2[res]['FL'] = [round(NMI_,2), round(Purity_,2), '1', '100%', Num_Cluster_Leiden_on_G]\n",
    "            \n",
    "\n",
    "\n",
    "            for Mod_type in [0]:\n",
    "                for FR_type in range(4):\n",
    "                    \n",
    "                    '''\n",
    "                    Get induced subgraph of top k% nodes in FR value\n",
    "                    '''\n",
    "                    node2FR = FR_precalculated[FR_type]\n",
    "                    node_list = sorted(G.nodes, key=lambda x: node2FR[x], reverse=True)\n",
    "                    \n",
    "                    k_ = int(k*len(node_list))\n",
    "                    top_nodes = node_list[:k_]\n",
    "                    nodes_rest = node_list[k_:]\n",
    "                    H = getInducedSubgraph(G, top_nodes) # H = induced subgraph\n",
    "                    \n",
    "                    '''\n",
    "                    label counts for balancedness calculation\n",
    "                    '''\n",
    "                    selected_labels_dict = defaultdict(int)\n",
    "                    for node in H.nodes():\n",
    "                        selected_labels_dict[label[node]]+=1\n",
    "                    \n",
    "                    '''\n",
    "                    Leiden on the subgraph H \n",
    "                    '''\n",
    "                    H_label, NMI_, Purity_ = do_Leiden(H, G, res, 0, label)\n",
    "                    \n",
    "                    Num_Cluster_Leid_on_H = len({x for x in set(H_label) if x != -1})\n",
    "\n",
    "                    preservation_ = calc_preservation(selected_labels_dict, cluster_sizes, G.number_of_nodes())\n",
    "                    \n",
    "                    data_for_excel3['fr_tp'] = FR_tp\n",
    "                    data_for_excel3['method_idx'] = 2\n",
    "                    data_for_excel3['method_name'] = 'Leiden on 20%'\n",
    "                    data_for_excel3[res][FR_tp[FR_type]] = [round(NMI_,2), round(Purity_,2), round(preservation_,2),'20%', Num_Cluster_Leid_on_H]\n",
    "                   \n",
    "                    '''\n",
    "                    Add nodes to the subgraph by strong majority vote (1 round)\n",
    "                    '''\n",
    "                    H_label_copy = copy.deepcopy(H_label)\n",
    "                    NMI_List, Purity_List, Balance_List, Preserv_List, InEdge_List = merge_by_vote(top_nodes, nodes_rest, H_label_copy, G, label, selected_labels_dict, cluster_sizes, one_round=True)\n",
    "\n",
    "                    selected_labels_dict = defaultdict(int)\n",
    "                    for node in [idx_ for idx_, x in enumerate(H_label_copy) if x != -1]:\n",
    "                        selected_labels_dict[label[node]]+=1\n",
    "                    preservation_ = calc_preservation(selected_labels_dict, cluster_sizes, G.number_of_nodes())\n",
    "\n",
    "                    selected_node_num = len([x for x in H_label_copy if x != -1])\n",
    "                    selected_node_percent = str(round(selected_node_num*100/(G.number_of_nodes()),2))+'%'\n",
    "                    \n",
    "                    data_for_excel4['method_idx'] = 3\n",
    "                    data_for_excel4['method_name'] = 'Leiden + Vote(1_Round)'\n",
    "                    #data_for_excel4[res][FR_tp[FR_type]] = [round(NMI_List[-1],2), round(Purity_List[-1],2), selected_node_percent, Num_Cluster_Leid_on_H]\n",
    "                    data_for_excel4[res][FR_tp[FR_type]] = [round(NMI_List[-1],2), round(Purity_List[-1],2), round(preservation_,2), selected_node_percent, Num_Cluster_Leid_on_H]\n",
    "                  \n",
    "                    '''\n",
    "                    Add nodes to the subgraph by strong majority vote\n",
    "                    '''\n",
    "                    NMI_List, Purity_List, Balance_List, Preserv_List, InEdge_List = merge_by_vote(top_nodes, nodes_rest, H_label, G, label, selected_labels_dict, cluster_sizes)\n",
    "                    selected_node_num = len([x for x in H_label if x != -1])\n",
    "                    selected_node_percent = str(round(selected_node_num*100/(G.number_of_nodes()),2))+'%'\n",
    "\n",
    "                    selected_labels_dict = defaultdict(int)\n",
    "                    for node in [idx_ for idx_, x in enumerate(H_label) if x != -1]:\n",
    "                        selected_labels_dict[label[node]]+=1\n",
    "                    preservation_ = calc_preservation(selected_labels_dict, cluster_sizes, G.number_of_nodes())\n",
    "\n",
    "                    \n",
    "                    data_for_excel5['method_idx'] = 4\n",
    "                    data_for_excel5['method_name'] = 'Leiden + Vote'\n",
    "                    #data_for_excel5[res][FR_tp[FR_type]] = [round(NMI_List[-1],2), round(Purity_List[-1],2), selected_node_percent, Num_Cluster_Leid_on_H]\n",
    "                    data_for_excel5[res][FR_tp[FR_type]] = [round(NMI_List[-1],2), round(Purity_List[-1],2), round(preservation_,2), selected_node_percent, Num_Cluster_Leid_on_H]\n",
    "                 \n",
    "                    '''\n",
    "                    Random walks from unselected nodes\n",
    "                    '''\n",
    "                    unselected_nodes = [node_idx for node_idx, node_label in enumerate(H_label) if node_label == -1]\n",
    "                    H_label_copy = copy.deepcopy(H_label)\n",
    "                    H_label_copy, NMI_rand_walk, Purity_rand_walk = do_random_walks(G, unselected_nodes, label, H_label_copy, node2FR, walk_len=10, walk_rep = 100) \n",
    "                    selected_node_num2 = len([x for x in H_label_copy if x != -1])\n",
    "                    selected_node_percent2 = str(round(selected_node_num2*100/(G.number_of_nodes()),2))+'%'\n",
    "                    \n",
    "                    selected_labels_dict = defaultdict(int)\n",
    "                    for node in [idx_ for idx_, x in enumerate(H_label_copy) if x != -1]:\n",
    "                        selected_labels_dict[label[node]]+=1\n",
    "                    preservation_ = calc_preservation(selected_labels_dict, cluster_sizes, G.number_of_nodes())\n",
    "\n",
    "                    \n",
    "                    data_for_excel_['method_idx'] = 5\n",
    "                    data_for_excel_['method_name'] = 'Leid+Vote+RW(weakMajority)'\n",
    "                    #data_for_excel_[res][FR_tp[FR_type]] = [round(NMI_rand_walk,2), round(Purity_rand_walk,2), selected_node_percent2, Num_Cluster_Leid_on_H]\n",
    "                    data_for_excel_[res][FR_tp[FR_type]] = [round(NMI_rand_walk,2), round(Purity_rand_walk,2), round(preservation_,2), selected_node_percent2, Num_Cluster_Leid_on_H]\n",
    "              \n",
    "                    '''\n",
    "                    Leiden again on the vote subgraph\n",
    "                    '''\n",
    "                    selected_node_list = [node_num_ for node_num_, node_label_ in enumerate(H_label) if node_label_ != -1]\n",
    "                    H2 = getInducedSubgraph(G, selected_node_list)\n",
    "                    H2_ig, ig_to_nx, nx_to_ig = networkx_to_igraph(H2) # Mapping = igraph index to networkx index\n",
    "                    initial_membership = [H_label[ig_to_nx[i]] for i in list(H2_ig.vs.indices)]\n",
    "                    partition2_ = la.find_partition(H2_ig, la.RBConfigurationVertexPartition, initial_membership = initial_membership, n_iterations=-1, resolution_parameter=res, seed=0)\n",
    "                    H_label2 = part_to_full_label(partition2_, G.number_of_nodes(), ig_to_nx)\n",
    "                    \n",
    "                    label_compressed2, H_label_compressed2 = get_compressed_labels(label,H_label2, selected_node_list)\n",
    "                    NMI_louv_vote_louv = NMI(H_label_compressed2, label_compressed2)\n",
    "                    Purity_louv_vote_louv = met.purity_score(label_compressed2, H_label_compressed2)\n",
    "                    Num_Cluster_Leid_on_H2 = len({x for x in set(H_label2) if x != -1})\n",
    "                    \n",
    "                    selected_labels_dict = defaultdict(int)\n",
    "                    for node in [idx_ for idx_, x in enumerate(H_label2) if x != -1]:\n",
    "                        selected_labels_dict[label[node]]+=1\n",
    "                    preservation_ = calc_preservation(selected_labels_dict, cluster_sizes, G.number_of_nodes())\n",
    "\n",
    "                    \n",
    "                    data_for_excel6['method_idx'] = 6\n",
    "                    data_for_excel6['method_name'] = 'Leid+Vote+Leid'\n",
    "                    #data_for_excel6[res][FR_tp[FR_type]] = [round(NMI_louv_vote_louv,2), round(Purity_louv_vote_louv,2), selected_node_percent, Num_Cluster_Leid_on_H2]\n",
    "                    data_for_excel6[res][FR_tp[FR_type]] = [round(NMI_louv_vote_louv,2), round(Purity_louv_vote_louv,2), round(preservation_,2), selected_node_percent, Num_Cluster_Leid_on_H2]\n",
    "                 \n",
    "                    '''\n",
    "                    Leiden + vote + Leiden + vote\n",
    "                    '''\n",
    "                    nodes_rest2 = [node_num_ for node_num_, node_label_ in enumerate(H_label2) if node_label_ == -1]\n",
    "                    NMI_List2, Purity_List2, Balance_List2, Preserv_List2, InEdge_List2 = merge_by_vote(selected_node_list, nodes_rest2, H_label2, G, label, selected_labels_dict, cluster_sizes)\n",
    "                    selected_node_num2 = len([node_num_ for node_num_, node_label_ in enumerate(H_label2) if node_label_ != -1])\n",
    "                    selected_node_percent = str(round(selected_node_num2*100/(G.number_of_nodes()),2))+'%' \n",
    "\n",
    "                    selected_labels_dict = defaultdict(int)\n",
    "                    for node in [idx_ for idx_, x in enumerate(H_label2) if x != -1]:\n",
    "                        selected_labels_dict[label[node]]+=1\n",
    "                    preservation_ = calc_preservation(selected_labels_dict, cluster_sizes, G.number_of_nodes())\n",
    "\n",
    "                   \n",
    "                    data_for_excel7['method_idx'] = 7\n",
    "                    data_for_excel7['method_name'] = '(Leiden + Vote)x2'\n",
    "                    #data_for_excel7[res][FR_tp[FR_type]] = [round(NMI_List2[-1],2), round(Purity_List2[-1],2), selected_node_percent, Num_Cluster_Leid_on_H2]\n",
    "                    data_for_excel7[res][FR_tp[FR_type]] = [round(NMI_List2[-1],2), round(Purity_List2[-1],2), round(preservation_,2), selected_node_percent, Num_Cluster_Leid_on_H2]\n",
    "                   \n",
    "    \n",
    "    for excel_data in list_of_excel_data:\n",
    "        write_to_excel(excel_data, 'results.xlsx', 'results')             \n",
    "    \n",
    "        \n",
    "            \n",
    "\n",
    "                                \n",
    "                    \n",
    "\n",
    "                    \n",
    "                    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combined (With Modularity computation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALM 10068\n",
      "Log transform done\n",
      "(10068, 50)\n",
      "Accuracy of  15 -NN graph is 0.700\n",
      "151020\n",
      "AMB 12832\n",
      "Log transform done\n",
      "(12832, 50)\n",
      "Accuracy of  15 -NN graph is 0.763\n",
      "192480\n",
      "Baron_Human 8569\n",
      "Log transform done\n",
      "(8569, 50)\n",
      "Accuracy of  15 -NN graph is 0.972\n",
      "128535\n",
      "Baron_Mouse 1886\n",
      "Log transform done\n",
      "(1886, 50)\n",
      "Accuracy of  15 -NN graph is 0.954\n",
      "28290\n",
      "Muraro 2122\n",
      "Log transform done\n",
      "(2122, 50)\n",
      "Accuracy of  15 -NN graph is 0.950\n",
      "31830\n",
      "Segerstolpe 2133\n",
      "Log transform done\n",
      "(2133, 50)\n",
      "Accuracy of  15 -NN graph is 0.933\n",
      "31995\n",
      "Tcell-medicine 5759\n",
      "Log transform done\n",
      "(5759, 50)\n",
      "Accuracy of  15 -NN graph is 0.735\n",
      "86385\n",
      "TM 54865\n",
      "Log transform done\n",
      "(54865, 50)\n",
      "Accuracy of  15 -NN graph is 0.949\n",
      "822975\n",
      "VISP 15413\n",
      "Log transform done\n",
      "(15413, 50)\n",
      "Accuracy of  15 -NN graph is 0.711\n",
      "231195\n",
      "Xin 1449\n",
      "Log transform done\n",
      "(1449, 50)\n",
      "Accuracy of  15 -NN graph is 0.974\n",
      "21735\n",
      "Zheng 65943\n",
      "Log transform done\n",
      "(65943, 50)\n",
      "Accuracy of  15 -NN graph is 0.561\n",
      "989145\n"
     ]
    }
   ],
   "source": [
    "import Cust_Top as Cust\n",
    "import networkx.algorithms.community.louvain as Louv\n",
    "from sklearn.metrics.cluster import normalized_mutual_info_score as NMI\n",
    "from collections import deque\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import os\n",
    "from subgraph import * \n",
    "import debug\n",
    "from collections import defaultdict\n",
    "import leidenalg as la \n",
    "import copy\n",
    "\n",
    "#data_names = ['Zhengmix8eq','mRNA','miRNA','FashionMNIST','MNIST','seeds','breast-cancer','Omniglot','bbc_news','20NewsGroups_tfdif','biorxiv','big_patent','Cora','Cora full','Citeseer','Eu core']\n",
    "#data_names = ['ALM', 'AMB', 'Baron_Human', 'Baron_Mouse', 'Muraro', 'Segerstolpe', 'Tcell-medicine', 'TM', 'VISP', 'Xin', 'Zheng']\n",
    "#data_names = ['Zhengmix8eq','miRNA']\n",
    "#data_names = ['Zhengmix8eq']\n",
    "#data_names = ['Zhengmix8eq','mRNA','miRNA','FashionMNIST','MNIST','seeds','breast-cancer','Omniglot','bbc_news','20NewsGroups_tfdif','biorxiv','big_patent','Cora','Cora full','Citeseer','Eu core','ALM', 'AMB', 'Baron_Human', 'Baron_Mouse', 'Muraro', 'Segerstolpe', 'Tcell-medicine', 'TM', 'VISP', 'Xin', 'Zheng']\n",
    "data_names = ['ALM', 'AMB', 'Baron_Human', 'Baron_Mouse', 'Muraro', 'Segerstolpe', 'Tcell-medicine', 'TM', 'VISP', 'Xin', 'Zheng']\n",
    "\n",
    "'''\n",
    "datasets with nodes that have no outgoing edges : \n",
    "['Cora full', 'Citeseer', 'Eu core']\n",
    "'''\n",
    "\n",
    "FR_tp = ['FL','FL_ng','FL_ng_pr','PageRank']\n",
    "FR_tp_short = ['FL','FL_ng','FL_ng_p','PR']\n",
    "Num_hops = {0:'5',1:'log(n)'}\n",
    "\n",
    "#top k% nodes for induced subgraph\n",
    "k=0.2\n",
    "resolution_list = [0.05, 0.5, 1, 1.5, 5, 50]\n",
    "\n",
    "for data_idx, data in enumerate(data_names): \n",
    "\n",
    "    data_directory = f'./Plots/{data}'\n",
    "    file_path = f'{data_directory}/{data}.txt'\n",
    "    os.makedirs(data_directory, exist_ok=True)\n",
    "    pdf_name = './Plots/'+data+'/Testing'+data+'.pdf'\n",
    "\n",
    "    '''\n",
    "    Get the Graph from Edge_List and get the labels\n",
    "    '''\n",
    "    G, label= data_to_graph(data)\n",
    "\n",
    "    True_num_of_clusters = len(set(label))\n",
    "    \n",
    "\n",
    "    cluster_sizes = defaultdict(int)\n",
    "    for node in G.nodes():\n",
    "        cluster_sizes[label[node]]+=1\n",
    "\n",
    "    '''\n",
    "    Add self loops to the nodes with no outgoing edges\n",
    "    '''\n",
    "    G_ = copy.deepcopy(G)\n",
    "    for node in G_.nodes():\n",
    "        if not list(G_.successors(node)):\n",
    "            G_.add_edge(node, node, weight=1)\n",
    "\n",
    "    '''\n",
    "    dictionary for exporting to excel\n",
    "    '''\n",
    "    \n",
    "\n",
    "    data_for_excel = defaultdict(lambda: defaultdict(int)) #nested dictionary to store data for plots\n",
    "    data_for_excel['data_idx'] = data_idx\n",
    "    data_for_excel['data_name'] = data\n",
    "    #data_for_excel['fr_tp'] = FR_tp\n",
    "    data_for_excel['fr_tp']=['FL']\n",
    "    data_for_excel['res_list'] = resolution_list\n",
    "    data_for_excel['method_idx'] = 0\n",
    "    data_for_excel['method_name'] = 'Louv_baseline'\n",
    "    data_for_excel['num_comm'] = True_num_of_clusters\n",
    "\n",
    "    data_for_excel2 = copy.deepcopy(data_for_excel)\n",
    "    data_for_excel3 = copy.deepcopy(data_for_excel)\n",
    "    data_for_excel3['fr_tp'] = FR_tp\n",
    "    data_for_excel4 = copy.deepcopy(data_for_excel3)\n",
    "    data_for_excel5 = copy.deepcopy(data_for_excel3)\n",
    "    data_for_excel6 = copy.deepcopy(data_for_excel3)\n",
    "    data_for_excel_ = copy.deepcopy(data_for_excel3)\n",
    "    data_for_excel7 = copy.deepcopy(data_for_excel3)  \n",
    "\n",
    "    list_of_excel_data = [data_for_excel, data_for_excel2, data_for_excel3, data_for_excel4, data_for_excel5, data_for_excel_, data_for_excel6, data_for_excel7]\n",
    "    for Num_hop in [1]:\n",
    "        #List of FR_values\n",
    "        FR_precalculated = []\n",
    "        for fr_type in range(4): \n",
    "            '''\n",
    "            Calculate FlowRank for the whole graph\n",
    "            '''\n",
    "            if Num_hop==0:\n",
    "                node2FR = calc_FlowRank(G_, fr_type, 5)\n",
    "            else:\n",
    "                node2FR = calc_FlowRank(G_, fr_type, np.log2(G.number_of_nodes()))\n",
    "            FR_precalculated.append(node2FR)\n",
    "\n",
    "        for idx, res in enumerate(resolution_list):\n",
    "            ''' \n",
    "            Louvain on G (baseline)\n",
    "            '''\n",
    "            label_, NMI_, Purity_ = do_Louvain(G, G, res, 0, label)\n",
    "            Num_Cluster_Louv_on_G = len(set(label_))\n",
    "            \n",
    "            data_for_excel[res]['FL'] = [round(NMI_,2), round(Purity_,2), '1', '100%', Num_Cluster_Louv_on_G]\n",
    "            data_for_excel[res]['FL'].extend([calc_modularity(G, label_, G, list(G.nodes()), res, label)])\n",
    "\n",
    "            '''\n",
    "            Leiden on G (Baseline)\n",
    "            '''\n",
    "            label_, NMI_, Purity_ = do_Leiden(G, G, res, 0, label)\n",
    "            Num_Cluster_Leiden_on_G = len(set(label_))\n",
    "            \n",
    "            \n",
    "            data_for_excel2['method_idx'] = 1\n",
    "            data_for_excel2['method_name'] = 'Leiden_baseline'\n",
    "            data_for_excel2[res]['FL'] = [round(NMI_,2), round(Purity_,2), '1', '100%', Num_Cluster_Leiden_on_G]\n",
    "            data_for_excel2[res]['FL'].extend([calc_modularity(G, label_, G, list(G.nodes()), res, label)])\n",
    "\n",
    "\n",
    "            for Mod_type in [0]:\n",
    "                for FR_type in range(4):\n",
    "                    \n",
    "                    '''\n",
    "                    Get induced subgraph of top k% nodes in FR value\n",
    "                    '''\n",
    "                    node2FR = FR_precalculated[FR_type]\n",
    "                    node_list = sorted(G.nodes, key=lambda x: node2FR[x], reverse=True)\n",
    "                    \n",
    "                    k_ = int(k*len(node_list))\n",
    "                    top_nodes = node_list[:k_]\n",
    "                    nodes_rest = node_list[k_:]\n",
    "                    H = getInducedSubgraph(G, top_nodes) # H = induced subgraph\n",
    "                    \n",
    "                    '''\n",
    "                    label counts for balancedness calculation\n",
    "                    '''\n",
    "                    selected_labels_dict = defaultdict(int)\n",
    "                    for node in H.nodes():\n",
    "                        selected_labels_dict[label[node]]+=1\n",
    "                    \n",
    "                    '''\n",
    "                    Leiden on the subgraph H \n",
    "                    '''\n",
    "                    H_label, NMI_, Purity_ = do_Leiden(H, G, res, 0, label)\n",
    "                    \n",
    "                    Num_Cluster_Leid_on_H = len({x for x in set(H_label) if x != -1})\n",
    "\n",
    "                    preservation_ = calc_preservation(selected_labels_dict, cluster_sizes, G.number_of_nodes())\n",
    "                    \n",
    "                    data_for_excel3['fr_tp'] = FR_tp\n",
    "                    data_for_excel3['method_idx'] = 2\n",
    "                    data_for_excel3['method_name'] = 'Leiden on 20%'\n",
    "                    data_for_excel3[res][FR_tp[FR_type]] = [round(NMI_,2), round(Purity_,2), round(preservation_,2),'20%', Num_Cluster_Leid_on_H]\n",
    "                    \n",
    "                    '''\n",
    "                    Add nodes to the subgraph by strong majority vote (1 round)\n",
    "                    '''\n",
    "                    H_label_copy = copy.deepcopy(H_label)\n",
    "                    NMI_List, Purity_List, Balance_List, Preserv_List, InEdge_List = merge_by_vote(top_nodes, nodes_rest, H_label_copy, G, label, selected_labels_dict, cluster_sizes, one_round=True)\n",
    "\n",
    "                    selected_labels_dict = defaultdict(int)\n",
    "                    for node in [idx_ for idx_, x in enumerate(H_label_copy) if x != -1]:\n",
    "                        selected_labels_dict[label[node]]+=1\n",
    "                    preservation_ = calc_preservation(selected_labels_dict, cluster_sizes, G.number_of_nodes())\n",
    "\n",
    "                    selected_node_num = len([x for x in H_label_copy if x != -1])\n",
    "                    selected_node_percent = str(round(selected_node_num*100/(G.number_of_nodes()),2))+'%'\n",
    "                    \n",
    "                    data_for_excel4['method_idx'] = 3\n",
    "                    data_for_excel4['method_name'] = 'Leiden + Vote(1_Round)'\n",
    "                    #data_for_excel4[res][FR_tp[FR_type]] = [round(NMI_List[-1],2), round(Purity_List[-1],2), selected_node_percent, Num_Cluster_Leid_on_H]\n",
    "                    data_for_excel4[res][FR_tp[FR_type]] = [round(NMI_List[-1],2), round(Purity_List[-1],2), round(preservation_,2), selected_node_percent, Num_Cluster_Leid_on_H]\n",
    "                  \n",
    "                    '''\n",
    "                    Add nodes to the subgraph by strong majority vote\n",
    "                    '''\n",
    "                    NMI_List, Purity_List, Balance_List, Preserv_List, InEdge_List = merge_by_vote(top_nodes, nodes_rest, H_label, G, label, selected_labels_dict, cluster_sizes)\n",
    "                    selected_nodes = [idx for idx,x in enumerate(H_label) if x != -1]\n",
    "                    selected_node_percent = str(round(len(selected_nodes)*100/(G.number_of_nodes()),2))+'%'\n",
    "\n",
    "                    selected_labels_dict = defaultdict(int)\n",
    "                    for node in [idx_ for idx_, x in enumerate(H_label) if x != -1]:\n",
    "                        selected_labels_dict[label[node]]+=1\n",
    "                    preservation_ = calc_preservation(selected_labels_dict, cluster_sizes, G.number_of_nodes())\n",
    "\n",
    "                    \n",
    "                    data_for_excel5['method_idx'] = 4\n",
    "                    data_for_excel5['method_name'] = 'Leiden + Vote'\n",
    "                    #data_for_excel5[res][FR_tp[FR_type]] = [round(NMI_List[-1],2), round(Purity_List[-1],2), selected_node_percent, Num_Cluster_Leid_on_H]\n",
    "                    data_for_excel5[res][FR_tp[FR_type]] = [round(NMI_List[-1],2), round(Purity_List[-1],2), round(preservation_,2), selected_node_percent, Num_Cluster_Leid_on_H]\n",
    "                    \n",
    "                    H_ = getInducedSubgraph(G, selected_nodes)\n",
    "                    data_for_excel5[res][FR_tp[FR_type]].extend([calc_modularity(H_, H_label, G, node_list, res, label)])\n",
    "                    '''\n",
    "                    Random walks from unselected nodes\n",
    "                    '''\n",
    "                    unselected_nodes = [node_idx for node_idx, node_label in enumerate(H_label) if node_label == -1]\n",
    "                    H_label_copy = copy.deepcopy(H_label)\n",
    "                    H_label_copy, NMI_rand_walk, Purity_rand_walk = do_random_walks(G, unselected_nodes, label, H_label_copy, node2FR, walk_len=10, walk_rep = 100) \n",
    "                    selected_node_num2 = len([x for x in H_label_copy if x != -1])\n",
    "                    selected_node_percent2 = str(round(selected_node_num2*100/(G.number_of_nodes()),2))+'%'\n",
    "                    \n",
    "                    selected_labels_dict = defaultdict(int)\n",
    "                    for node in [idx_ for idx_, x in enumerate(H_label_copy) if x != -1]:\n",
    "                        selected_labels_dict[label[node]]+=1\n",
    "                    preservation_ = calc_preservation(selected_labels_dict, cluster_sizes, G.number_of_nodes())\n",
    "\n",
    "                    \n",
    "                    data_for_excel_['method_idx'] = 5\n",
    "                    data_for_excel_['method_name'] = 'Leid+Vote+RW(weakMajority)'\n",
    "                    #data_for_excel_[res][FR_tp[FR_type]] = [round(NMI_rand_walk,2), round(Purity_rand_walk,2), selected_node_percent2, Num_Cluster_Leid_on_H]\n",
    "                    data_for_excel_[res][FR_tp[FR_type]] = [round(NMI_rand_walk,2), round(Purity_rand_walk,2), round(preservation_,2), selected_node_percent2, Num_Cluster_Leid_on_H]\n",
    "              \n",
    "                    '''\n",
    "                    Leiden again on the vote subgraph\n",
    "                    '''\n",
    "                    selected_node_list = [node_num_ for node_num_, node_label_ in enumerate(H_label) if node_label_ != -1]\n",
    "                    H2 = getInducedSubgraph(G, selected_node_list)\n",
    "                    H2_ig, ig_to_nx, nx_to_ig = networkx_to_igraph(H2) # Mapping = igraph index to networkx index\n",
    "                    initial_membership = [H_label[ig_to_nx[i]] for i in list(H2_ig.vs.indices)]\n",
    "                    partition2_ = la.find_partition(H2_ig, la.RBConfigurationVertexPartition, initial_membership = initial_membership, n_iterations=-1, resolution_parameter=res, seed=0)\n",
    "                    H_label2 = part_to_full_label(partition2_, G.number_of_nodes(), ig_to_nx)\n",
    "                    \n",
    "                    label_compressed2, H_label_compressed2 = get_compressed_labels(label,H_label2, selected_node_list)\n",
    "                    NMI_louv_vote_louv = NMI(H_label_compressed2, label_compressed2)\n",
    "                    Purity_louv_vote_louv = met.purity_score(label_compressed2, H_label_compressed2)\n",
    "                    Num_Cluster_Leid_on_H2 = len({x for x in set(H_label2) if x != -1})\n",
    "                    \n",
    "                    selected_labels_dict = defaultdict(int)\n",
    "                    for node in [idx_ for idx_, x in enumerate(H_label2) if x != -1]:\n",
    "                        selected_labels_dict[label[node]]+=1\n",
    "                    preservation_ = calc_preservation(selected_labels_dict, cluster_sizes, G.number_of_nodes())\n",
    "\n",
    "                    \n",
    "                    data_for_excel6['method_idx'] = 6\n",
    "                    data_for_excel6['method_name'] = 'Leid+Vote+Leid'\n",
    "                    #data_for_excel6[res][FR_tp[FR_type]] = [round(NMI_louv_vote_louv,2), round(Purity_louv_vote_louv,2), selected_node_percent, Num_Cluster_Leid_on_H2]\n",
    "                    data_for_excel6[res][FR_tp[FR_type]] = [round(NMI_louv_vote_louv,2), round(Purity_louv_vote_louv,2), round(preservation_,2), selected_node_percent, Num_Cluster_Leid_on_H2]\n",
    "                 \n",
    "                    '''\n",
    "                    Leiden + vote + Leiden + vote\n",
    "                    '''\n",
    "                    nodes_rest2 = [node_num_ for node_num_, node_label_ in enumerate(H_label2) if node_label_ == -1]\n",
    "                    NMI_List2, Purity_List2, Balance_List2, Preserv_List2, InEdge_List2 = merge_by_vote(selected_node_list, nodes_rest2, H_label2, G, label, selected_labels_dict, cluster_sizes)\n",
    "                    selected_node_num2 = len([node_num_ for node_num_, node_label_ in enumerate(H_label2) if node_label_ != -1])\n",
    "                    selected_node_percent = str(round(selected_node_num2*100/(G.number_of_nodes()),2))+'%' \n",
    "\n",
    "                    selected_labels_dict = defaultdict(int)\n",
    "                    for node in [idx_ for idx_, x in enumerate(H_label2) if x != -1]:\n",
    "                        selected_labels_dict[label[node]]+=1\n",
    "                    preservation_ = calc_preservation(selected_labels_dict, cluster_sizes, G.number_of_nodes())\n",
    "\n",
    "                   \n",
    "                    data_for_excel7['method_idx'] = 7\n",
    "                    data_for_excel7['method_name'] = '(Leiden + Vote)x2'\n",
    "                    #data_for_excel7[res][FR_tp[FR_type]] = [round(NMI_List2[-1],2), round(Purity_List2[-1],2), selected_node_percent, Num_Cluster_Leid_on_H2]\n",
    "                    data_for_excel7[res][FR_tp[FR_type]] = [round(NMI_List2[-1],2), round(Purity_List2[-1],2), round(preservation_,2), selected_node_percent, Num_Cluster_Leid_on_H2]\n",
    "                   \n",
    "    \n",
    "    for excel_data in list_of_excel_data:\n",
    "        write_to_excel_with_modularity(excel_data, 'results_with_modularity.xlsx', 'results')             \n",
    "    \n",
    "        \n",
    "            \n",
    "\n",
    "                                \n",
    "                    \n",
    "\n",
    "                    \n",
    "                    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Freeze pane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from subgraph import *\n",
    "freeze_panes('results_with_modularity.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Col Width Adjustment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from subgraph import *\n",
    "adjust_col_width('results_with_modularity.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
