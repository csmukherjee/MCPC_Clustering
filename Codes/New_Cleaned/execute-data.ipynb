{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "#sys.path.append('/Users/chandrasekharmukherjee/Home/Centrality framework/Modules')\n",
    "sys.path.append('I:/내 드라이브/backup/document/USC/Research/MCPC/Code/Codes')\n",
    "\n",
    "#Import packages\n",
    "#imports\n",
    "import time\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import sknetwork\n",
    "\n",
    "\n",
    "from sknetwork.ranking import PageRank\n",
    "from sknetwork.ranking import Betweenness\n",
    "from sknetwork.ranking import Closeness\n",
    "\n",
    "#import umap as umap\n",
    "\n",
    "from numba.typed import List\n",
    "import warnings\n",
    "from numba import njit\n",
    "import pynndescent\n",
    "import numpy as np\n",
    "from sklearn.cluster import SpectralClustering\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import operator\n",
    "from sklearn.utils.extmath import randomized_svd\n",
    "from random import randint\n",
    "from sklearn.utils.extmath import randomized_svd\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import scipy\n",
    "#from umap.umap_ import *\n",
    "import math\n",
    "from random import randint\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.datasets import cifar10\n",
    "from keras.datasets import cifar100\n",
    "from keras.datasets import fashion_mnist\n",
    "import scanpy\n",
    "from sklearn.metrics.cluster import normalized_mutual_info_score\n",
    "from sklearn.metrics import adjusted_mutual_info_score, roc_auc_score\n",
    "from sklearn.metrics.cluster import adjusted_rand_score\n",
    "from sklearn.metrics.cluster import adjusted_mutual_info_score\n",
    "\n",
    "#import community as community_louvain\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import fowlkes_mallows_score\n",
    "\n",
    "import scipy\n",
    "\n",
    "import igraph \n",
    "import networkx as nx\n",
    "\n",
    "\n",
    "import metric as met \n",
    "import embedding as embed   \n",
    "import data_utils_ch as data_util\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import importlib\n",
    "\n",
    "import metric as met \n",
    "import embedding as embed   \n",
    "import data_utils_ch as data_util\n",
    "from subgraph import *\n",
    "\n",
    "\n",
    "met=importlib.reload(met)\n",
    "embed=importlib.reload(embed)\n",
    "data_util=importlib.reload(data_util)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing every dataset with top k % nodes induced subgraph (Louvain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top k% induced subgraph + Strong Majority Vote later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### PDF Export version (Final Working Version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zhengmix8eq 3994\n",
      "Log transform done\n",
      "(3994, 50)\n",
      "Accuracy of  15 -NN graph is 0.793\n",
      "59910\n",
      "Number of nodes: 3994\n",
      " --- Zhengmix8eq (top 20.0%): FL + log(n) hops | res:  0.05\n",
      "NMI baseline: 0.688\n",
      "NMI Louvain twice: 0.691\n",
      "Number of nodes not included:  89\n",
      "NMI after top  20.0 % nodes: 0.83\n",
      "Max NMI:  0.833\n",
      " --- Zhengmix8eq (top 20.0%): FL_ng + log(n) hops | res:  0.05\n",
      "NMI baseline: 0.688\n",
      "NMI Louvain twice: 0.688\n",
      "Number of nodes not included:  16\n",
      "NMI after top  20.0 % nodes: 0.841\n",
      "Max NMI:  0.849\n",
      " --- Zhengmix8eq (top 20.0%): FL_ng_prop + log(n) hops | res:  0.05\n",
      "NMI baseline: 0.688\n",
      "NMI Louvain twice: 0.687\n",
      "Number of nodes not included:  15\n",
      "NMI after top  20.0 % nodes: 0.731\n",
      "Max NMI:  0.734\n",
      " --- Zhengmix8eq (top 20.0%): PageRank | res:  0.05\n",
      "NMI baseline: 0.688\n",
      "NMI Louvain twice: 0.69\n",
      "Number of nodes not included:  102\n",
      "NMI after top  20.0 % nodes: 0.711\n",
      "Max NMI:  0.717\n",
      " --- Zhengmix8eq (top 20.0%): FL + log(n) hops | res:  0.25\n",
      "NMI baseline: 0.782\n",
      "NMI Louvain twice: 0.801\n",
      "Number of nodes not included:  252\n",
      "NMI after top  20.0 % nodes: 0.797\n",
      "Max NMI:  0.797\n",
      " --- Zhengmix8eq (top 20.0%): FL_ng + log(n) hops | res:  0.25\n",
      "NMI baseline: 0.782\n",
      "NMI Louvain twice: 0.802\n",
      "Number of nodes not included:  89\n",
      "NMI after top  20.0 % nodes: 0.768\n",
      "Max NMI:  0.772\n",
      " --- Zhengmix8eq (top 20.0%): FL_ng_prop + log(n) hops | res:  0.25\n",
      "NMI baseline: 0.782\n",
      "NMI Louvain twice: 0.8\n",
      "Number of nodes not included:  129\n",
      "NMI after top  20.0 % nodes: 0.768\n",
      "Max NMI:  0.774\n",
      " --- Zhengmix8eq (top 20.0%): PageRank | res:  0.25\n",
      "NMI baseline: 0.782\n",
      "NMI Louvain twice: 0.792\n",
      "Number of nodes not included:  148\n",
      "NMI after top  20.0 % nodes: 0.82\n",
      "Max NMI:  0.829\n",
      " --- Zhengmix8eq (top 20.0%): FL + log(n) hops | res:  0.5\n",
      "NMI baseline: 0.802\n",
      "NMI Louvain twice: 0.772\n",
      "Number of nodes not included:  272\n",
      "NMI after top  20.0 % nodes: 0.787\n",
      "Max NMI:  0.79\n",
      " --- Zhengmix8eq (top 20.0%): FL_ng + log(n) hops | res:  0.5\n",
      "NMI baseline: 0.802\n",
      "NMI Louvain twice: 0.748\n",
      "Number of nodes not included:  178\n",
      "NMI after top  20.0 % nodes: 0.772\n",
      "Max NMI:  0.787\n",
      " --- Zhengmix8eq (top 20.0%): FL_ng_prop + log(n) hops | res:  0.5\n",
      "NMI baseline: 0.802\n",
      "NMI Louvain twice: 0.73\n",
      "Number of nodes not included:  126\n",
      "NMI after top  20.0 % nodes: 0.744\n",
      "Max NMI:  0.758\n",
      " --- Zhengmix8eq (top 20.0%): PageRank | res:  0.5\n",
      "NMI baseline: 0.802\n",
      "NMI Louvain twice: 0.761\n",
      "Number of nodes not included:  607\n",
      "NMI after top  20.0 % nodes: 0.807\n",
      "Max NMI:  0.821\n",
      " --- Zhengmix8eq (top 20.0%): FL + log(n) hops | res:  1\n",
      "NMI baseline: 0.745\n",
      "NMI Louvain twice: 0.762\n",
      "Number of nodes not included:  341\n",
      "NMI after top  20.0 % nodes: 0.786\n",
      "Max NMI:  0.792\n",
      " --- Zhengmix8eq (top 20.0%): FL_ng + log(n) hops | res:  1\n",
      "NMI baseline: 0.745\n",
      "NMI Louvain twice: 0.749\n",
      "Number of nodes not included:  178\n",
      "NMI after top  20.0 % nodes: 0.748\n",
      "Max NMI:  0.762\n",
      " --- Zhengmix8eq (top 20.0%): FL_ng_prop + log(n) hops | res:  1\n",
      "NMI baseline: 0.745\n",
      "NMI Louvain twice: 0.73\n",
      "Number of nodes not included:  312\n",
      "NMI after top  20.0 % nodes: 0.745\n",
      "Max NMI:  0.771\n",
      " --- Zhengmix8eq (top 20.0%): PageRank | res:  1\n",
      "NMI baseline: 0.745\n",
      "NMI Louvain twice: 0.731\n",
      "Number of nodes not included:  768\n",
      "NMI after top  20.0 % nodes: 0.76\n",
      "Max NMI:  0.786\n",
      " --- Zhengmix8eq (top 20.0%): FL + log(n) hops | res:  1.5\n",
      "NMI baseline: 0.692\n",
      "NMI Louvain twice: 0.715\n",
      "Number of nodes not included:  374\n",
      "NMI after top  20.0 % nodes: 0.768\n",
      "Max NMI:  0.776\n",
      " --- Zhengmix8eq (top 20.0%): FL_ng + log(n) hops | res:  1.5\n",
      "NMI baseline: 0.692\n",
      "NMI Louvain twice: 0.689\n",
      "Number of nodes not included:  205\n",
      "NMI after top  20.0 % nodes: 0.735\n",
      "Max NMI:  0.755\n",
      " --- Zhengmix8eq (top 20.0%): FL_ng_prop + log(n) hops | res:  1.5\n",
      "NMI baseline: 0.692\n",
      "NMI Louvain twice: 0.706\n",
      "Number of nodes not included:  375\n",
      "NMI after top  20.0 % nodes: 0.71\n",
      "Max NMI:  0.734\n",
      " --- Zhengmix8eq (top 20.0%): PageRank | res:  1.5\n",
      "NMI baseline: 0.692\n",
      "NMI Louvain twice: 0.69\n",
      "Number of nodes not included:  780\n",
      "NMI after top  20.0 % nodes: 0.749\n",
      "Max NMI:  0.772\n",
      " --- Zhengmix8eq (top 20.0%): FL + log(n) hops | res:  5\n",
      "NMI baseline: 0.606\n",
      "NMI Louvain twice: 0.622\n",
      "Number of nodes not included:  1403\n",
      "NMI after top  20.0 % nodes: 0.687\n",
      "Max NMI:  0.711\n",
      " --- Zhengmix8eq (top 20.0%): FL_ng + log(n) hops | res:  5\n",
      "NMI baseline: 0.606\n",
      "NMI Louvain twice: 0.619\n",
      "Number of nodes not included:  1186\n",
      "NMI after top  20.0 % nodes: 0.672\n",
      "Max NMI:  0.706\n",
      " --- Zhengmix8eq (top 20.0%): FL_ng_prop + log(n) hops | res:  5\n",
      "NMI baseline: 0.606\n",
      "NMI Louvain twice: 0.621\n",
      "Number of nodes not included:  1053\n",
      "NMI after top  20.0 % nodes: 0.663\n",
      "Max NMI:  0.694\n",
      " --- Zhengmix8eq (top 20.0%): PageRank | res:  5\n",
      "NMI baseline: 0.606\n",
      "NMI Louvain twice: 0.608\n",
      "Number of nodes not included:  1849\n",
      "NMI after top  20.0 % nodes: 0.645\n",
      "Max NMI:  0.684\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 52\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmRNA\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmiRNA\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;129;01mand\u001b[39;00m survive\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m---> 52\u001b[0m G, label\u001b[38;5;241m=\u001b[39m \u001b[43mdata_to_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43msurvive\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     53\u001b[0m cluster_sizes \u001b[38;5;241m=\u001b[39m defaultdict(\u001b[38;5;28mint\u001b[39m)\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m G\u001b[38;5;241m.\u001b[39mnodes():\n",
      "File \u001b[1;32mi:\\내 드라이브\\backup\\document\\USC\\Research\\MCPC\\Code\\Codes\\New_Cleaned\\subgraph.py:159\u001b[0m, in \u001b[0;36mdata_to_graph\u001b[1;34m(name, survive)\u001b[0m\n\u001b[0;32m    154\u001b[0m     \u001b[38;5;66;03m#print(\"Dataset names is \",name,\" |V|, |E| #clusters= \",n,len(edge_list),len(set(label)))\u001b[39;00m\n\u001b[0;32m    155\u001b[0m \n\u001b[0;32m    156\u001b[0m \u001b[38;5;66;03m#These are for the bulk-RNA datasets.\u001b[39;00m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmRNA\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmiRNA\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;66;03m#for survive in [0,1]:\u001b[39;00m\n\u001b[1;32m--> 159\u001b[0m     edge_list,vlist,label,n\u001b[38;5;241m=\u001b[39m\u001b[43mdata_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlocal_bulkRNA\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43msurvive\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    160\u001b[0m     label\u001b[38;5;241m=\u001b[39mdata_util\u001b[38;5;241m.\u001b[39mset_labels(label)\n\u001b[0;32m    161\u001b[0m     \u001b[38;5;66;03m#print(\"Dataset names is \",name,\" |V|, |E| #clusters= \",n,len(edge_list),len(set(label)))\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \n\u001b[0;32m    163\u001b[0m \u001b[38;5;66;03m#These contain image and document data.\u001b[39;00m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;66;03m#datanames=['FashionMNIST','MNIST','seeds','breast-cancer','Omniglot','bbc_news','20NewsGroups','biorxiv','big_patent']\u001b[39;00m\n",
      "File \u001b[1;32mi:\\내 드라이브\\backup\\document\\USC\\Research\\MCPC\\Code\\Codes\\New_Cleaned\\data_utils_ch.py:632\u001b[0m, in \u001b[0;36mlocal_bulkRNA\u001b[1;34m(name, survive)\u001b[0m\n\u001b[0;32m    630\u001b[0m     x3\u001b[38;5;241m=\u001b[39mdf_labels2[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSample ID\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProject ID\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[0;32m    631\u001b[0m     dfl\u001b[38;5;241m=\u001b[39mx3\u001b[38;5;241m.\u001b[39mto_numpy()\n\u001b[1;32m--> 632\u001b[0m     dfr\u001b[38;5;241m=\u001b[39m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdatapath1\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmRNA_pc_gene_raw.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    633\u001b[0m     Xdf\u001b[38;5;241m=\u001b[39mdfr\u001b[38;5;241m.\u001b[39mto_numpy()\n\u001b[0;32m    635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m(survive\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m1\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\io\\parsers\\readers.py:626\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[1;32m--> 626\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\io\\parsers\\readers.py:1923\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1916\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[0;32m   1917\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1918\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[0;32m   1919\u001b[0m     (\n\u001b[0;32m   1920\u001b[0m         index,\n\u001b[0;32m   1921\u001b[0m         columns,\n\u001b[0;32m   1922\u001b[0m         col_dict,\n\u001b[1;32m-> 1923\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[0;32m   1924\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[0;32m   1925\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1926\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1927\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:234\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[1;32m--> 234\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    235\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[0;32m    236\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[1;32mparsers.pyx:838\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:905\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:874\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:891\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:2053\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m<frozen codecs>:331\u001b[0m, in \u001b[0;36mgetstate\u001b[1;34m(self)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import Cust_Top as Cust\n",
    "import networkx.algorithms.community.louvain as Louv\n",
    "from sklearn.metrics.cluster import normalized_mutual_info_score as NMI\n",
    "from collections import deque\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import os\n",
    "from subgraph import * \n",
    "import time \n",
    "import debug\n",
    "from collections import defaultdict\n",
    "\n",
    "res_=[] #0.26, 0.24 is best for Louvain, 3.3, 2.0\n",
    "labels=[]\n",
    "total_labels=[]\n",
    "names = []\n",
    "\n",
    "data_names = ['Zhengmix8eq','mRNA','miRNA','FashionMNIST','MNIST','seeds','breast-cancer','Omniglot','bbc_news','20NewsGroups_tfdif','biorxiv','big_patent','Cora','Cora full','Citeseer','Eu core']\n",
    "#data_names = ['mRNA','miRNA','FashionMNIST','MNIST','seeds','breast-cancer','Omniglot','bbc_news','20NewsGroups_tfdif','biorxiv','big_patent','Cora','Cora full','Citeseer','Eu core']\n",
    "#data_names = ['mRNA']\n",
    "#data_names = ['Zhengmix8eq']\n",
    "'''\n",
    "datasets with nodes that have no outgoing edges : \n",
    "['Cora full', 'Citeseer', 'Eu core']\n",
    "'''\n",
    "#data_names = ['Cora full', 'Citeseer', 'Eu core']\n",
    "# FR_ord = ['Rd', 'Ord']\n",
    "# FR_Recalc = ['FR_avg', 'FR_Re']\n",
    "FR_tp = ['FL','FL_ng','FL_ng_prop','PageRank']\n",
    "FR_tp_short = ['FL','FL_ng','FL_ng_p','PR']\n",
    "Num_hops = {0:'5',1:'log(n)'}\n",
    "Mod_tp = {0: 'Louv'}\n",
    "\n",
    "#top k% nodes for induced subgraph\n",
    "k=0.2\n",
    "traverse = {0:'Reset',1:'Static'}\n",
    "ord = {0:'Rand',1:'FR_order'}\n",
    "\n",
    "#list of plotted figures\n",
    "figures = []\n",
    "\n",
    "for data in data_names: \n",
    "    pdf_name = './Plots/'+data+'/fixed_'+data+'.pdf'\n",
    "    \n",
    "    \n",
    "    for survive in [0]:\n",
    "        '''\n",
    "        Get the Graph from Edge_List and get the labels\n",
    "        '''\n",
    "        #DO not recalculate Graph for non bulk RNA datasets\n",
    "        if data not in ['mRNA','miRNA'] and survive==1:\n",
    "            continue\n",
    "        G, label= data_to_graph(data,survive)\n",
    "        cluster_sizes = defaultdict(int)\n",
    "        for node in G.nodes():\n",
    "            cluster_sizes[label[node]]+=1\n",
    "        #print('Selected Labels:',selected_labels_dict)\n",
    "        #add self loop to nodes without outgoing edges\n",
    "        #G_ is copy of G\n",
    "        G_ = G.copy()\n",
    "        # if (data in ['Cora full', 'Citeseer', 'Eu core']):\n",
    "        #     for node in G.nodes():\n",
    "        #         if not list(G.successors(node)):\n",
    "        #             G_.remove_node(node)\n",
    "        for node in G_.nodes():\n",
    "            if not list(G_.successors(node)):\n",
    "                #print(data, ' has a node without outgoing edges:',node)\n",
    "                G_.add_edge(node, node, weight=1)\n",
    "        print('Number of nodes:',G.number_of_nodes())\n",
    "        \n",
    "\n",
    "        data_directory = f'./Plots/{data}'\n",
    "        file_path = f'{data_directory}/{data}.txt'\n",
    "        os.makedirs(data_directory, exist_ok=True)\n",
    "        with open(file_path, 'w') as f:\n",
    "            f.write('------------------------------------------------------------------------\\n')\n",
    "        \n",
    "        \n",
    "            \n",
    "        for Num_hop in [1]:\n",
    "            plt.figure(figsize=(10,15)) # figure for NMI vs purity\n",
    "            plt.figure(figsize=(10,6)) # figure for NMI vs Purity (whole)\n",
    "            plt.figure(figsize=(10,15)) # figure for NMI\n",
    "            plt.figure(figsize=(10,15)) # figure for Purity\n",
    "            plt.figure(figsize=(10,15)) # figure for preserve_ratio\n",
    "            plt.figure(figsize=(10,15)) # figure for balancedness\n",
    "            plt.figure(figsize=(10,15)) # figure for InEdge Degrees\n",
    "            #List of FR_values\n",
    "            FR_precalculated = []\n",
    "            for fr_type in range(4): \n",
    "                '''\n",
    "                Calculate FlowRank for the whole graph\n",
    "                '''\n",
    "                if Num_hop==0:\n",
    "                    node2FR = calc_FlowRank(G_, fr_type, 5)\n",
    "                else:\n",
    "                    node2FR = calc_FlowRank(G_, fr_type, np.log2(G.number_of_nodes()))\n",
    "                FR_precalculated.append(node2FR)\n",
    "\n",
    "            for idx, res in enumerate([0.05,0.25, 0.5, 1, 1.5, 5]):\n",
    "            #for idx, res in enumerate([0.05]):\n",
    "            #for idx, res in enumerate([0.01,0.03,0.05,0.1,0.15,0.2]):\n",
    "                for Mod_type in [0]:\n",
    "                    ''' \n",
    "                    Louvain on G (baseline)\n",
    "                    '''\n",
    "                    #start_time = time.time()\n",
    "                    partition = debug.louvain_partitions(G, seed=0,resolution=res)\n",
    "                    partition_ = deque(partition, maxlen=1).pop()\n",
    "                    label_ = part_to_full_label(partition_,G.number_of_nodes())\n",
    "                    NMI_baseline = NMI(label_, label)\n",
    "                    Purity_baseline = met.purity_score(label, label_)\n",
    "                    \n",
    "                    #print('Time Louvain on whole G:', time.time()-start_time)\n",
    "                    for FR_type in range(4):\n",
    "                        name =  data + ' (top ' + str(k*100) + '%): '+ str(FR_tp[FR_type]) + ' + '+ str(Num_hops[Num_hop]) +' hops'\n",
    "                        if FR_type==3:\n",
    "                            name = data + ' (top ' + str(k*100) + '%): PageRank'\n",
    "                        if data in ['mRNA','miRNA']:\n",
    "                            name = data +  ' (top ' + str(k*100) + '%): '+ str(FR_tp[FR_type]) + ' + '+ str(Num_hops[Num_hop]) +' hops' + ' + Survive: '+str(survive)\n",
    "                            if FR_type==3:\n",
    "                                name = data + ' (top ' + str(k*100) + '%): PageRank' + ' + Survive: '+str(survive)\n",
    "                        print(' ---',name,'| res: ',str(res))\n",
    "                        \n",
    "                        # Create the directory if it doesn't exist\n",
    "                        os.makedirs(data_directory, exist_ok=True)\n",
    "                        with open(file_path, 'a') as f:\n",
    "                            f.write(' ---'+name+'| res: '+str(res)+'\\n')\n",
    "                            f.write('NMI baseline: ' + str(round(NMI_baseline,3)) + '\\n')\n",
    "                        \n",
    "\n",
    "                        '''\n",
    "                        Get induced subgraph of top k% nodes in FR value\n",
    "                        '''\n",
    "                        node2FR = FR_precalculated[FR_type]\n",
    "                        \n",
    "                        # if data in ['Cora full', 'Citeseer', 'Eu core']:\n",
    "                        #     for node in G.nodes():\n",
    "                        #         if not list(G.successors(node)):\n",
    "                        #             node2FR[node]=0\n",
    "\n",
    "                        node_list = sorted(G.nodes, key=lambda x: node2FR[x], reverse=True)\n",
    "                        #print('Time sort:', time.time()-start_time)\n",
    "                        \n",
    "                        k_ = int(k*len(node_list))\n",
    "                        top_nodes = node_list[:k_]\n",
    "                        H = getInducedSubgraph(G, top_nodes) # H = induced subgraph\n",
    "                        #print('Time Induced Subgraph:', time.time()-start_time)\n",
    "                        \n",
    "                        '''\n",
    "                        label counts for balancedness calculation\n",
    "                        '''\n",
    "                        selected_labels_dict = defaultdict(int)\n",
    "                        for node in H.nodes():\n",
    "                            selected_labels_dict[label[node]]+=1\n",
    "                        \n",
    "\n",
    "                        '''\n",
    "                        Louvain on the subgraph H \n",
    "                        '''\n",
    "                        # partition = RC10.louvain_partitions(H, seed=0,resolution=res, FR_type=FR_type, Mod_type=Mod_type)\n",
    "                        #partition = Louv.louvain_partitions(H, seed=0,resolution=res ,threshold=0.0001)\n",
    "                        \n",
    "                        partition = debug.louvain_partitions(H, seed=0,resolution=res)\n",
    "                        partition_ = deque(partition, maxlen=1).pop()\n",
    "                        H_label = part_to_full_label(partition_,G.number_of_nodes())\n",
    "                        #print('Time Louvain:', time.time()-start_time)\n",
    "        \n",
    "                        '''Run Louvain Again on the rest ( Warm Start )'''\n",
    "                        #start_time = time.time()\n",
    "\n",
    "                        k_ = int(k*len(node_list))\n",
    "                        nodes_rest = node_list[k_:]\n",
    "                        \n",
    "                        for node in nodes_rest:\n",
    "                            partition_.append({node})\n",
    "                        part = Cust.louvain_partitions(G, seed=0,resolution=res,init_part=partition_)\n",
    "                        part_ = deque(part, maxlen=1).pop()\n",
    "                        label_ = part_to_full_label(part_,G.number_of_nodes())\n",
    "                        NMI_twice = NMI(label_, label)\n",
    "                        Purity_twice = met.purity_score(label, label_)\n",
    "                        #print('Time Louvain twice:', time.time()-start_time)\n",
    "                        print('NMI baseline:', round(NMI_baseline,3))\n",
    "                        print('NMI Louvain twice:', round(NMI_twice,3))\n",
    "\n",
    "\n",
    "                        '''\n",
    "                        Add nodes to the subgraph by strong majority vote\n",
    "                        '''\n",
    "                        #See the trend by adding node to the subgraph by strong majority vote (in order of FlowRank Value)\n",
    "                        \n",
    "                        #print('H_label: ',H_label, 'len: ',len(H_label))\n",
    "                        \n",
    "                        \n",
    "                        #start_time = time.time()\n",
    "                        NMI_List, Purity_List, Balance_List, Preserv_List, InEdge_List = merge_by_vote(top_nodes, nodes_rest, H_label, G, label, selected_labels_dict, cluster_sizes)\n",
    "                        #print('Time merge by vote:', time.time()-start_time)\n",
    "                        \n",
    "                        #Plot NMI_List\n",
    "                        fig_numbers = plt.get_fignums()\n",
    "                        NMI_vs_Purity = fig_numbers[-7]\n",
    "                        NMI_vs_Purity_whole = fig_numbers[-6]\n",
    "                        nmi_fig =fig_numbers[-5]\n",
    "                        purity_fig = fig_numbers[-4]\n",
    "                        preserve_fig = fig_numbers[-3]\n",
    "                        balance_fig = fig_numbers[-2]\n",
    "                        InEdge_fig = fig_numbers[-1]\n",
    "                        \n",
    "\n",
    "                        max_dot_size = 100\n",
    "                        #plot NMI vs Purity\n",
    "                        markers = ['o','s','*','^','h','D'] #idx (resolution)\n",
    "                        colors = ['b','g','y','r'] #FR_type\n",
    "                        plt.figure(NMI_vs_Purity)\n",
    "                        plt.subplot(3,2,idx+1)\n",
    "                        percent_nodes = (H.number_of_nodes() + len(NMI_List))*100 / G.number_of_nodes()\n",
    "                        #plt.scatter(Purity_List[-1], NMI_List[-1], color = colors[FR_type], s = percent_nodes*max_dot_size, marker = markers[idx],label = str(FR_tp[FR_type])+ '|'+str(round(percent_nodes,2))+ '% nodes')\n",
    "                        plt.scatter(Purity_List[-1], NMI_List[-1], color = colors[FR_type], s = percent_nodes/100*max_dot_size,label = str(FR_tp[FR_type])+ '|'+str(round(percent_nodes,2))+ '% nodes')\n",
    "                        if FR_type==0:\n",
    "                            plt.scatter(Purity_baseline, NMI_baseline, color = 'k', s = max_dot_size,label = 'Louv_baseline')\n",
    "                            #plt.scatter(Purity_baseline, NMI_baseline, color = 'k', s = max_dot_size*0.5, marker = markers[idx],label = 'Louv_baseline|'+str(res))\n",
    "                        #plt.scatter(Purity_twice, NMI_twice, color = 'm', s = max_dot_size, marker = markers[idx],label = '2*Louv|'+str(res))\n",
    "\n",
    "                        #plot NMI vs Purity (whole)\n",
    "                        plt.figure(NMI_vs_Purity_whole)\n",
    "                        plt.scatter(Purity_List[-1], NMI_List[-1], color = colors[FR_type], s = percent_nodes/100*max_dot_size, marker = markers[idx],label = str(FR_tp[FR_type])+ '|'+str(res)+'|'+str(round(percent_nodes,2))+ '% nodes')\n",
    "                        if FR_type==0:\n",
    "                            plt.scatter(Purity_baseline, NMI_baseline, color = 'k', s = max_dot_size, marker = markers[idx],label = 'Louv_baseline|'+str(res))\n",
    "                        #plt.scatter(Purity_twice, NMI_twice, color = 'm', s = max_dot_size, marker = markers[idx],label = '2*Louv|'+str(res))\n",
    "\n",
    "                        #plot NMI\n",
    "                        plt.figure(nmi_fig)\n",
    "                        plt.subplot(3, 2, idx+1)\n",
    "                        plt.plot(NMI_List,  color = colors[FR_type], label = str(FR_tp[FR_type]))\n",
    "\n",
    "                        if FR_type==0: \n",
    "                            #Horizontal Line for Baselines\n",
    "                            NMI_baseline_list = [NMI_baseline]*len(nodes_rest)\n",
    "                            plt.plot(NMI_baseline_list, label = 'Louv_baseline')\n",
    "                        NMI_Louv_twice_list = [NMI_twice]*len(nodes_rest)\n",
    "                        plt.plot(NMI_Louv_twice_list, label = '2*Louv|'+str(FR_tp_short[FR_type]))\n",
    "                        \n",
    "                        with open(file_path, 'a') as f:\n",
    "                            f.write('# of nodes not included: ' + str(G.number_of_nodes() - H.number_of_nodes() - len(NMI_List)+1) + '\\n')\n",
    "                            f.write('NMI_Louvain_twice: ' + str(round(NMI_twice,3)) + '\\n')\n",
    "                            f.write('NMI after top ' + str(k*100) + '% nodes: ' + str(round(NMI_List[0],3)) + '\\n')\n",
    "                            f.write('Max NMI: ' + str(round(max(NMI_List),3)) + '\\n')\n",
    "                        print('Number of nodes not included: ' , G.number_of_nodes() - H.number_of_nodes() - len(NMI_List)+1) \n",
    "                        print('NMI after top ', k*100, '% nodes:', round(NMI_List[0],3))\n",
    "                        print('Max NMI: ', round(max(NMI_List),3))\n",
    "\n",
    "                        #plot Purity\n",
    "                        plt.figure(purity_fig)\n",
    "                        plt.subplot(3, 2, idx+1)\n",
    "                        plt.plot(Purity_List,  color = colors[FR_type], label = str(FR_tp[FR_type]))\n",
    "                        if FR_type==0: \n",
    "                            #Horizontal Line for Baselines\n",
    "                            Purity_baseline_list = [Purity_baseline]*len(nodes_rest)\n",
    "                            plt.plot(Purity_baseline_list, label = 'Louv_baseline')\n",
    "                    \n",
    "                        Purity_Louv_twice_list = [Purity_twice]*len(nodes_rest)\n",
    "                        plt.plot(Purity_Louv_twice_list, label = '2*Louv|'+str(FR_tp_short[FR_type]))\n",
    "                        \n",
    "                        with open(file_path, 'a') as f:\n",
    "                            f.write('Purity_Louvain_twice: ' + str(round(Purity_twice,3)) + '\\n')\n",
    "                            f.write('Purity after top ' + str(k*100) + '% nodes: ' + str(round(Purity_List[0],3)) + '\\n')\n",
    "                            f.write('Max Purity: ' + str(round(max(Purity_List),3)) + '\\n')\n",
    "\n",
    "                        #plot preserve_ratio\n",
    "                        plt.figure(preserve_fig)\n",
    "                        plt.subplot(3, 2, idx+1)\n",
    "                        plt.plot(Preserv_List,  color = colors[FR_type], label = str(FR_tp[FR_type]))\n",
    "\n",
    "                        #plot balancedness\n",
    "                        plt.figure(balance_fig)\n",
    "                        plt.subplot(3, 2, idx+1)\n",
    "                        plt.plot(Balance_List,  color = colors[FR_type], label = str(FR_tp[FR_type])) \n",
    "\n",
    "                        #plot InEdge Degrees\n",
    "                        plt.figure(InEdge_fig)\n",
    "                        plt.subplot(3, 2, idx+1)\n",
    "                        plt.plot(InEdge_List,  color = colors[FR_type], label = str(FR_tp[FR_type]))\n",
    "                    \n",
    "                plt.figure(NMI_vs_Purity)\n",
    "                plt.tight_layout()\n",
    "                plt.subplot(3,2,idx+1)\n",
    "                plt.xlabel('Purity')\n",
    "                plt.ylabel('NMI')\n",
    "                plt.title(data + ' | top ' + str(k*100) + '%' + '| Num_hops: ' + str(Num_hops[Num_hop]) + '|res: ' + str(res)+ '|')\n",
    "                #plt.legend()\n",
    "                plt.legend()\n",
    "\n",
    "                plt.figure(NMI_vs_Purity_whole)\n",
    "                plt.xlabel('Purity')\n",
    "                plt.ylabel('NMI')\n",
    "                plt.title(data + ' | top ' + str(k*100) + '%' + '| Num_hops: ' + str(Num_hops[Num_hop]))\n",
    "                #plt.legend()\n",
    "                plt.legend(loc='center left', bbox_to_anchor=(1, 0.5), fontsize=8)\n",
    "                plt.tight_layout(rect=[0, 0, 0.85, 1])\n",
    "\n",
    "                plt.figure(nmi_fig)\n",
    "                plt.tight_layout()\n",
    "                plt.subplot(3, 2, idx+1)    \n",
    "                #Plot all at once\n",
    "                plt.xlabel('Number of nodes added after top ' + str(k*100) + '% nodes')\n",
    "                plt.ylabel('NMI')\n",
    "                plt.title(data + ' | top ' + str(k*100) + '%' + '| Num_hops: ' + str(Num_hops[Num_hop]) + '|res: ' + str(res)+ '|')\n",
    "                plt.legend()\n",
    "\n",
    "                plt.figure(purity_fig)\n",
    "                plt.tight_layout()\n",
    "                plt.subplot(3, 2, idx+1)\n",
    "                #Plot all at once\n",
    "                plt.xlabel('Number of nodes added after top ' + str(k*100) + '% nodes')\n",
    "                plt.ylabel('Purity')\n",
    "                plt.title(data + ' | top ' + str(k*100) + '%' + '| Num_hops: ' + str(Num_hops[Num_hop]) + '|res: ' + str(res)+ '|')\n",
    "                plt.legend()\n",
    "\n",
    "                plt.figure(preserve_fig)\n",
    "                plt.tight_layout()\n",
    "                plt.subplot(3, 2, idx+1)\n",
    "                #Plot all at once\n",
    "                plt.xlabel('Number of nodes added after top ' + str(k*100) + '% nodes')\n",
    "                plt.ylabel('Preserve Ratio')\n",
    "                plt.title(data + ' | top ' + str(k*100) + '%' + '| Num_hops: ' + str(Num_hops[Num_hop]) + '|res: ' + str(res)+ '|')\n",
    "                plt.legend()\n",
    "\n",
    "                plt.figure(balance_fig)\n",
    "                plt.tight_layout()\n",
    "                plt.subplot(3, 2, idx+1)\n",
    "                #Plot all at once\n",
    "                plt.xlabel('Number of nodes added after top ' + str(k*100) + '% nodes')\n",
    "                plt.ylabel('Balancedness')\n",
    "                plt.title(data + ' | top ' + str(k*100) + '%' + '| Num_hops: ' + str(Num_hops[Num_hop]) + '|res: ' + str(res)+ '|')\n",
    "                plt.legend()\n",
    "\n",
    "                plt.figure(InEdge_fig)\n",
    "                plt.tight_layout()\n",
    "                plt.subplot(3, 2, idx+1)\n",
    "                #Plot all at once\n",
    "                plt.xlabel('Number of nodes added after top ' + str(k*100) + '% nodes')\n",
    "                plt.ylabel('InEdge Degrees')\n",
    "                plt.title(data + ' | top ' + str(k*100) + '%' + '| Num_hops: ' + str(Num_hops[Num_hop]) + '|res: ' + str(res)+ '|')\n",
    "                plt.legend()\n",
    "    \n",
    "    \n",
    "    p = PdfPages(pdf_name)            \n",
    "    fig_nums = plt.get_fignums() \n",
    "    figs = [plt.figure(n) for n in fig_nums] \n",
    "\t\n",
    "\t# iterating over the numbers in list \n",
    "    for fig in figs: \n",
    "\t\t# and saving the files \n",
    "        fig.savefig(p, format='pdf') \n",
    "\t\n",
    "\t# close the object \n",
    "    p.close() \n",
    "    plt.close('all')\n",
    "    \n",
    "        \n",
    "            \n",
    "\n",
    "                                \n",
    "                    \n",
    "\n",
    "                    \n",
    "                    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
