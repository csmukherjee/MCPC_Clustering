{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "#sys.path.append('/Users/chandrasekharmukherjee/Home/Centrality framework/Modules')\n",
    "\n",
    "#Import packages\n",
    "#imports\n",
    "import time\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import sknetwork\n",
    "\n",
    "\n",
    "from sknetwork.ranking import PageRank\n",
    "from sknetwork.ranking import Betweenness\n",
    "from sknetwork.ranking import Closeness\n",
    "\n",
    "import umap as umap\n",
    "\n",
    "from numba.typed import List\n",
    "import warnings\n",
    "from numba import njit\n",
    "import pynndescent\n",
    "import numpy as np\n",
    "from sklearn.cluster import SpectralClustering\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import operator\n",
    "from sklearn.utils.extmath import randomized_svd\n",
    "from random import randint\n",
    "from sklearn.utils.extmath import randomized_svd\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import scipy\n",
    "from umap.umap_ import *\n",
    "import math\n",
    "from random import randint\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.datasets import cifar10\n",
    "from keras.datasets import cifar100\n",
    "from keras.datasets import fashion_mnist\n",
    "import scanpy\n",
    "from sklearn.metrics.cluster import normalized_mutual_info_score\n",
    "from sklearn.metrics import adjusted_mutual_info_score, roc_auc_score\n",
    "from sklearn.metrics.cluster import adjusted_rand_score\n",
    "from sklearn.metrics.cluster import adjusted_mutual_info_score\n",
    "\n",
    "import community as community_louvain\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import fowlkes_mallows_score\n",
    "\n",
    "import scipy\n",
    "\n",
    "import igraph \n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import importlib\n",
    "\n",
    "import metric as met \n",
    "import embedding as embed   \n",
    "import data_utils_ch as data_util\n",
    "\n",
    "\n",
    "met=importlib.reload(met)\n",
    "embed=importlib.reload(embed)\n",
    "data_util=importlib.reload(data_util)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (/Users/chandrasekharmukherjee/.cache/huggingface/datasets/mteb___json/mteb--twentynewsgroups-clustering-770ea5c2eedc7237/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4)\n",
      "100%|██████████| 1/1 [00:00<00:00, 306.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20NewsGroups_tfdif (10909, 50)\n",
      "20 19\n",
      "Dataset names is  20NewsGroups_tfdif  |V|, |E| #clusters=  10909 109090 20\n",
      "42 41\n",
      "Dataset names is  Cora  |V|, |E| #clusters=  1005 25571 42\n",
      "42 41\n",
      "Dataset names is  Cora full  |V|, |E| #clusters=  1005 25571 42\n",
      "42 41\n",
      "Dataset names is  Citeseer  |V|, |E| #clusters=  1005 25571 42\n",
      "42 41\n",
      "Dataset names is  Eu core  |V|, |E| #clusters=  1005 25571 42\n"
     ]
    }
   ],
   "source": [
    "#This is to get the edge_lists.\n",
    "\n",
    "#scRNA datasets\n",
    "datanames=['Zhengmix8eq']\n",
    "for name in datanames:\n",
    "    edge_list,vlist,n,label=data_util.local_SCRNA(name)\n",
    "    print(\"Dataset names is \",name,\" |V|, |E| #clusters= \",n,len(edge_list),len(set(label)))\n",
    "\n",
    "\n",
    "#These are for the bulk-RNA datasets.\n",
    "datanames=['mRNA','miRNA']\n",
    "for name in datanames:\n",
    "    for survive in [0,1]:\n",
    "        edge_list,vlist,label,n=data_util.local_bulkRNA(name,survive)\n",
    "        label=data_util.set_labels(label)\n",
    "        print(\"Dataset names is \",name,\" |V|, |E| #clusters= \",n,len(edge_list),len(set(label)))\n",
    "\n",
    "\n",
    "\n",
    "#These contain image and document data.\n",
    "datanames=['FashionMNIST','MNIST','seeds','breast-cancer','Omniglot','bbc_news','20NewsGroups','biorxiv','big_patent']\n",
    "for name in datanames:\n",
    "    edge_list, label=data_util.load_data(name,kchoice=10)\n",
    "    n=len(label)\n",
    "    vlist=[i for i in range(n)]\n",
    "    label=data_util.set_labels(label)\n",
    "\n",
    "    print(\"Dataset names is \",name,\" |V|, |E| #clusters= \",n,len(edge_list),len(set(label)))\n",
    "\n",
    "\n",
    "#These are data of 4 popular directed graphs. \n",
    "graphnames=['Cora','Cora full','Citeseer','Eu core']\n",
    "for name in graphnames:\n",
    "    edge_list,vlist,label,n,good_v=data_util.graph_database(name)\n",
    "    label=data_util.set_labels(label)\n",
    "\n",
    "    print(\"Dataset names is \",name,\" |V|, |E| #clusters= \",n,len(edge_list),len(set(label)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zhengmix8eq 3994\n",
      "Log transform done\n",
      "(3994, 50)\n",
      "Accuracy of  15 -NN graph is 0.791\n",
      "59910\n"
     ]
    }
   ],
   "source": [
    "#To get the raw data.\n",
    "\n",
    "#scRNA datasets\n",
    "datanames=['Zhengmix8eq']\n",
    "for name in datanames:\n",
    "    X,n,label=data_util.local_SCRNA(name,raw=1)\n",
    "\n",
    "\n",
    "\n",
    "#These are for the bulk-RNA datasets.\n",
    "datanames=['mRNA','miRNA']\n",
    "for name in datanames:\n",
    "    for survive in [0,1]:\n",
    "        X,label,n=data_util.local_bulkRNA(name,survive)\n",
    "        label=data_util.set_labels(label)\n",
    "\n",
    "\n",
    "\n",
    "#These contain image and document data.\n",
    "datanames=['FashionMNIST','MNIST','seeds','breast-cancer','Omniglot','bbc_news','20NewsGroups','biorxiv','big_patent']\n",
    "for name in datanames:\n",
    "    X,label=data_util.load_data(name,raw=1)\n",
    "    n=len(label)\n",
    "    label=data_util.set_labels(label)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
