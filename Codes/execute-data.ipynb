{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "#sys.path.append('/Users/chandrasekharmukherjee/Home/Centrality framework/Modules')\n",
    "sys.path.append('I:/내 드라이브/backup/document/USC/Research/MCPC/Code/Codes')\n",
    "\n",
    "#Import packages\n",
    "#imports\n",
    "import time\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import sknetwork\n",
    "\n",
    "\n",
    "from sknetwork.ranking import PageRank\n",
    "from sknetwork.ranking import Betweenness\n",
    "from sknetwork.ranking import Closeness\n",
    "\n",
    "#import umap as umap\n",
    "\n",
    "from numba.typed import List\n",
    "import warnings\n",
    "from numba import njit\n",
    "import pynndescent\n",
    "import numpy as np\n",
    "from sklearn.cluster import SpectralClustering\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import operator\n",
    "from sklearn.utils.extmath import randomized_svd\n",
    "from random import randint\n",
    "from sklearn.utils.extmath import randomized_svd\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import scipy\n",
    "#from umap.umap_ import *\n",
    "import math\n",
    "from random import randint\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.datasets import cifar10\n",
    "from keras.datasets import cifar100\n",
    "from keras.datasets import fashion_mnist\n",
    "import scanpy\n",
    "from sklearn.metrics.cluster import normalized_mutual_info_score\n",
    "from sklearn.metrics import adjusted_mutual_info_score, roc_auc_score\n",
    "from sklearn.metrics.cluster import adjusted_rand_score\n",
    "from sklearn.metrics.cluster import adjusted_mutual_info_score\n",
    "\n",
    "#import community as community_louvain\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import fowlkes_mallows_score\n",
    "\n",
    "import scipy\n",
    "\n",
    "import igraph \n",
    "import networkx as nx\n",
    "\n",
    "\n",
    "import metric as met \n",
    "import embedding as embed   \n",
    "import data_utils_ch as data_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "hi\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import importlib\n",
    "\n",
    "import metric as met \n",
    "import embedding as embed   \n",
    "import data_utils_ch as data_util\n",
    "\n",
    "\n",
    "met=importlib.reload(met)\n",
    "embed=importlib.reload(embed)\n",
    "data_util=importlib.reload(data_util)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get edge Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zhengmix8eq 3994\n",
      "Log transform done\n",
      "(3994, 50)\n",
      "Accuracy of  15 -NN graph is 0.792\n",
      "59910\n",
      "Dataset names is  Zhengmix8eq  |V|, |E| #clusters=  3994 59910 8\n",
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "(11235, 19939)\n",
      "selected vertices  11235\n",
      "(11235,) Counter({'TCGA-BRCA': 1226, 'TCGA-KIRC': 610, 'TCGA-LUAD': 589, 'TCGA-UCEC': 585, 'TCGA-THCA': 572, 'TCGA-HNSC': 566, 'TCGA-PRAD': 554, 'TCGA-LUSC': 552, 'TCGA-LGG': 534, 'TCGA-COAD': 514, 'TCGA-SKCM': 473, 'TCGA-STAD': 448, 'TCGA-OV': 429, 'TCGA-BLCA': 428, 'TCGA-LIHC': 424, 'TCGA-KIRP': 323, 'TCGA-CESC': 309, 'TCGA-SARC': 265, 'TCGA-ESCA': 198, 'TCGA-PCPG': 187, 'TCGA-PAAD': 183, 'TCGA-READ': 177, 'TCGA-GBM': 174, 'TCGA-TGCT': 156, 'TCGA-LAML': 151, 'TCGA-THYM': 122, 'TCGA-KICH': 91, 'TCGA-MESO': 87, 'TCGA-UVM': 80, 'TCGA-ACC': 79, 'TCGA-UCS': 57, 'TCGA-DLBC': 48, 'TCGA-CHOL': 44})\n",
      "33 32\n",
      "Dataset names is  mRNA  |V|, |E| #clusters=  11235 168525 33\n",
      "[ 5  6 10 11 12 14 16 17 25 26]\n",
      "(9737, 19939)\n",
      "selected vertices  9737\n",
      "(9737,) Counter({0: 6980, 1: 2757})\n",
      "2 1\n",
      "Dataset names is  mRNA  |V|, |E| #clusters=  9737 146055 2\n",
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "(11020, 1882)\n",
      "selected vertices  11020\n",
      "(11020,) Counter({'TCGA-BRCA': 1202, 'TCGA-KIRC': 592, 'TCGA-UCEC': 575, 'TCGA-THCA': 573, 'TCGA-HNSC': 569, 'TCGA-LUAD': 564, 'TCGA-PRAD': 551, 'TCGA-LGG': 530, 'TCGA-LUSC': 523, 'TCGA-OV': 498, 'TCGA-STAD': 477, 'TCGA-COAD': 461, 'TCGA-SKCM': 452, 'TCGA-BLCA': 432, 'TCGA-LIHC': 425, 'TCGA-KIRP': 326, 'TCGA-CESC': 312, 'TCGA-SARC': 263, 'TCGA-ESCA': 198, 'TCGA-LAML': 188, 'TCGA-PCPG': 187, 'TCGA-PAAD': 183, 'TCGA-READ': 165, 'TCGA-TGCT': 156, 'TCGA-THYM': 126, 'TCGA-KICH': 91, 'TCGA-MESO': 87, 'TCGA-UVM': 80, 'TCGA-ACC': 80, 'TCGA-UCS': 57, 'TCGA-DLBC': 47, 'TCGA-CHOL': 45, 'TCGA-GBM': 5})\n",
      "33 32\n",
      "Dataset names is  miRNA  |V|, |E| #clusters=  11020 165300 33\n",
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "(9664, 1882)\n",
      "selected vertices  9664\n",
      "(9664,) Counter({0: 6944, 1: 2720})\n",
      "2 1\n",
      "Dataset names is  miRNA  |V|, |E| #clusters=  9664 144960 2\n",
      "FashionMNIST (30000, 50)\n",
      "10 9\n",
      "Dataset names is  FashionMNIST  |V|, |E| #clusters=  30000 300000 10\n",
      "MNIST (30000, 50)\n",
      "10 9\n",
      "Dataset names is  MNIST  |V|, |E| #clusters=  30000 300000 10\n",
      "seeds (209, 7)\n",
      "3 2\n",
      "Dataset names is  seeds  |V|, |E| #clusters=  209 2090 3\n",
      "2 1\n",
      "Dataset names is  breast-cancer  |V|, |E| #clusters=  569 5690 2\n",
      "Files already downloaded and verified\n",
      "964 963\n",
      "Dataset names is  Omniglot  |V|, |E| #clusters=  10000 100000 964\n",
      "bbc_news (1490, 50)\n",
      "5 4\n",
      "Dataset names is  bbc_news  |V|, |E| #clusters=  1490 14900 5\n",
      "biorxiv (68131, 50)\n",
      "26 25\n",
      "Dataset names is  biorxiv  |V|, |E| #clusters=  68131 681310 26\n",
      "big_patent (17064, 50)\n",
      "9 8\n",
      "Dataset names is  big_patent  |V|, |E| #clusters=  17064 170640 9\n",
      "7 6\n",
      "Dataset names is  Cora  |V|, |E| #clusters=  2485 10138 7\n",
      "70 69\n",
      "Dataset names is  Cora full  |V|, |E| #clusters=  23166 89157 70\n",
      "Validation for `citeseer_labels` and `citeseer_features` passes.\n",
      "7 6\n",
      "Dataset names is  Citeseer  |V|, |E| #clusters=  2120 3768 7\n",
      "42 41\n",
      "Dataset names is  Eu core  |V|, |E| #clusters=  1005 25571 42\n"
     ]
    }
   ],
   "source": [
    "#This is to get the edge_lists.\n",
    "\n",
    "#scRNA datasets\n",
    "datanames=['Zhengmix8eq']\n",
    "for name in datanames:\n",
    "    edge_list,vlist,n,label=data_util.local_SCRNA(name)\n",
    "    print(\"Dataset names is \",name,\" |V|, |E| #clusters= \",n,len(edge_list),len(set(label)))\n",
    "\n",
    "\n",
    "#These are for the bulk-RNA datasets.\n",
    "datanames=['mRNA','miRNA']\n",
    "for name in datanames:\n",
    "    for survive in [0,1]:\n",
    "        edge_list,vlist,label,n=data_util.local_bulkRNA(name,survive)\n",
    "        label=data_util.set_labels(label)\n",
    "        print(\"Dataset names is \",name,\" |V|, |E| #clusters= \",n,len(edge_list),len(set(label)))\n",
    "\n",
    "\n",
    "\n",
    "#These contain image and document data.\n",
    "#datanames=['FashionMNIST','MNIST','seeds','breast-cancer','Omniglot','bbc_news','20NewsGroups','biorxiv','big_patent']\n",
    "datanames=['FashionMNIST','MNIST','seeds','breast-cancer','Omniglot','bbc_news','20NewsGroups_tfdif','biorxiv','big_patent']\n",
    "for name in datanames:\n",
    "    edge_list, label=data_util.load_data(name,kchoice=10)\n",
    "    n=len(label)\n",
    "    vlist=[i for i in range(n)]\n",
    "    label=data_util.set_labels(label)\n",
    "\n",
    "    print(\"Dataset names is \",name,\" |V|, |E| #clusters= \",n,len(edge_list),len(set(label)))\n",
    "\n",
    "\n",
    "#These are data of 4 popular directed graphs. \n",
    "graphnames=['Cora','Cora full','Citeseer','Eu core']\n",
    "for name in graphnames:\n",
    "    edge_list,vlist,label,n,good_v=data_util.graph_database(name)\n",
    "    label=data_util.set_labels(label)\n",
    "\n",
    "    print(\"Dataset names is \",name,\" |V|, |E| #clusters= \",n,len(edge_list),len(set(label)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "local_SCRNA() got an unexpected keyword argument 'raw'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m datanames\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mZhengmix8eq\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m datanames:\n\u001b[1;32m----> 6\u001b[0m     X,n,label\u001b[38;5;241m=\u001b[39m\u001b[43mdata_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlocal_SCRNA\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43mraw\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m#These are for the bulk-RNA datasets.\u001b[39;00m\n\u001b[0;32m     11\u001b[0m datanames\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmRNA\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmiRNA\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mTypeError\u001b[0m: local_SCRNA() got an unexpected keyword argument 'raw'"
     ]
    }
   ],
   "source": [
    "#To get the raw data.\n",
    "\n",
    "#scRNA datasets\n",
    "datanames=['Zhengmix8eq']\n",
    "for name in datanames:\n",
    "    X,n,label=data_util.local_SCRNA(name,raw=1)\n",
    "\n",
    "\n",
    "\n",
    "#These are for the bulk-RNA datasets.\n",
    "datanames=['mRNA','miRNA']\n",
    "for name in datanames:\n",
    "    for survive in [0,1]:\n",
    "        X,label,n=data_util.local_bulkRNA(name,survive)\n",
    "        label=data_util.set_labels(label)\n",
    "\n",
    "\n",
    "\n",
    "#These contain image and document data.\n",
    "#datanames=['FashionMNIST','MNIST','seeds','breast-cancer','Omniglot','bbc_news','20NewsGroups','biorxiv','big_patent']\n",
    "datanames=['FashionMNIST','MNIST','seeds','breast-cancer','Omniglot','bbc_news','biorxiv','big_patent']\n",
    "for name in datanames:\n",
    "    X,label=data_util.load_data(name,raw=1)\n",
    "    n=len(label)\n",
    "    label=data_util.set_labels(label)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing every dataset with top k % nodes induced subgraph (Louvain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for Tok k% induced Subgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import FlowRank_General as FR\n",
    "from sklearn.metrics.cluster import normalized_mutual_info_score as NMI\n",
    "def getInducedSubgraph(G, k, node2FR): #G = original graph, k = pick top k percent, node2FR = node to FR value\n",
    "    #Get top k% nodes\n",
    "    node_list = sorted(G.nodes, key=lambda x: node2FR[x], reverse=True)\n",
    "    k = int(k*len(node_list))\n",
    "    top_nodes = node_list[:k]\n",
    "    #Remove nodes also remove adjacent edges\n",
    "    H = G.copy()\n",
    "    for u in G.nodes:\n",
    "        if u not in top_nodes:\n",
    "            H.remove_node(u)\n",
    "    return H\n",
    "\n",
    "def FlowRank_Func(edge_list,vlist,walk_len_c1,c_const=0,type=0):\n",
    "    if type==0:\n",
    "        return FR.FLOW(edge_list,vlist,walk_len_c1,c_const)\n",
    "    elif type==1:\n",
    "        return FR.FLOW_ng(edge_list,vlist,walk_len_c1,c_const)\n",
    "    elif type==2:\n",
    "        return FR.FLOW_ng_prop(edge_list,vlist,walk_len_c1,c_const)\n",
    "\n",
    "def calc_FlowRank(graph, FR_type, walk_len_c1):\n",
    "    node2FR = dict()\n",
    "    if FR_type==3:\n",
    "        pg_rank = nx.pagerank(graph,alpha=0.85) #alpha = 0.85 is the default\n",
    "        node2FR = {k: pg_rank[k]*graph.number_of_nodes() for k in pg_rank}\n",
    "    else:\n",
    "        for i in FlowRank_Func(graph.edges(),graph.nodes(),walk_len_c1,0,FR_type):\n",
    "            node_num = int(i[1])\n",
    "            node2FR[node_num] = i[0]\n",
    "    return node2FR\n",
    "\n",
    "def part_to_label(partition,H,original_n): #partition to labels\n",
    "    #Mapping node numbers to index\n",
    "        \n",
    "    label_1=[-1]*(original_n+1)\n",
    "    c=0\n",
    "    for sets in partition:\n",
    "        for ell in sets:\n",
    "            label_1[ell]=c\n",
    "        \n",
    "        c=c+1\n",
    "    \n",
    "    label_compressed = []\n",
    "    for i in sorted(H.nodes()):\n",
    "        if label_1[i] == -1: \n",
    "            print('Error: Node not found in partition')\n",
    "            return None\n",
    "        label_compressed.append([label_1[i]])\n",
    "    #print(label_compressed)\n",
    "    return label_compressed\n",
    "\n",
    "def get_NMI(H, partition, label, original_n):\n",
    "    #Keep the labels of the nodes in subgraph G only\n",
    "    new_label = []\n",
    "    for i in sorted(H.nodes()):\n",
    "        #print('node: ',i)\n",
    "        new_label.append(label[i])\n",
    "    #change the partition form {[node2,node4], [,...,]} to label form {[0,2,1,2,grp#,...]}\n",
    "    part_label = part_to_label(partition,H, original_n)\n",
    "    \n",
    "    arr = np.array(part_label)\n",
    "    arr = arr.flatten()\n",
    "    nmi = NMI(arr, new_label)\n",
    "    return nmi\n",
    "\n",
    "def get_Purity(H, partition, label, original_n):\n",
    "    #Keep the labels of the nodes in subgraph G only\n",
    "    new_label = []\n",
    "    for i in sorted(H.nodes()):\n",
    "        #print('node: ',i)\n",
    "        new_label.append(label[i])\n",
    "    #change the partition form {[node2,node4], [,...,]} to label form {[0,2,1,2,grp#,...]}\n",
    "    part_label = part_to_label(partition,H, original_n)\n",
    "    \n",
    "    arr = np.array(part_label)\n",
    "    arr = arr.flatten()\n",
    "    purity = met.purity_score(arr, new_label)\n",
    "    return purity\n",
    "\n",
    "def relabel_graph(H): #compress the node numberings \n",
    "    mapping = dict(zip(H.nodes(), range(H.number_of_nodes())))\n",
    "    H = nx.relabel_nodes(H, mapping)\n",
    "    return H\n",
    "\n",
    "def check_if_has_edge(H, partition_):\n",
    "    for i in H.nodes():\n",
    "        for j in H.nodes():\n",
    "            if i!=j and H.has_edge(i,j):\n",
    "                #find i in partition_\n",
    "                for k in range(len(partition_)):\n",
    "                    if i in partition_[k]:\n",
    "                        if j not in partition_[k]:\n",
    "                            print('Edge between nodes:',i,j) #Edge between two different communities\n",
    "    return\n",
    "\n",
    "# def make_graph(edge_list):\n",
    "#     G = nx.Graph(edge_list)\n",
    "#     return G\n",
    "                                            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Dataset into a NetworkX Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_to_graph(name, survive=0):\n",
    "    #scRNA datasets\n",
    "    if name in ['Zhengmix8eq']:\n",
    "        edge_list,vlist,n,label=data_util.local_SCRNA(name)\n",
    "        #print(\"Dataset names is \",name,\" |V|, |E| #clusters= \",n,len(edge_list),len(set(label)))\n",
    "\n",
    "    #These are for the bulk-RNA datasets.\n",
    "    elif name in ['mRNA','miRNA']:\n",
    "        #for survive in [0,1]:\n",
    "        edge_list,vlist,label,n=data_util.local_bulkRNA(name,survive)\n",
    "        label=data_util.set_labels(label)\n",
    "        #print(\"Dataset names is \",name,\" |V|, |E| #clusters= \",n,len(edge_list),len(set(label)))\n",
    "\n",
    "    #These contain image and document data.\n",
    "    #datanames=['FashionMNIST','MNIST','seeds','breast-cancer','Omniglot','bbc_news','20NewsGroups','biorxiv','big_patent']\n",
    "    elif name in ['FashionMNIST','MNIST','seeds','breast-cancer','Omniglot','bbc_news','20NewsGroups_tfdif','biorxiv','big_patent']:\n",
    "        edge_list, label=data_util.load_data(name,kchoice=10)\n",
    "        n=len(label)\n",
    "        vlist=[i for i in range(n)]\n",
    "        label=data_util.set_labels(label)\n",
    "        #print(\"Dataset names is \",name,\" |V|, |E| #clusters= \",n,len(edge_list),len(set(label)))\n",
    "\n",
    "\n",
    "    #These are data of 4 popular directed graphs. \n",
    "    elif name in ['Cora','Cora full','Citeseer','Eu core']:\n",
    "        edge_list,vlist,label,n,good_v=data_util.graph_database(name)\n",
    "        label=data_util.set_labels(label)\n",
    "        #print(\"Dataset names is \",name,\" |V|, |E| #clusters= \",n,len(edge_list),len(set(label)))\n",
    "    \n",
    "    G = nx.DiGraph(edge_list)\n",
    "    return G, label\n",
    "\n",
    "def write_out(data, name, max_nmi, max_purity):\n",
    "    with open('./Results/'+data+'.txt', 'a') as f:\n",
    "        f.write(name+'\\n')\n",
    "    with open('./Results/'+data+'.txt', 'a') as f:\n",
    "        f.write('   Max NMI = [' + str(round(max_nmi[0],3)) + ',' + str(round(max_nmi[1],3)) + ']' + ' res:= ' + str(round(max_nmi[2],3)) + '\\n')\n",
    "    \n",
    "    with open('./Results/'+data+'.txt', 'a') as f:\n",
    "        f.write('   Partition sizes: [')\n",
    "    for i in max_nmi[4]:\n",
    "        #print(len(i),end=' ')\n",
    "        with open('./Results/'+data+'.txt', 'a') as f:\n",
    "            f.write(str(len(i))+', ')\n",
    "    with open('./Results/'+data+'.txt', 'a') as f:\n",
    "        f.write('] ' + '# of comm: ' + str(len(max_nmi[4]))+ '\\n')\n",
    "    \n",
    "    \n",
    "    with open('./Results/'+data+'.txt', 'a') as f:\n",
    "        f.write('   Max Purity = [' + str(round(max_purity[0],3)) + ',' + str(round(max_purity[1],3)) + ']' + ' res:= ' + str(round(max_purity[2],3)) + '\\n')\n",
    "    with open('./Results/'+data+'.txt', 'a') as f:\n",
    "        f.write('   Partition sizes: [')\n",
    "    for i in max_purity[4]:\n",
    "        with open('./Results/'+data+'.txt', 'a') as f:\n",
    "            f.write(str(len(i))+', ')\n",
    "    with open('./Results/'+data+'.txt', 'a') as f:\n",
    "        f.write('] ' + '# of comm: ' + str(len(max_purity[4]))+ '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Top K subgraph testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zhengmix8eq 3994\n",
      "Log transform done\n",
      "(3994, 50)\n",
      "Accuracy of  15 -NN graph is 0.792\n",
      "59910\n",
      "Number of nodes: 3994\n",
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "(11235, 19939)\n",
      "selected vertices  11235\n",
      "(11235,) Counter({'TCGA-BRCA': 1226, 'TCGA-KIRC': 610, 'TCGA-LUAD': 589, 'TCGA-UCEC': 585, 'TCGA-THCA': 572, 'TCGA-HNSC': 566, 'TCGA-PRAD': 554, 'TCGA-LUSC': 552, 'TCGA-LGG': 534, 'TCGA-COAD': 514, 'TCGA-SKCM': 473, 'TCGA-STAD': 448, 'TCGA-OV': 429, 'TCGA-BLCA': 428, 'TCGA-LIHC': 424, 'TCGA-KIRP': 323, 'TCGA-CESC': 309, 'TCGA-SARC': 265, 'TCGA-ESCA': 198, 'TCGA-PCPG': 187, 'TCGA-PAAD': 183, 'TCGA-READ': 177, 'TCGA-GBM': 174, 'TCGA-TGCT': 156, 'TCGA-LAML': 151, 'TCGA-THYM': 122, 'TCGA-KICH': 91, 'TCGA-MESO': 87, 'TCGA-UVM': 80, 'TCGA-ACC': 79, 'TCGA-UCS': 57, 'TCGA-DLBC': 48, 'TCGA-CHOL': 44})\n",
      "33 32\n",
      "Number of nodes: 11235\n",
      "[ 5  6 10 11 12 14 16 17 25 26]\n",
      "(9737, 19939)\n",
      "selected vertices  9737\n",
      "(9737,) Counter({0: 6980, 1: 2757})\n",
      "2 1\n",
      "Number of nodes: 9737\n",
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "(11020, 1882)\n",
      "selected vertices  11020\n",
      "(11020,) Counter({'TCGA-BRCA': 1202, 'TCGA-KIRC': 592, 'TCGA-UCEC': 575, 'TCGA-THCA': 573, 'TCGA-HNSC': 569, 'TCGA-LUAD': 564, 'TCGA-PRAD': 551, 'TCGA-LGG': 530, 'TCGA-LUSC': 523, 'TCGA-OV': 498, 'TCGA-STAD': 477, 'TCGA-COAD': 461, 'TCGA-SKCM': 452, 'TCGA-BLCA': 432, 'TCGA-LIHC': 425, 'TCGA-KIRP': 326, 'TCGA-CESC': 312, 'TCGA-SARC': 263, 'TCGA-ESCA': 198, 'TCGA-LAML': 188, 'TCGA-PCPG': 187, 'TCGA-PAAD': 183, 'TCGA-READ': 165, 'TCGA-TGCT': 156, 'TCGA-THYM': 126, 'TCGA-KICH': 91, 'TCGA-MESO': 87, 'TCGA-UVM': 80, 'TCGA-ACC': 80, 'TCGA-UCS': 57, 'TCGA-DLBC': 47, 'TCGA-CHOL': 45, 'TCGA-GBM': 5})\n",
      "33 32\n",
      "Number of nodes: 11020\n",
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "(9664, 1882)\n",
      "selected vertices  9664\n",
      "(9664,) Counter({0: 6944, 1: 2720})\n",
      "2 1\n",
      "Number of nodes: 9664\n",
      "FashionMNIST (30000, 50)\n",
      "10 9\n",
      "Number of nodes: 30000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[60], line 80\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m res_list:\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;66;03m#partition = RC10.louvain_partitions(H, seed=0,resolution=res,FR_order=FR_order, FR_Recalc=FR_Rec, FR_type=FR_type, Mod_type=Mod_type)\u001b[39;00m\n\u001b[0;32m     78\u001b[0m     partition \u001b[38;5;241m=\u001b[39m Louv\u001b[38;5;241m.\u001b[39mlouvain_partitions(H, seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,resolution\u001b[38;5;241m=\u001b[39mres)\n\u001b[1;32m---> 80\u001b[0m     partition_ \u001b[38;5;241m=\u001b[39m \u001b[43mdeque\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpartition\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxlen\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mpop()\n\u001b[0;32m     82\u001b[0m     nmi_ \u001b[38;5;241m=\u001b[39m get_NMI(H,partition_,label, G\u001b[38;5;241m.\u001b[39mnumber_of_nodes())\n\u001b[0;32m     83\u001b[0m     purity_ \u001b[38;5;241m=\u001b[39m get_Purity(H,partition_,label, G\u001b[38;5;241m.\u001b[39mnumber_of_nodes())\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\networkx\\algorithms\\community\\louvain.py:206\u001b[0m, in \u001b[0;36mlouvain_partitions\u001b[1;34m(G, weight, resolution, threshold, seed)\u001b[0m\n\u001b[0;32m    203\u001b[0m     graph\u001b[38;5;241m.\u001b[39madd_weighted_edges_from(G\u001b[38;5;241m.\u001b[39medges(data\u001b[38;5;241m=\u001b[39mweight, default\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m    205\u001b[0m m \u001b[38;5;241m=\u001b[39m graph\u001b[38;5;241m.\u001b[39msize(weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweight\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 206\u001b[0m partition, inner_partition, improvement \u001b[38;5;241m=\u001b[39m \u001b[43m_one_level\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    207\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartition\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresolution\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_directed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\n\u001b[0;32m    208\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m improvement \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m improvement:\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;66;03m# gh-5901 protect the sets in the yielded list from further manipulation here\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\networkx\\algorithms\\community\\louvain.py:275\u001b[0m, in \u001b[0;36m_one_level\u001b[1;34m(G, m, partition, resolution, is_directed, seed)\u001b[0m\n\u001b[0;32m    273\u001b[0m best_mod \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    274\u001b[0m best_com \u001b[38;5;241m=\u001b[39m node2com[u]\n\u001b[1;32m--> 275\u001b[0m weights2com \u001b[38;5;241m=\u001b[39m \u001b[43m_neighbor_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbrs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mu\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode2com\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    276\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_directed:\n\u001b[0;32m    277\u001b[0m     in_degree \u001b[38;5;241m=\u001b[39m in_degrees[u]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\networkx\\algorithms\\community\\louvain.py:346\u001b[0m, in \u001b[0;36m_neighbor_weights\u001b[1;34m(nbrs, node2com)\u001b[0m\n\u001b[0;32m    344\u001b[0m weights \u001b[38;5;241m=\u001b[39m defaultdict(\u001b[38;5;28mfloat\u001b[39m)\n\u001b[0;32m    345\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m nbr, wt \u001b[38;5;129;01min\u001b[39;00m nbrs\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m--> 346\u001b[0m     weights[node2com[nbr]] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m wt\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m weights\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import analysis as an\n",
    "#import Cust_Final as RC10\n",
    "import networkx.algorithms.community.louvain as Louv\n",
    "from sklearn.metrics.cluster import normalized_mutual_info_score as NMI\n",
    "from collections import deque\n",
    "\n",
    "res_=[] #0.26, 0.24 is best for Louvain, 3.3, 2.0\n",
    "labels=[]\n",
    "total_labels=[]\n",
    "names = []\n",
    "\n",
    "data_names = ['Zhengmix8eq','mRNA','miRNA','FashionMNIST','MNIST','seeds','breast-cancer','Omniglot','bbc_news','20NewsGroups_tfdif','biorxiv','big_patent','Cora','Cora full','Citeseer','Eu core']\n",
    "# FR_ord = ['Rd', 'Ord']\n",
    "# FR_Recalc = ['FR_avg', 'FR_Re']\n",
    "FR_tp = ['FL','FL_ng','FL_ng_prop','PageRank']\n",
    "Num_hops = ['5','log(n)']\n",
    "Mod_tp = {0: 'Louv'}\n",
    "\n",
    "for data in data_names: \n",
    "    for survive in [0,1]:\n",
    "        '''\n",
    "        Get the Graph from Edge_List and get the labels\n",
    "        '''\n",
    "        #DO not recalculate Graph for non bulk RNA datasets\n",
    "        if data not in ['mRNA','miRNA'] and survive==1:\n",
    "            continue\n",
    "        G, label= data_to_graph(data,survive)\n",
    "        print('Number of nodes:',G.number_of_nodes())\n",
    "        #get unique entry in label\n",
    "        with open('./Results/'+data+'.txt', 'a') as f:\n",
    "            f.write('True Labels: [')\n",
    "            for i in list(set(label)):\n",
    "                f.write(str(i)+', ')\n",
    "            f.write('] # of Comms: ' + str(len(list(set(label))))+ '\\n')\n",
    "\n",
    "        for Num_hop in [0,1]:\n",
    "            for FR_type in range(4):\n",
    "                for Mod_type in [0]:\n",
    "                    #skip survive for non bulk RNA datasets\n",
    "                    if data not in ['mRNA','miRNA'] and survive==1:\n",
    "                        continue\n",
    "                    #Do pagerank once only (No different hops for PageRank)\n",
    "                    if FR_type==3 and Num_hop==0:\n",
    "                        continue\n",
    "\n",
    "                    name =  data + ': '+ str(FR_tp[FR_type]) + ' + '+ str(Num_hops[Num_hop]) +' hops'\n",
    "                    if FR_type==3:\n",
    "                        name = data + ': PageRank'\n",
    "                    if data in ['mRNA','miRNA']:\n",
    "                        name = data + ': '+ str(FR_tp[FR_type]) + ' + '+ str(Num_hops[Num_hop]) +' hops' + ' + Survive: '+str(survive)\n",
    "                        if FR_type==3:\n",
    "                            name = data + ': PageRank' + ' + Survive: '+str(survive)\n",
    "                    #print(name)\n",
    "                    \n",
    "                    \n",
    "                    '''\n",
    "                    Get induced subgraph of top k% nodes in FR value\n",
    "                    '''\n",
    "                    #Get induced subgraph\n",
    "                    if Num_hop==0:\n",
    "                        node2FR = calc_FlowRank(G, FR_type, 5)\n",
    "                    else:\n",
    "                        node2FR = calc_FlowRank(G, FR_type, np.log2(G.number_of_nodes()))\n",
    "                    H = getInducedSubgraph(G, 0.2, node2FR)\n",
    "                    #print('Number of nodes in subgraph:',H.number_of_nodes())\n",
    "\n",
    "                    '''\n",
    "                    Calculate NMI and Purity for different resolutions\n",
    "                    '''\n",
    "                    max_nmi = (0,0,0,0,[]) # (nmi, purity, res, FR_type, partition)\n",
    "                    max_purity = (0,0,0,0,[])\n",
    "                    res_list = []\n",
    "                    for i in range(40):\n",
    "                        res_list.append(i/20+0.01)\n",
    "                    \n",
    "                    for res in res_list:\n",
    "                        #partition = RC10.louvain_partitions(H, seed=0,resolution=res,FR_order=FR_order, FR_Recalc=FR_Rec, FR_type=FR_type, Mod_type=Mod_type)\n",
    "                        partition = Louv.louvain_partitions(H, seed=0,resolution=res)\n",
    "\n",
    "                        partition_ = deque(partition, maxlen=1).pop()\n",
    "\n",
    "                        nmi_ = get_NMI(H,partition_,label, G.number_of_nodes())\n",
    "                        purity_ = get_Purity(H,partition_,label, G.number_of_nodes())\n",
    "                        #print('NMI:', nmi_,'res:',res)\n",
    "                        if nmi_>max_nmi[0]:\n",
    "                            max_nmi = (nmi_,purity_,res,FR_type,partition_)\n",
    "                        if purity_>max_purity[1]:\n",
    "                            max_purity = (nmi_,purity_,res,FR_type,partition_)\n",
    "                    '''\n",
    "                    Write the results to Results folder\n",
    "                    '''\n",
    "                    write_out(data, name, max_nmi, max_purity)\n",
    "                    #print(' Max NMI = [' , round(max_nmi[0],3), ',', round(max_nmi[1],3), ']', ' res:= ', round(max_nmi[2],3))\n",
    "                    #print('Partition sizes:',end=' ')\n",
    "                    # for i in max_nmi[4]:\n",
    "                    #     print(len(i),end=' ')\n",
    "                    # print()  \n",
    "                    # \n",
    "                    #  #print(' Max Purity = [' , round(max_purity[0],3), ',', round(max_purity[1],3), ']', ' res:= ', round(max_purity[2],3))\n",
    "                    # #print('Partition sizes:',end=' ')\n",
    "                    # for i in max_purity[4]:\n",
    "                    #    print(len(i),end=' ')\n",
    "                    # print()  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Louv + Cust-Louv on All Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, deque\n",
    "\n",
    "def get_labels(partition,n_s):\n",
    "    #final_partition_1 = deque(partition, maxlen=1).pop()\n",
    "    #print(final_partition_1)\n",
    "\n",
    "\n",
    "    label_1=np.zeros((n_s))\n",
    "    c=0\n",
    "    for sets in partition:\n",
    "        for ell in sets:\n",
    "            label_1[ell]=c\n",
    "        \n",
    "        c=c+1\n",
    "\n",
    "    return label_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "(11020, 1882)\n",
      "selected vertices  11020\n",
      "(11020,) Counter({'TCGA-BRCA': 1202, 'TCGA-KIRC': 592, 'TCGA-UCEC': 575, 'TCGA-THCA': 573, 'TCGA-HNSC': 569, 'TCGA-LUAD': 564, 'TCGA-PRAD': 551, 'TCGA-LGG': 530, 'TCGA-LUSC': 523, 'TCGA-OV': 498, 'TCGA-STAD': 477, 'TCGA-COAD': 461, 'TCGA-SKCM': 452, 'TCGA-BLCA': 432, 'TCGA-LIHC': 425, 'TCGA-KIRP': 326, 'TCGA-CESC': 312, 'TCGA-SARC': 263, 'TCGA-ESCA': 198, 'TCGA-LAML': 188, 'TCGA-PCPG': 187, 'TCGA-PAAD': 183, 'TCGA-READ': 165, 'TCGA-TGCT': 156, 'TCGA-THYM': 126, 'TCGA-KICH': 91, 'TCGA-MESO': 87, 'TCGA-UVM': 80, 'TCGA-ACC': 80, 'TCGA-UCS': 57, 'TCGA-DLBC': 47, 'TCGA-CHOL': 45, 'TCGA-GBM': 5})\n",
      "33 32\n",
      "Number of nodes: 11020\n",
      "Max NMI:  0.8354813887877923 at res:  0.61\n",
      "Max NMI:  0.8185235033396749 at res:  1.81\n",
      "Max NMI:  0.8342545951244514 at res:  1.81\n",
      "Max NMI:  0.838109425507587 at res:  1.01\n",
      "Max NMI:  0.834690943637039 at res:  1.61\n",
      "Max NMI:  0.8342885942625952 at res:  1.31\n",
      "Max NMI:  0.8389953858482124 at res:  0.71\n",
      "Max NMI:  0.8312823398687794 at res:  0.91\n",
      "Max NMI:  0.8379546572400983 at res:  1.01\n",
      "Max NMI:  0.8335148486762499 at res:  0.71\n",
      "Max NMI:  0.8449473166809709 at res:  0.71\n",
      "Max NMI:  0.8440440764273124 at res:  0.71\n",
      "Max NMI:  0.83927329113676 at res:  1.11\n",
      "FashionMNIST (30000, 50)\n",
      "10 9\n",
      "Number of nodes: 30000\n",
      "Max NMI:  0.654837582255918 at res:  0.11\n",
      "Max NMI:  0.6782661851425367 at res:  1.01\n",
      "Max NMI:  0.6883198471980476 at res:  0.91\n",
      "Max NMI:  0.6648456180234276 at res:  0.21000000000000002\n",
      "Max NMI:  0.6814068053913261 at res:  0.71\n",
      "Max NMI:  0.6938383819249829 at res:  0.51\n",
      "Max NMI:  0.6506220296061536 at res:  0.11\n",
      "Max NMI:  0.672157278853525 at res:  0.71\n",
      "Max NMI:  0.6790725443425111 at res:  0.31\n",
      "Max NMI:  0.6554437369531776 at res:  0.21000000000000002\n",
      "Max NMI:  0.6493724034563358 at res:  0.21000000000000002\n",
      "Max NMI:  0.6651318490638458 at res:  0.31\n",
      "Max NMI:  0.6649135429303811 at res:  0.21000000000000002\n",
      "MNIST (30000, 50)\n",
      "10 9\n",
      "Number of nodes: 30000\n",
      "Max NMI:  0.870845922598212 at res:  0.41000000000000003\n",
      "Max NMI:  0.8380157961541369 at res:  1.41\n",
      "Max NMI:  0.8616893745822647 at res:  1.91\n",
      "Max NMI:  0.8614947308153194 at res:  0.51\n",
      "Max NMI:  0.8640679401478913 at res:  1.31\n",
      "Max NMI:  0.8666943296200704 at res:  1.51\n",
      "Max NMI:  0.8565395011720682 at res:  0.31\n",
      "Max NMI:  0.8638183816594625 at res:  0.81\n",
      "Max NMI:  0.8650253509712094 at res:  1.01\n",
      "Max NMI:  0.865617131958723 at res:  0.41000000000000003\n",
      "Max NMI:  0.8693392112961916 at res:  0.71\n",
      "Max NMI:  0.8605781597034141 at res:  0.51\n",
      "Max NMI:  0.8592437395173104 at res:  0.61\n",
      "seeds (209, 7)\n",
      "3 2\n",
      "Number of nodes: 209\n",
      "Max NMI:  0.6913380568065037 at res:  0.31\n",
      "Max NMI:  0.6913380568065037 at res:  0.41000000000000003\n",
      "Max NMI:  0.6913380568065037 at res:  0.31\n",
      "Max NMI:  0.6432145184560951 at res:  0.31\n",
      "Max NMI:  0.6487994961503221 at res:  0.51\n",
      "Max NMI:  0.6487994961503221 at res:  0.51\n",
      "Max NMI:  0.6913380568065037 at res:  0.31\n",
      "Max NMI:  0.6487994961503221 at res:  0.41000000000000003\n",
      "Max NMI:  0.648799496150322 at res:  0.41000000000000003\n",
      "Max NMI:  0.6913380568065037 at res:  0.31\n",
      "Max NMI:  0.6913380568065037 at res:  0.21000000000000002\n",
      "Max NMI:  0.6913380568065037 at res:  0.21000000000000002\n",
      "Max NMI:  0.6375074716418518 at res:  0.41000000000000003\n",
      "2 1\n",
      "Number of nodes: 569\n",
      "Max NMI:  0.6720173084428747 at res:  0.11\n",
      "Max NMI:  0.7290083273535174 at res:  1.11\n",
      "Max NMI:  0.7087315281517461 at res:  1.61\n",
      "Max NMI:  0.6880675457013685 at res:  0.11\n",
      "Max NMI:  0.6752105677116106 at res:  0.31\n",
      "Max NMI:  0.6689120362705803 at res:  0.21000000000000002\n",
      "Max NMI:  0.6815945697010094 at res:  0.11\n",
      "Max NMI:  0.6689120362705803 at res:  0.21000000000000002\n",
      "Max NMI:  0.6789329929709699 at res:  0.21000000000000002\n",
      "Max NMI:  0.6815945697010094 at res:  0.11\n",
      "Max NMI:  0.6815945697010094 at res:  0.11\n",
      "Max NMI:  0.6815945697010094 at res:  0.11\n",
      "Max NMI:  0.6689120362705803 at res:  0.11\n",
      "Files already downloaded and verified\n",
      "964 963\n",
      "Number of nodes: 10000\n",
      "Max NMI:  0.4381691698649451 at res:  1.91\n",
      "Max NMI:  0.04923767893510363 at res:  1.61\n",
      "Max NMI:  0.08887906125975367 at res:  1.91\n",
      "Max NMI:  0.43767809860348533 at res:  1.91\n",
      "Max NMI:  0.15130661744692644 at res:  1.81\n",
      "Max NMI:  0.24083738287766993 at res:  1.91\n",
      "Max NMI:  0.43906461814516695 at res:  1.91\n",
      "Max NMI:  0.2892109003262288 at res:  1.91\n",
      "Max NMI:  0.324309487290725 at res:  1.91\n",
      "Max NMI:  0.43374124977741696 at res:  1.91\n",
      "Max NMI:  0.4135071301238294 at res:  1.91\n",
      "Max NMI:  0.43108456467450784 at res:  1.91\n",
      "Max NMI:  0.4422538250714023 at res:  1.91\n",
      "bbc_news (1490, 50)\n",
      "5 4\n",
      "Number of nodes: 1490\n",
      "Max NMI:  0.779100457737732 at res:  0.31\n",
      "Max NMI:  0.7937131224936256 at res:  0.81\n",
      "Max NMI:  0.7902133766802835 at res:  0.61\n",
      "Max NMI:  0.7853935170557106 at res:  0.21000000000000002\n",
      "Max NMI:  0.7933275895448313 at res:  0.61\n",
      "Max NMI:  0.8024028883063349 at res:  0.61\n",
      "Max NMI:  0.7836618876482427 at res:  0.31\n",
      "Max NMI:  0.8022494000518512 at res:  0.41000000000000003\n",
      "Max NMI:  0.7823184675321994 at res:  0.51\n",
      "Max NMI:  0.784983156673164 at res:  0.31\n",
      "Max NMI:  0.777001990025863 at res:  0.31\n",
      "Max NMI:  0.781375216411583 at res:  0.31\n",
      "Max NMI:  0.7893137838895493 at res:  0.21000000000000002\n",
      "20NewsGroups_tfdif (10909, 50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MSI\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\scipy\\sparse\\_index.py:145: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 19\n",
      "Number of nodes: 10909\n",
      "Max NMI:  0.3365657118992977 at res:  1.91\n",
      "Max NMI:  0.31730292551202643 at res:  1.81\n",
      "Max NMI:  0.32002212735943963 at res:  1.91\n",
      "Max NMI:  0.34182464951250596 at res:  1.91\n",
      "Max NMI:  0.31955380714913795 at res:  1.81\n",
      "Max NMI:  0.32258372115961387 at res:  1.91\n",
      "Max NMI:  0.3439614162920427 at res:  1.91\n",
      "Max NMI:  0.3229099077110389 at res:  1.51\n",
      "Max NMI:  0.32819282454277704 at res:  1.91\n",
      "Max NMI:  0.34096090096663195 at res:  1.91\n",
      "Max NMI:  0.3426365319321868 at res:  1.91\n",
      "Max NMI:  0.3385641133377422 at res:  1.91\n",
      "Max NMI:  0.3402687193975797 at res:  1.91\n",
      "biorxiv (68131, 50)\n",
      "26 25\n",
      "Number of nodes: 68131\n",
      "Max NMI:  0.36170559657257567 at res:  1.81\n",
      "Max NMI:  0.32608523686253266 at res:  1.81\n",
      "Max NMI:  0.3409331462154175 at res:  1.51\n",
      "Max NMI:  0.365511733997418 at res:  1.61\n",
      "Max NMI:  0.3600729786772639 at res:  1.91\n",
      "Max NMI:  0.3614542689499371 at res:  1.71\n",
      "Max NMI:  0.36294932552347997 at res:  1.51\n",
      "Max NMI:  0.362175457173279 at res:  1.41\n",
      "Max NMI:  0.355308573684311 at res:  1.41\n",
      "Max NMI:  0.3628891692292454 at res:  1.61\n",
      "Max NMI:  0.36246349846027015 at res:  1.91\n",
      "Max NMI:  0.35949036249052685 at res:  1.41\n",
      "Max NMI:  0.3637335941169345 at res:  1.91\n",
      "big_patent (17064, 50)\n",
      "9 8\n",
      "Number of nodes: 17064\n",
      "Max NMI:  0.2429996937712768 at res:  0.81\n",
      "Max NMI:  0.18660657033485215 at res:  1.41\n",
      "Max NMI:  0.20718678763318654 at res:  1.61\n",
      "Max NMI:  0.23707473686770844 at res:  1.41\n",
      "Max NMI:  0.2259831847361313 at res:  1.81\n",
      "Max NMI:  0.23145497690550826 at res:  1.11\n",
      "Max NMI:  0.230866169570062 at res:  1.91\n",
      "Max NMI:  0.2308210864992215 at res:  1.61\n",
      "Max NMI:  0.2263942429185733 at res:  1.61\n",
      "Max NMI:  0.2369063731693719 at res:  1.31\n",
      "Max NMI:  0.23825606477660072 at res:  0.91\n",
      "Max NMI:  0.23724065356060603 at res:  1.41\n",
      "Max NMI:  0.23942911230844438 at res:  1.11\n",
      "7 6\n",
      "Number of nodes: 2485\n",
      "Max NMI:  0.5436693486297722 at res:  0.31\n",
      "Max NMI:  0.5136985066638438 at res:  1.41\n",
      "Max NMI:  0.5048691505418981 at res:  1.11\n",
      "Max NMI:  0.5013381712980784 at res:  0.21000000000000002\n",
      "Max NMI:  0.4989181383502386 at res:  1.91\n",
      "Max NMI:  0.5162583150145351 at res:  1.71\n",
      "Max NMI:  0.5062757995908201 at res:  0.51\n",
      "Max NMI:  0.5126388545694182 at res:  0.61\n",
      "Max NMI:  0.500049311654493 at res:  0.81\n",
      "Max NMI:  0.5225498424693374 at res:  0.41000000000000003\n",
      "Max NMI:  0.5142800446179044 at res:  0.41000000000000003\n",
      "Max NMI:  0.5254489894171995 at res:  0.41000000000000003\n",
      "Max NMI:  0.4519601170736145 at res:  0.31\n",
      "70 69\n",
      "Number of nodes: 23166\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "invalid operation on untyped list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[74], line 79\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m res_list:\n\u001b[0;32m     77\u001b[0m     partition \u001b[38;5;241m=\u001b[39m RC\u001b[38;5;241m.\u001b[39mlouvain_partitions(G, seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,resolution\u001b[38;5;241m=\u001b[39mres,FR_order\u001b[38;5;241m=\u001b[39mFR_order, FR_Recalc\u001b[38;5;241m=\u001b[39mFR_Rec, FR_type\u001b[38;5;241m=\u001b[39mFR_type, Mod_type\u001b[38;5;241m=\u001b[39mMod_type)\n\u001b[1;32m---> 79\u001b[0m     partition_ \u001b[38;5;241m=\u001b[39m \u001b[43mdeque\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpartition\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxlen\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mpop()\n\u001b[0;32m     80\u001b[0m     label_new \u001b[38;5;241m=\u001b[39m get_labels(partition_,G\u001b[38;5;241m.\u001b[39mnumber_of_nodes())\n\u001b[0;32m     82\u001b[0m     nmi_ \u001b[38;5;241m=\u001b[39m NMI(label,label_new)\n",
      "File \u001b[1;32mi:\\내 드라이브\\backup\\document\\USC\\Research\\MCPC\\Code\\Codes\\Cust_Final.py:66\u001b[0m, in \u001b[0;36mlouvain_partitions\u001b[1;34m(G, weight, resolution, threshold, seed, FR_order, FR_Recalc, FR_type, Mod_type, exp_base)\u001b[0m\n\u001b[0;32m     64\u001b[0m     node2FR \u001b[38;5;241m=\u001b[39m {k: pg_rank[k]\u001b[38;5;241m*\u001b[39mgraph\u001b[38;5;241m.\u001b[39mnumber_of_nodes() \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m pg_rank}\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 66\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[43mFlowRank_Func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medges\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnodes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumber_of_nodes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mFR_type\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     67\u001b[0m         node_num \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(i[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m     68\u001b[0m         node2FR[node_num] \u001b[38;5;241m=\u001b[39m i[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mi:\\내 드라이브\\backup\\document\\USC\\Research\\MCPC\\Code\\Codes\\Cust_Final.py:35\u001b[0m, in \u001b[0;36mFlowRank_Func\u001b[1;34m(edge_list, vlist, walk_len_c1, c_const, type)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mFlowRank_Func\u001b[39m(edge_list,vlist,walk_len_c1,c_const\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m---> 35\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mFR\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFLOW\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43mvlist\u001b[49m\u001b[43m,\u001b[49m\u001b[43mwalk_len_c1\u001b[49m\u001b[43m,\u001b[49m\u001b[43mc_const\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m     37\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m FR\u001b[38;5;241m.\u001b[39mFLOW_ng(edge_list,vlist,walk_len_c1,c_const)\n",
      "File \u001b[1;32mi:\\내 드라이브\\backup\\document\\USC\\Research\\MCPC\\Code\\Codes\\FlowRank_General.py:228\u001b[0m, in \u001b[0;36mFLOW\u001b[1;34m(edge_list, vlist, walk_len_c1, c_const)\u001b[0m\n\u001b[0;32m    225\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (u,v) \u001b[38;5;129;01min\u001b[39;00m edge_list:\n\u001b[0;32m    226\u001b[0m     adj_list1[u]\u001b[38;5;241m.\u001b[39mappend(v)\n\u001b[1;32m--> 228\u001b[0m adj_list\u001b[38;5;241m=\u001b[39m\u001b[43mList\u001b[49m\u001b[43m(\u001b[49m\u001b[43mList\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43madj_list1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    230\u001b[0m v_cover_order\u001b[38;5;241m=\u001b[39mflow_calc(adj_list,vlist,walk_len_c1,c_const)\n\u001b[0;32m    233\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m v_cover_order\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\numba\\typed\\typedlist.py:268\u001b[0m, in \u001b[0;36mList.__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    266\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mList() argument must be iterable\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    267\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m args[\u001b[38;5;241m0\u001b[39m]:\n\u001b[1;32m--> 268\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\numba\\typed\\typedlist.py:344\u001b[0m, in \u001b[0;36mList.append\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m    342\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_typed:\n\u001b[0;32m    343\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initialise_list(item)\n\u001b[1;32m--> 344\u001b[0m \u001b[43m_append\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\numba\\core\\dispatcher.py:688\u001b[0m, in \u001b[0;36m_DispatcherBase.typeof_pyval\u001b[1;34m(self, val)\u001b[0m\n\u001b[0;32m    685\u001b[0m \u001b[38;5;66;03m# Not going through the resolve_argument_type() indirection\u001b[39;00m\n\u001b[0;32m    686\u001b[0m \u001b[38;5;66;03m# can save a couple µs.\u001b[39;00m\n\u001b[0;32m    687\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 688\u001b[0m     tp \u001b[38;5;241m=\u001b[39m \u001b[43mtypeof\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mPurpose\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margument\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    689\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[0;32m    690\u001b[0m     tp \u001b[38;5;241m=\u001b[39m types\u001b[38;5;241m.\u001b[39mpyobject\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\numba\\core\\typing\\typeof.py:33\u001b[0m, in \u001b[0;36mtypeof\u001b[1;34m(val, purpose)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Note the behaviour for Purpose.argument must match _typeof.c.\u001b[39;00m\n\u001b[0;32m     32\u001b[0m c \u001b[38;5;241m=\u001b[39m _TypeofContext(purpose)\n\u001b[1;32m---> 33\u001b[0m ty \u001b[38;5;241m=\u001b[39m \u001b[43mtypeof_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ty \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     35\u001b[0m     msg \u001b[38;5;241m=\u001b[39m _termcolor\u001b[38;5;241m.\u001b[39merrmsg(\n\u001b[0;32m     36\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot determine Numba type of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(val)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.1520.0_x64__qbz5n2kfra8p0\\Lib\\functools.py:907\u001b[0m, in \u001b[0;36msingledispatch.<locals>.wrapper\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    903\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[0;32m    904\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfuncname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires at least \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    905\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1 positional argument\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 907\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\numba\\core\\typing\\typeof.py:50\u001b[0m, in \u001b[0;36mtypeof_impl\u001b[1;34m(val, c)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tp \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tp\n\u001b[1;32m---> 50\u001b[0m tp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m_numba_type_\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tp \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tp\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\numba\\typed\\typedlist.py:283\u001b[0m, in \u001b[0;36mList._numba_type_\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    280\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m    281\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_numba_type_\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    282\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_list_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 283\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minvalid operation on untyped list\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    284\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_list_type\n",
      "\u001b[1;31mTypeError\u001b[0m: invalid operation on untyped list"
     ]
    }
   ],
   "source": [
    "import analysis as an\n",
    "import Cust_Final as RC\n",
    "#import networkx.algorithms.community.louvain as Louv\n",
    "from sklearn.metrics.cluster import normalized_mutual_info_score as NMI\n",
    "from collections import deque\n",
    "\n",
    "res_=[] #0.26, 0.24 is best for Louvain, 3.3, 2.0\n",
    "labels=[]\n",
    "total_labels=[]\n",
    "names = []\n",
    "\n",
    "#data_names = ['Zhengmix8eq','mRNA','miRNA','FashionMNIST','MNIST','seeds','breast-cancer','Omniglot','bbc_news','20NewsGroups_tfdif','biorxiv','big_patent','Cora','Cora full','Citeseer','Eu core']\n",
    "data_names = ['miRNA','FashionMNIST','MNIST','seeds','breast-cancer','Omniglot','bbc_news','20NewsGroups_tfdif','biorxiv','big_patent','Cora','Cora full','Citeseer','Eu core']\n",
    "# FR_ord = ['Rd', 'Ord']\n",
    "# FR_Recalc = ['FR_avg', 'FR_Re']\n",
    "FR_ord = ['Rd', 'Ord']\n",
    "FR_Recalc = ['FR_avg', 'FR_Re']\n",
    "FR_tp = ['FL','FL_ng','FL_ng_prop','PageRank']\n",
    "Mod_tp = {0:'Louv', 2:'Cust2', 6:'Cust6', 11:'Cust11'}\n",
    "\n",
    "\n",
    "for data in data_names: \n",
    "    for survive in [0]:\n",
    "    #for survive in [0,1]:\n",
    "        '''\n",
    "        Get the Graph from Edge_List and get the labels\n",
    "        '''\n",
    "        #DO not recalculate Graph for non bulk RNA datasets\n",
    "        if data not in ['mRNA','miRNA'] and survive==1:\n",
    "            continue\n",
    "        G, label= data_to_graph(data,survive)\n",
    "        print('Number of nodes:',G.number_of_nodes())\n",
    "        #get unique entry in label\n",
    "        with open('./Results/'+data+'.txt', 'a') as f:\n",
    "            f.write('True Labels: [')\n",
    "            for i in list(set(label)):\n",
    "                f.write(str(i)+', ')\n",
    "            f.write('] # of Comms: ' + str(len(list(set(label))))+ '\\n')\n",
    "\n",
    "        \n",
    "        for FR_type in range(4):\n",
    "            for FR_order in [0]:\n",
    "                for FR_Rec in [0]:\n",
    "                    for Mod_type in [0,2,6,11]:\n",
    "                        #skip survive for non bulk RNA datasets\n",
    "                        if data not in ['mRNA','miRNA'] and survive==1:\n",
    "                            continue\n",
    "                        \n",
    "                        name =  data + '(All nodes): '+ str(FR_tp[FR_type]) + ' + '+ str(Mod_tp[Mod_type])\n",
    "                        if FR_type==3:\n",
    "                            name = data + ' (All nodes): PageRank' + ' + '+ str(Mod_tp[Mod_type])\n",
    "                        if data in ['mRNA','miRNA']:\n",
    "                            name = data + ' (All nodes): '+ str(FR_tp[FR_type]) + ' + '+ str(Mod_tp[Mod_type]) + ' + Survive: '+str(survive)\n",
    "                            if FR_type==3:\n",
    "                                name = data + ' (All nodes): PageRank' + ' + '+ str(Mod_tp[Mod_type]) + ' + Survive: '+str(survive)\n",
    "                        #print(name)\n",
    "                        \n",
    "                        #Louvain doesn't have FlowRank values involved\n",
    "                        if Mod_type==0:\n",
    "                            name = data + ' (All nodes): '+ str(Mod_tp[Mod_type])\n",
    "                        #Louvain just runs once\n",
    "                        if Mod_type==0:\n",
    "                            if FR_type!=0:\n",
    "                                continue\n",
    "                        #print('Number of nodes in subgraph:',H.number_of_nodes())\n",
    "\n",
    "                        '''\n",
    "                        Calculate NMI and Purity for different resolutions\n",
    "                        '''\n",
    "                        max_nmi = (0,0,0,0,[]) # (nmi, purity, res, FR_type, partition)\n",
    "                        max_purity = (0,0,0,0,[])\n",
    "                        res_list = []\n",
    "                        for i in range(20):\n",
    "                            res_list.append(i/10+0.01)\n",
    "                        \n",
    "                        for res in res_list:\n",
    "                            partition = RC.louvain_partitions(G, seed=0,resolution=res,FR_order=FR_order, FR_Recalc=FR_Rec, FR_type=FR_type, Mod_type=Mod_type)\n",
    "                            \n",
    "                            partition_ = deque(partition, maxlen=1).pop()\n",
    "                            label_new = get_labels(partition_,G.number_of_nodes())\n",
    "\n",
    "                            nmi_ = NMI(label,label_new)\n",
    "                            purity_ = met.purity_score(label,label_new)\n",
    "                            #print('NMI:', nmi_,'res:',res)\n",
    "                            if nmi_>max_nmi[0]:\n",
    "                                max_nmi = (nmi_,purity_,res,FR_type,partition_)\n",
    "                            if purity_>max_purity[1]:\n",
    "                                max_purity = (nmi_,purity_,res,FR_type,partition_)\n",
    "                        '''\n",
    "                        Write the results to Results folder\n",
    "                        '''\n",
    "                        print ('Max NMI: ',max_nmi[0], 'at res: ',max_nmi[2])\n",
    "                        write_out(data, name, max_nmi, max_purity)\n",
    "                        #print(' Max NMI = [' , round(max_nmi[0],3), ',', round(max_nmi[1],3), ']', ' res:= ', round(max_nmi[2],3))\n",
    "                        #print('Partition sizes:',end=' ')\n",
    "                        # for i in max_nmi[4]:\n",
    "                        #     print(len(i),end=' ')\n",
    "                        # print()  \n",
    "                        # \n",
    "                        #  #print(' Max Purity = [' , round(max_purity[0],3), ',', round(max_purity[1],3), ']', ' res:= ', round(max_purity[2],3))\n",
    "                        # #print('Partition sizes:',end=' ')\n",
    "                        # for i in max_purity[4]:\n",
    "                        #    print(len(i),end=' ')\n",
    "                        # print()  \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
